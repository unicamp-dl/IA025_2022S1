{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unicamp-dl/IA025_2022S1/blob/main/Final_project/Karen_Rosero/wav2vec2_Preprocess_ANSYN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95459e0a",
      "metadata": {
        "id": "95459e0a"
      },
      "source": [
        "# Sound detection and classification using transformers\n",
        "## Data processing notebook\n",
        "\n",
        "## Projeto final da disclipina IA025\n",
        "## Autora: Karen Rosero"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7847d4a",
      "metadata": {
        "id": "a7847d4a"
      },
      "source": [
        "Importo bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2780edc1",
      "metadata": {
        "id": "2780edc1"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import torch\n",
        "import torchaudio\n",
        "import torchaudio.functional as F\n",
        "import torchaudio.transforms as T\n",
        "from scipy.io.wavfile import write\n",
        "from sklearn.model_selection import train_test_split\n",
        "import csv\n",
        "import librosa "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96ecc157",
      "metadata": {
        "id": "96ecc157"
      },
      "source": [
        "## 1. Pré-procesando a base de dados ANSYN "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78a6cb81",
      "metadata": {
        "id": "78a6cb81"
      },
      "source": [
        "#### O objetivo deste processo é mudar a frequência de amostragem de 44100Hz para 16000Hz visando a compatibilidade com o modelo pré-treinado wav2vec2. Também é modificado o formato das etiquetas que indicava o tempo de começo e finalização do evento de som, para um formato de amostras. Tantos os áudios, como as etiquetas foram fixados em 30s, seja com padding ou cortando amostras adicionais"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6a639c2",
      "metadata": {
        "id": "d6a639c2"
      },
      "outputs": [],
      "source": [
        "path_fold = '/home/lab_acustica/Documentos/ANSYN_Pilot'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "569a334a",
      "metadata": {
        "id": "569a334a"
      },
      "source": [
        "Funções para modificar os sinais de áudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20ec62ce",
      "metadata": {
        "id": "20ec62ce"
      },
      "outputs": [],
      "source": [
        "def process_audio(signal, sr, new_sr):\n",
        "    resampler = T.Resample(sr, new_sr)\n",
        "    signal = resampler(signal)\n",
        "    # cut if necessary \n",
        "    length_signal = signal.shape[1]\n",
        "    if length_signal > new_sr*30:\n",
        "        signal = signal[:, :new_sr*30]\n",
        "    # right pad if neccesary    \n",
        "    if length_signal < new_sr*30:\n",
        "        num_missing_samples = new_sr*30 - length_signal\n",
        "        last_dim_padding = (0, num_missing_samples)\n",
        "        signal = torch.nn.functional.pad(signal, last_dim_padding)\n",
        "    return signal"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55efc8fe",
      "metadata": {
        "id": "55efc8fe"
      },
      "source": [
        "Funções para modificar o formato das etiquetas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d76680c8",
      "metadata": {
        "id": "d76680c8"
      },
      "outputs": [],
      "source": [
        "tg_sr = 16000\n",
        "_label_hop_len_s=0.1\n",
        "_max_audio_len_s=30         \n",
        "_label_hop_len = int(tg_sr * _label_hop_len_s)\n",
        "_label_frame_res = tg_sr / float(_label_hop_len)\n",
        "_nb_label_frames_1s = int(_label_frame_res)\n",
        "_max_label_frames = int(np.ceil((tg_sr*_max_audio_len_s) / float(_label_hop_len)))\n",
        "_unique_classes = \\\n",
        "                {\n",
        "                    'clearthroat': 2,\n",
        "                    'cough': 8,\n",
        "                    'doorslam': 9,\n",
        "                    'drawer': 1,\n",
        "                    'keyboard': 6,\n",
        "                    'keysDrop': 4,\n",
        "                    'knock': 0,\n",
        "                    'laughter': 10,\n",
        "                    'pageturn': 7,\n",
        "                    'phone': 3,\n",
        "                    'speech': 5\n",
        "                }\n",
        "new_audio_fold = '/home/lab_acustica/Documentos/ANSYN_Pilot/audio/'\n",
        "new_label_fold = '/home/lab_acustica/Documentos/ANSYN_Pilot/label/'\n",
        "\n",
        "def _read_desc_file(desc_filename):\n",
        "    desc_file = {\n",
        "        'class': list(), 'start': list(), 'end': list(), 'ele': list(), 'azi': list()\n",
        "    }\n",
        "    fid = open(desc_filename, 'r')\n",
        "    next(fid)\n",
        "    for line in fid:\n",
        "        split_line = line.strip().split(',')\n",
        "        desc_file['class'].append(split_line[0].split('.')[0][:-3])\n",
        "        desc_file['start'].append(int(np.floor(float(split_line[1])*_label_frame_res)))\n",
        "        desc_file['end'].append(int(np.ceil(float(split_line[2])*_label_frame_res)))\n",
        "        desc_file['ele'].append(int(float(split_line[3])))\n",
        "        desc_file['azi'].append(int(float(split_line[4])))     \n",
        "    fid.close()\n",
        "    return desc_file\n",
        "\n",
        "def _get_se_labels(_desc_file):\n",
        "    se_label = np.zeros((_max_label_frames, len(_unique_classes)))\n",
        "    for i, se_class in enumerate(_desc_file['class']):\n",
        "        start_frame = _desc_file['start'][i]\n",
        "        end_frame = _max_label_frames if _desc_file['end'][i] > _max_label_frames else _desc_file['end'][i]\n",
        "        se_label[start_frame:end_frame + 1, _unique_classes[se_class]] = 1\n",
        "    se_list = []\n",
        "    for i in range(len(se_label)):\n",
        "        k = np.where(se_label[i])\n",
        "        se_list.append(k)\n",
        "    return se_list\n",
        " \n",
        "def write_new_format(label_name, se_label):\n",
        "    \n",
        "    _fid = open(label_name, 'w')\n",
        "    # _fid.write('{},{},{},{}\\n'.format('frame number with 20ms hop (int)', 'class index (int)', 'azimuth angle (int)', 'elevation angle (int)'))\n",
        "    count = 0\n",
        "    for ind in range(len(se_label)):\n",
        "        if len(se_label[ind][0])==1:\n",
        "            _fid.write('{},{}\\n'.format(int(count), int(se_label[ind][0][0])))\n",
        "        elif len(se_label[ind][0])==2:\n",
        "            _fid.write('{},{},{}\\n'.format(int(count), int(se_label[ind][0][0]), int(se_label[ind][0][1])))\n",
        "        elif len(se_label[ind][0])==3:\n",
        "            _fid.write('{},{},{},{}\\n'.format(int(count), int(se_label[ind][0][0]), int(se_label[ind][0][1]), int(se_label[ind][0][2])))        \n",
        "        elif len(se_label[ind][0])==0:\n",
        "            _fid.write('{}\\n'.format(int(count)))    \n",
        "        count = count +1\n",
        "    _fid.close()\n",
        "\n",
        "def process_labels(orig_name, new_name):\n",
        "    dicc = _read_desc_file(orig_name)\n",
        "    se_label = _get_se_labels(dicc)\n",
        "    write_new_format(new_name, se_label)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8248488",
      "metadata": {
        "id": "c8248488"
      },
      "source": [
        "Esta célula salva a nova versão da base de dados modificada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83064687",
      "metadata": {
        "id": "83064687"
      },
      "outputs": [],
      "source": [
        "for fold in os.listdir(path_fold):\n",
        "    if 'wav' in fold:\n",
        "        for file in os.listdir(path_fold + '/' + fold):\n",
        "            if 'test' in file and len(file)==22:\n",
        "                new_name = 'tst_00'+file[5]+'_'+fold[4:7]+'_s'+fold[13]+'.wav'\n",
        "                #process audio and save the new one\n",
        "                signal, sr = torchaudio.load(path_fold + '/' + fold+'/'+file)\n",
        "                signal = process_audio(signal, sr, tg_sr)\n",
        "                torchaudio.save(new_audio_fold+new_name, signal, tg_sr)\n",
        "                #print(path_fold+'/'+fold+'/'+file, path_fold+'/audio/test/'+new_name)\n",
        "            elif 'test' in file and len(file)==23:\n",
        "                new_name = 'tst_0'+file[5:7]+'_'+fold[4:7]+'_s'+fold[13]+'.wav'\n",
        "                #process audio and save the new one\n",
        "                signal, sr = torchaudio.load(path_fold + '/' + fold+'/'+file)\n",
        "                signal = process_audio(signal, sr, tg_sr)\n",
        "                torchaudio.save(new_audio_fold+new_name, signal, tg_sr)\n",
        "#                #print(file, new_name)\n",
        "            elif 'train' in file and len(file)==23:               \n",
        "                new_name = 'tra_00'+file[6]+'_'+fold[4:7]+'_s'+fold[13]+'.wav'\n",
        "                #process audio and save the new one\n",
        "                signal, sr = torchaudio.load(path_fold + '/' + fold+'/'+file)\n",
        "                signal = process_audio(signal, sr, tg_sr)\n",
        "                torchaudio.save(new_audio_fold+new_name, signal, tg_sr)            \n",
        "                #print(file, new_name)\n",
        "            elif 'train' in file and len(file)==24:            \n",
        "                new_name = 'tra_0'+file[6:8]+'_'+fold[4:7]+'_s'+fold[13]+'.wav'\n",
        "                #process audio and save the new one\n",
        "                signal, sr = torchaudio.load(path_fold + '/' + fold+'/'+file)\n",
        "                signal = process_audio(signal, sr, tg_sr)\n",
        "                torchaudio.save(new_audio_fold+new_name, signal, tg_sr)                \n",
        "                #print(file, new_name)      \n",
        "            elif 'train' in file and len(file)==25:          \n",
        "                new_name = 'tra_'+file[6:9]+'_'+fold[4:7]+'_s'+fold[13]+'.wav'\n",
        "                #process audio and save the new one\n",
        "                signal, sr = torchaudio.load(path_fold + '/' + fold+'/'+file)\n",
        "                signal = process_audio(signal, sr, tg_sr)\n",
        "                torchaudio.save(new_audio_fold+new_name, signal, tg_sr)                \n",
        "                #print(file, new_name)                \n",
        "            #shutil.copy(path_fold+'/'+fold+'/'+file, path_fold+'/audio/test/'+new_name)\n",
        "    if 'desc' in fold:\n",
        "        for file in os.listdir(path_fold + '/' + fold):\n",
        "            if 'test' in file and len(file)==22:       \n",
        "                new_name = 'tst_00'+file[5]+'_'+fold[5:8]+'_s'+fold[14]+'.csv'\n",
        "                #process label\n",
        "                process_labels(path_fold+'/'+fold+'/'+file, new_label_fold+new_name)\n",
        "                #print(file, new_name)\n",
        "            elif 'test' in file and len(file)==23:                \n",
        "                new_name = 'tst_0'+file[5:7]+'_'+fold[5:8]+'_s'+fold[14]+'.csv'\n",
        "                #process label\n",
        "                process_labels(path_fold+'/'+fold+'/'+file, new_label_fold+new_name)                \n",
        "                #print(file, new_name)\n",
        "            elif 'train' in file and len(file)==23:               \n",
        "                new_name = 'tra_00'+file[6]+'_'+fold[5:8]+'_s'+fold[14]+'.csv'\n",
        "                #process label\n",
        "                process_labels(path_fold+'/'+fold+'/'+file, new_label_fold+new_name)                \n",
        "                #print(file, new_name)\n",
        "            elif 'train' in file and len(file)==24:                \n",
        "                new_name = 'tra_0'+file[6:8]+'_'+fold[5:8]+'_s'+fold[14]+'.csv'\n",
        "                #process label\n",
        "                process_labels(path_fold+'/'+fold+'/'+file, new_label_fold+new_name)                \n",
        "                #print(file, new_name)      \n",
        "            elif 'train' in file and len(file)==25:               \n",
        "                new_name = 'tra_'+file[6:9]+'_'+fold[5:8]+'_s'+fold[14]+'.csv'\n",
        "                #process label\n",
        "                process_labels(path_fold+'/'+fold+'/'+file, new_label_fold+new_name)                \n",
        "                #print(file, new_name)                \n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aae8c57d",
      "metadata": {
        "id": "aae8c57d"
      },
      "source": [
        "## 2. Carregando os dados da nova versão da base ANSYN 30s"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c73b7937",
      "metadata": {
        "id": "c73b7937"
      },
      "source": [
        "### 2.1. Separo os dados em treinamento, validação e teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c5c4dba",
      "metadata": {
        "id": "7c5c4dba"
      },
      "outputs": [],
      "source": [
        "path_new = \"/home/lab_acustica/Documentos/ANSYN_Dataset/label\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbc28eae",
      "metadata": {
        "id": "cbc28eae"
      },
      "outputs": [],
      "source": [
        "train_total_list = []\n",
        "X_test = []\n",
        "for file in os.listdir(path_new):\n",
        "    if 'tra' in file:\n",
        "        train_total_list.append(file[:-4])\n",
        "    elif 'tst' in file:\n",
        "        X_test.append(file[:-4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2d3ad9b",
      "metadata": {
        "id": "e2d3ad9b"
      },
      "outputs": [],
      "source": [
        "train_set, val_set = torch.utils.data.random_split(train_total_list, [int(len(train_total_list)*0.7), int(len(train_total_list)*0.3)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e04662f9",
      "metadata": {
        "scrolled": true,
        "id": "e04662f9",
        "outputId": "82b715f8-e696-4365-9cb9-5a219c97017d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1512 648 540\n"
          ]
        }
      ],
      "source": [
        "X_train, X_val = train_test_split(train_total_list,  test_size=0.3, random_state=42, shuffle = True)\n",
        "print(len(X_train), len(X_val), len(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e06488d",
      "metadata": {
        "id": "2e06488d",
        "outputId": "feb70e5a-617f-4344-f70f-c4cac275b077"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tra_220_ov1_s1 tra_216_ov2_s3 tst_046_ov2_s2\n"
          ]
        }
      ],
      "source": [
        "print(X_train[0], X_val[0], X_test[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17be3e1b",
      "metadata": {
        "id": "17be3e1b"
      },
      "source": [
        "### 2.2. Dataloader para sinais de 30s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d55fb6d",
      "metadata": {
        "id": "2d55fb6d"
      },
      "outputs": [],
      "source": [
        "class ANSYN_Dataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, filenames):    \n",
        "        self.filenames = filenames\n",
        "        self.audio_path = \"/home/lab_acustica/Documentos/ANSYN_Dataset/audio/\"\n",
        "        self.label_path = \"/home/lab_acustica/Documentos/ANSYN_Dataset/label/\"\n",
        "    \n",
        "    def normalize_layer(self, feats):    # função para normalizar\n",
        "        with torch.no_grad():\n",
        "            feats = torch.nn.functional.layer_norm(feats, feats.shape)\n",
        "        return feats\n",
        "    \n",
        "    def read_label(self, labelfile):     # função para ler o conteúdo de cada csv\n",
        "        ex_label_df = csv.reader(open(labelfile))\n",
        "        csv_list = []\n",
        "        for line in ex_label_df:\n",
        "            if len(line)==1:\n",
        "                csv_list.append(tuple())\n",
        "            elif len(line)==2:\n",
        "                csv_list.append(tuple((line[1])))\n",
        "            elif len(line)==3:\n",
        "                csv_list.append(tuple((line[1], line[2])))\n",
        "            elif len(line)==4:\n",
        "                csv_list.append(tuple((line[1], line[2], line[3])))    \n",
        "        return csv_list    \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        feats, _ = torchaudio.load(self.audio_path + self.filenames[index]+'.wav')\n",
        "        feats = self.normalize_layer(feats)\n",
        "        target = self.read_label(self.label_path + self.filenames[index]+'.csv')\n",
        "        return {\"Audio\": feats, \"Class\":target}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1dddb916",
      "metadata": {
        "id": "1dddb916"
      },
      "outputs": [],
      "source": [
        "train_dataset = ANSYN_Dataset(X_train)                           \n",
        "val_dataset =  ANSYN_Dataset(X_val)                              "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a601dc96",
      "metadata": {
        "id": "a601dc96",
        "outputId": "68eca4c7-0b70-472e-e319-c9acd11079cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Número de amostras de treinamento: 1512\n",
            "Número de amostras de validação: 648\n"
          ]
        }
      ],
      "source": [
        "print('Número de amostras de treinamento:', len(train_dataset))\n",
        "print('Número de amostras de validação:', len(val_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d30a76b8",
      "metadata": {
        "id": "d30a76b8",
        "outputId": "4799208a-bc4a-4d4c-d6f8-afb39c7dc38e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.0148,  0.0102,  0.0176,  ...,  0.0011,  0.0011,  0.0011],\n",
              "        [-0.0353, -0.0142, -0.0224,  ...,  0.0011,  0.0011,  0.0011],\n",
              "        [ 0.0088,  0.0058, -0.0155,  ...,  0.0011,  0.0011,  0.0011],\n",
              "        [ 0.0269,  0.0086, -0.0007,  ...,  0.0011,  0.0011,  0.0011]])"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset[0][\"Audio\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "791b9fb4",
      "metadata": {
        "id": "791b9fb4",
        "outputId": "d10e805c-fca7-4c9b-b2d0-5cfa59f8d0d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(),\n",
              " (),\n",
              " (),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " ('4',),\n",
              " ('4',),\n",
              " ('4',),\n",
              " ('4',),\n",
              " ('4',),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " ('7',),\n",
              " ('7',),\n",
              " ('7',),\n",
              " ('7',),\n",
              " ('7',),\n",
              " ('7',),\n",
              " ('7',),\n",
              " ('7',),\n",
              " ('7',),\n",
              " ('7',),\n",
              " ('7',),\n",
              " ('7',),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " ('1',),\n",
              " ('1',),\n",
              " ('1',),\n",
              " ('1',),\n",
              " ('1',),\n",
              " ('1',),\n",
              " ('1',),\n",
              " ('1',),\n",
              " ('1',),\n",
              " ('1',),\n",
              " ('1',),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " ('5',),\n",
              " ('5',),\n",
              " ('5',),\n",
              " ('5',),\n",
              " ('5',),\n",
              " ('5',),\n",
              " ('5',),\n",
              " ('5',),\n",
              " ('5',),\n",
              " ('5',),\n",
              " ('5',),\n",
              " ('5',),\n",
              " ('5',),\n",
              " ('5',),\n",
              " ('5',),\n",
              " ('5',),\n",
              " ('5',),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " ('6',),\n",
              " ('6',),\n",
              " ('6',),\n",
              " ('6',),\n",
              " ('6',),\n",
              " ('6',),\n",
              " ('6',),\n",
              " ('6',),\n",
              " ('6',),\n",
              " ('6',),\n",
              " ('6',),\n",
              " ('6',),\n",
              " ('6',),\n",
              " ('6',),\n",
              " ('6',),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " ('7',),\n",
              " ('7',),\n",
              " ('7',),\n",
              " ('7',),\n",
              " ('7',),\n",
              " ('7',),\n",
              " ('7',),\n",
              " ('7',),\n",
              " ('7',),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " ('9',),\n",
              " ('9',),\n",
              " ('9',),\n",
              " ('9',),\n",
              " ('9',),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " ('5',),\n",
              " ('5',),\n",
              " ('5',),\n",
              " ('5',),\n",
              " ('5',),\n",
              " ('5',),\n",
              " ('5',),\n",
              " ('5',),\n",
              " ('5',),\n",
              " ('5',),\n",
              " ('5',),\n",
              " ('5',),\n",
              " ('5',),\n",
              " ('5',),\n",
              " ('5',),\n",
              " ('5',),\n",
              " ('5',),\n",
              " ('5',),\n",
              " ('5',),\n",
              " ('5',),\n",
              " ('5',),\n",
              " ('5',),\n",
              " ('5',),\n",
              " ('5',),\n",
              " ('5',),\n",
              " ('5',),\n",
              " ('5',),\n",
              " ('5',),\n",
              " ('5',),\n",
              " ('5',),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " ('7',),\n",
              " ('7',),\n",
              " ('7',),\n",
              " ('7',),\n",
              " ('7',),\n",
              " ('7',),\n",
              " ('7',),\n",
              " ('7',),\n",
              " ('7',),\n",
              " ('7',),\n",
              " ('7',),\n",
              " ('7',),\n",
              " ('7',),\n",
              " ('7',),\n",
              " ('7',),\n",
              " ('7',),\n",
              " ('7',),\n",
              " ('7',),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " ('3',),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " ('6',),\n",
              " ('6',),\n",
              " ('6',),\n",
              " ('6',),\n",
              " ('6',),\n",
              " ('6',),\n",
              " ('6',),\n",
              " ('6',),\n",
              " ('6',),\n",
              " ('6',),\n",
              " ('6',),\n",
              " ('6',),\n",
              " ('6',),\n",
              " ('6',),\n",
              " ('6',),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " (),\n",
              " ()]"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset[0][\"Class\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c33ac40",
      "metadata": {
        "id": "0c33ac40"
      },
      "source": [
        "# 3. Processando a base de dados em trechos de 200ms "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a43cf7b1",
      "metadata": {
        "id": "a43cf7b1"
      },
      "source": [
        "#### Considerando que precisamos predecir o que acontece no som a cada 200ms, processamos a base e salvamos os trechos de 200ms para economizar memória RAM no treinamento."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27288bf1",
      "metadata": {
        "id": "27288bf1"
      },
      "source": [
        "### 3.1. Processando os arquivos de áudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43ce0715",
      "metadata": {
        "scrolled": false,
        "id": "43ce0715",
        "outputId": "f268c48a-54b3-4a1b-a9c0-07b80c7371ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files processed: 0\n",
            "Files processed: 100\n",
            "Files processed: 200\n",
            "Files processed: 300\n",
            "Files processed: 400\n",
            "Files processed: 500\n",
            "Files processed: 600\n",
            "Files processed: 700\n",
            "Files processed: 800\n"
          ]
        }
      ],
      "source": [
        "# Executar essa célula uma vez só \n",
        "file_dest = '/home/lab_acustica/Documentos/ANSYN_Dataset/audio_200ms_ov1/'\n",
        "files = os.listdir('/home/lab_acustica/Documentos/ANSYN_Dataset/audio/')\n",
        "count  = 0\n",
        "for audios in files:\n",
        "    if 'ov1' in audios:\n",
        "        signal, _= torchaudio.load('/home/lab_acustica/Documentos/ANSYN_Dataset/audio/'+audios)\n",
        "        audio_30s = torch.tensor_split(signal, 150, dim=1)\n",
        "        if count%100 ==0: \n",
        "            print('Files processed:' , count)\n",
        "        for j in range(len(audio_30s)):\n",
        "            name = file_dest+audios[:-4]+'_'+str(j)+'.wav'\n",
        "            torchaudio.save(name, audio_30s[j], 16000) \n",
        "        count = count + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96dfe58a",
      "metadata": {
        "id": "96dfe58a"
      },
      "source": [
        "### 3.2. Separando em treino validação e teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70aff0ae",
      "metadata": {
        "id": "70aff0ae"
      },
      "outputs": [],
      "source": [
        "path_200ms = '/home/lab_acustica/Documentos/ANSYN_Dataset/audio_200ms_ov1/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60b34203",
      "metadata": {
        "id": "60b34203"
      },
      "outputs": [],
      "source": [
        "train_total_list = []\n",
        "X_test = []\n",
        "for file in os.listdir(path_200ms):\n",
        "    if 'tra' in file:\n",
        "        train_total_list.append(file[:-4])\n",
        "    elif 'tst' in file:\n",
        "        X_test.append(file[:-4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3a5a141",
      "metadata": {
        "id": "c3a5a141"
      },
      "outputs": [],
      "source": [
        "train_set, val_set = torch.utils.data.random_split(train_total_list, [int(len(train_total_list)*0.7), int(len(train_total_list)*0.3)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03174bd3",
      "metadata": {
        "scrolled": false,
        "id": "03174bd3",
        "outputId": "a0ecb3c9-8966-4dfc-cdb3-9b23a902e000"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "75600 32400 27000\n"
          ]
        }
      ],
      "source": [
        "X_train, X_val = train_test_split(train_total_list,  test_size=0.3, random_state=42, shuffle = True)\n",
        "print(len(X_train), len(X_val), len(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2131904",
      "metadata": {
        "id": "f2131904",
        "outputId": "63a422cc-c00b-46d8-dc94-8fddbedcdc7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tra_045_ov1_s3_106 tra_065_ov1_s1_1 tst_032_ov1_s2_5\n"
          ]
        }
      ],
      "source": [
        "print(X_train[0], X_val[0], X_test[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cda261d4",
      "metadata": {
        "id": "cda261d4"
      },
      "source": [
        "Crio um dataframe para cada grupo de dados "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92d362e3",
      "metadata": {
        "id": "92d362e3",
        "outputId": "1c50d325-9815-4f68-da62-2040279b6d12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(75600, 1)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Filename</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tra_045_ov1_s3_106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tra_165_ov1_s2_17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tra_102_ov1_s1_139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tra_105_ov1_s2_131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tra_023_ov1_s3_90</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Filename\n",
              "0  tra_045_ov1_s3_106\n",
              "1   tra_165_ov1_s2_17\n",
              "2  tra_102_ov1_s1_139\n",
              "3  tra_105_ov1_s2_131\n",
              "4   tra_023_ov1_s3_90"
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train = pd.DataFrame(X_train, columns=['Filename'])\n",
        "print(df_train.shape)\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a32a4e21",
      "metadata": {
        "id": "a32a4e21",
        "outputId": "c9331e22-56c3-465a-aba0-8b6975b7ed79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(32400, 1)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Filename</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tra_065_ov1_s1_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tra_096_ov1_s3_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tra_126_ov1_s1_9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tra_067_ov1_s1_61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tra_115_ov1_s3_56</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Filename\n",
              "0   tra_065_ov1_s1_1\n",
              "1   tra_096_ov1_s3_1\n",
              "2   tra_126_ov1_s1_9\n",
              "3  tra_067_ov1_s1_61\n",
              "4  tra_115_ov1_s3_56"
            ]
          },
          "execution_count": 142,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_val = pd.DataFrame(X_val, columns=['Filename'])\n",
        "print(df_val.shape)\n",
        "df_val.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b952271",
      "metadata": {
        "id": "0b952271",
        "outputId": "7755f02c-57f3-42ad-b96b-3f29e08e1142"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(27000, 1)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Filename</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tst_032_ov1_s2_5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tst_051_ov1_s1_45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tst_026_ov1_s2_64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tst_027_ov1_s3_53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tst_005_ov1_s2_44</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Filename\n",
              "0   tst_032_ov1_s2_5\n",
              "1  tst_051_ov1_s1_45\n",
              "2  tst_026_ov1_s2_64\n",
              "3  tst_027_ov1_s3_53\n",
              "4  tst_005_ov1_s2_44"
            ]
          },
          "execution_count": 143,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test = pd.DataFrame(X_test, columns=['Filename'])\n",
        "print(df_test.shape)\n",
        "df_test.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d45d173f",
      "metadata": {
        "id": "d45d173f"
      },
      "source": [
        "### 3.3. Processando as labels em arquivos separados cada 200ms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc000114",
      "metadata": {
        "id": "dc000114"
      },
      "outputs": [],
      "source": [
        "#código para o subconjunto ov1 só \n",
        "\n",
        "#label_dest = '/home/lab_acustica/Documentos/ANSYN_Dataset/label_200ms_ov1/'\n",
        "#files = '/home/lab_acustica/Documentos/ANSYN_Dataset/label/'\n",
        "\n",
        "for label in os.listdir(files):\n",
        "    if 'ov1' in label:\n",
        "        label_file = csv.reader(open(files+label, 'r'))\n",
        "        for line in label_file:\n",
        "            if int(line[0])%2==0 and len(line)==2: \n",
        "                _fid = open(label_dest+label[:-4]+'_'+str(int(int(line[0])/2))+'.csv', 'w')\n",
        "                _fid.write('{}\\n'.format(int(line[1])))\n",
        "                _fid.close()\n",
        "            elif int(line[0])%2==0 and len(line)==1:  \n",
        "                _fid = open(label_dest+label[:-4]+'_'+str(int(int(line[0])/2))+'.csv', 'w')\n",
        "                _fid.close()                \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "facc5b6d",
      "metadata": {
        "id": "facc5b6d"
      },
      "source": [
        "Baseado nos dataframes de treino validação e teste, abro o arquivo csv correspondente e salvo uma lista"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa99de2b",
      "metadata": {
        "id": "fa99de2b"
      },
      "outputs": [],
      "source": [
        "labels_path = '/home/lab_acustica/Documentos/ANSYN_Dataset/label_200ms_ov1/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94cda41f",
      "metadata": {
        "scrolled": true,
        "id": "94cda41f",
        "outputId": "28b02a63-1f52-4021-de67-080bc4f3b3b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "27000\n"
          ]
        }
      ],
      "source": [
        "test_classes = []\n",
        "for i in range(len(df_test)):    \n",
        "    if os.path.getsize(labels_path+df_test['Filename'][i]+'.csv')==0:\n",
        "        test_classes.append(str(-1))\n",
        "    else:\n",
        "        label_file = csv.reader(open(labels_path+df_test['Filename'][i]+'.csv', 'r'))\n",
        "        for count , line in enumerate(label_file):\n",
        "            test_classes.append(line[0])\n",
        "print(len(test_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca6d2f30",
      "metadata": {
        "id": "ca6d2f30",
        "outputId": "23809c5e-c8d9-4875-8350-d829101d2fb2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Filename</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tst_032_ov1_s2_5</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tst_051_ov1_s1_45</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tst_026_ov1_s2_64</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tst_027_ov1_s3_53</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tst_005_ov1_s2_44</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Filename Class\n",
              "0   tst_032_ov1_s2_5     7\n",
              "1  tst_051_ov1_s1_45    -1\n",
              "2  tst_026_ov1_s2_64     5\n",
              "3  tst_027_ov1_s3_53     3\n",
              "4  tst_005_ov1_s2_44     2"
            ]
          },
          "execution_count": 168,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test['Class'] = test_classes\n",
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b16b3e5c",
      "metadata": {
        "id": "b16b3e5c",
        "outputId": "810ec049-8450-4ff6-b314-8b7f19f3bd4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "32400\n"
          ]
        }
      ],
      "source": [
        "val_classes = []\n",
        "for i in range(len(df_val)):    \n",
        "    if os.path.getsize(labels_path+df_val['Filename'][i]+'.csv')==0:\n",
        "        val_classes.append(str(-1))\n",
        "    else:\n",
        "        label_file = csv.reader(open(labels_path+df_val['Filename'][i]+'.csv', 'r'))\n",
        "        for count , line in enumerate(label_file):\n",
        "            val_classes.append(line[0])\n",
        "print(len(val_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d0fddff",
      "metadata": {
        "id": "0d0fddff",
        "outputId": "a12416db-10ce-48c6-d8d5-6c50dcf518a6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Filename</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tra_065_ov1_s1_1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tra_096_ov1_s3_1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tra_126_ov1_s1_9</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tra_067_ov1_s1_61</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tra_115_ov1_s3_56</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Filename Class\n",
              "0   tra_065_ov1_s1_1     1\n",
              "1   tra_096_ov1_s3_1     0\n",
              "2   tra_126_ov1_s1_9     1\n",
              "3  tra_067_ov1_s1_61     3\n",
              "4  tra_115_ov1_s3_56     1"
            ]
          },
          "execution_count": 170,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_val['Class'] = val_classes\n",
        "df_val.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e881a9a1",
      "metadata": {
        "id": "e881a9a1",
        "outputId": "da64a7e5-6d16-4860-f30e-5d32e97d4e0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "75600\n"
          ]
        }
      ],
      "source": [
        "train_classes = []\n",
        "for i in range(len(df_train)):    \n",
        "    if os.path.getsize(labels_path+df_train['Filename'][i]+'.csv')==0:\n",
        "        train_classes.append(str(-1))\n",
        "    else:\n",
        "        label_file = csv.reader(open(labels_path+df_train['Filename'][i]+'.csv', 'r'))\n",
        "        for count , line in enumerate(label_file):\n",
        "            train_classes.append(line[0])\n",
        "print(len(train_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e658272",
      "metadata": {
        "id": "6e658272",
        "outputId": "1f31360b-d81c-4a81-d334-506c01b91639"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Filename</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tra_045_ov1_s3_106</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tra_165_ov1_s2_17</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tra_102_ov1_s1_139</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tra_105_ov1_s2_131</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tra_023_ov1_s3_90</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Filename Class\n",
              "0  tra_045_ov1_s3_106     4\n",
              "1   tra_165_ov1_s2_17     0\n",
              "2  tra_102_ov1_s1_139     2\n",
              "3  tra_105_ov1_s2_131     4\n",
              "4   tra_023_ov1_s3_90     0"
            ]
          },
          "execution_count": 172,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train['Class'] = train_classes\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1dcd6a63",
      "metadata": {
        "id": "1dcd6a63"
      },
      "source": [
        "Finalmente tenho um dataframe para cada grupo de dados, mesmo que será enviado como parâmetro para cada dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9b75b27",
      "metadata": {
        "id": "b9b75b27"
      },
      "source": [
        "### 3.4. Dataloader para base de dados dividida em 200ms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1a201ef",
      "metadata": {
        "id": "b1a201ef"
      },
      "outputs": [],
      "source": [
        "class ANSYN_Dataset_20ms(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, filenames):    \n",
        "        self.filenames = filenames\n",
        "        self.audio_path = \"/home/lab_acustica/Documentos/ANSYN_Dataset/audio_200ms_ov1/\"\n",
        "    \n",
        "    def normalize_layer(self, feats):    # função para normalizar\n",
        "        with torch.no_grad():\n",
        "            feats = torch.nn.functional.layer_norm(feats, feats.shape)\n",
        "        return feats\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        feats, _ = torchaudio.load(self.audio_path + self.filenames['Filename'][index]+'.wav')\n",
        "        feats = self.normalize_layer(feats)\n",
        "        return {\"Audio\": feats, \"Class\":self.filenames['Class'][index]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "594ab792",
      "metadata": {
        "id": "594ab792"
      },
      "outputs": [],
      "source": [
        "train_dataset = ANSYN_Dataset_20ms(df_train)                           \n",
        "val_dataset =  ANSYN_Dataset_20ms(df_val)  \n",
        "test_dataset = ANSYN_Dataset_20ms(df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b6f1af5",
      "metadata": {
        "id": "4b6f1af5",
        "outputId": "d5e7acc9-008f-4889-b3eb-69bb5c08c5bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Número de amostras de treinamento: 75600\n",
            "Número de amostras de validação: 32400\n",
            "Número de amostras de teste: 27000\n"
          ]
        }
      ],
      "source": [
        "print('Número de amostras de treinamento:', len(train_dataset))\n",
        "print('Número de amostras de validação:', len(val_dataset))\n",
        "print('Número de amostras de teste:', len(test_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cfd6b45",
      "metadata": {
        "id": "0cfd6b45",
        "outputId": "89647195-50c5-41bd-c339-afa8d7c50014"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.0256, -0.4013,  0.8544,  ..., -0.0391, -0.0111,  0.1783],\n",
              "        [-0.0034, -0.0026,  0.0420,  ..., -0.0236, -0.0217, -0.0097],\n",
              "        [-0.0157,  0.5152, -0.8648,  ...,  0.0439,  0.0293, -0.2325],\n",
              "        [ 0.0245, -0.5398,  1.0974,  ..., -0.0475, -0.0875,  0.3067]])"
            ]
          },
          "execution_count": 179,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset[0][\"Audio\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e08ef94c",
      "metadata": {
        "id": "e08ef94c",
        "outputId": "73980a2a-5528-41c6-acbd-25c818681c3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'4'"
            ]
          },
          "execution_count": 180,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset[0][\"Class\"]"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "colab": {
      "name": "wav2vec2_Preprocess_ANSYN.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}