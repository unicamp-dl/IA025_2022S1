{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unicamp-dl/IA025_2022S1/blob/main/Final_project/Fernando_Fortes_Granado/Pruning_GPT_J_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZX8Z-um1L3qU",
        "outputId": "438e2a49-8555-4c24-e4b6-28b2748e552a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jul  3 18:23:00 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P0    40W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRk0oWAP2_Da",
        "outputId": "cc8fe5eb-fb4a-488f-dfb4-83aa4d31acd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.7/dist-packages (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from accelerate) (1.21.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from accelerate) (1.11.0+cu113)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from accelerate) (5.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from accelerate) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->accelerate) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->accelerate) (4.1.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIwro5kuL_Tl",
        "outputId": "cfc84c89-da5b-49e8-91ae-7cb6d2e9b961"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.20.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNzWYfqQac2K",
        "outputId": "5c0c1a36-2a60-4cc0-e99e-0e8caadd2df1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.3.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.8.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.5.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.4)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ki8QAf7zl07u"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuv4lc_ZMCSJ",
        "outputId": "c347eabe-338e-462c-b8f3-f6feaee53fc6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTJForCausalLM(\n",
              "  (transformer): GPTJModel(\n",
              "    (wte): Embedding(50400, 4096)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
              "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
              "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
              "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
              "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
              "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
              "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
              "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
              "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
              "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
              "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
              "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
              "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (12): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
              "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (13): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
              "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (14): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
              "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (15): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
              "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (16): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
              "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (17): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
              "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (18): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
              "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (19): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
              "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (20): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
              "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (21): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
              "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (22): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
              "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (23): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
              "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (24): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
              "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (25): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
              "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (26): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
              "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (27): GPTJBlock(\n",
              "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPTJAttention(\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "        )\n",
              "        (mlp): GPTJMLP(\n",
              "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
              "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=4096, out_features=50400, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, GPTNeoXForCausalLM\n",
        "from transformers import GPTJForCausalLM, GPTNeoXTokenizerFast\n",
        "from transformers import GPT2Tokenizer, GPT2Model\n",
        "\n",
        "model = GPTJForCausalLM.from_pretrained(\n",
        "    \"EleutherAI/gpt-j-6B\", revision=\"float16\", torch_dtype=torch.float16, low_cpu_mem_usage=True\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\")\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "332d26fba85f40139fbe10b83c30d2eb",
            "1112eaa0351e45b287278408131f4748",
            "b6f1d6d03d0642179258d0a296404a22",
            "106621504092406dbf11c7e8e310873c",
            "51ab14f3c95a4d5ca7cd3f70e3027b9c",
            "cea11e81dbb24eeaaae0d027dae7cc35",
            "07347a64789e447d82518c8038ddca72",
            "5f6baf71b6da4965bc0e0509535111cc",
            "41113ff3877842eeb27521656d875c38",
            "77af4bfa7a97490ab60885d4c1fe8383",
            "5a541bbb71c741c9bd7b0b7087f377b1"
          ]
        },
        "id": "9maqQmmKc7uv",
        "outputId": "0cd95e5e-0721-4fe2-a0e0-792948a74fa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reusing dataset imdb (/root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "332d26fba85f40139fbe10b83c30d2eb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-f700cd6f222bd13f.arrow\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2174 > 2048). Running this sequence through the model will result in indexing errors\n",
            "Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-b23cfeb68a931a8d.arrow\n"
          ]
        }
      ],
      "source": [
        "from typing import *\n",
        "from datasets import load_dataset\n",
        "import numpy as np\n",
        "\n",
        "class Dataset:\n",
        "  def __init__(self, dataset, max_tokens):\n",
        "    self.max_tokens = max_tokens\n",
        "    self.dataset = dataset\n",
        "    self.token_dataset = [\n",
        "        (\n",
        "            tokenizer(dataset[idx][\"text\"], return_tensors=\"pt\"),\n",
        "            \"Positive\" if dataset[idx][\"label\"] else \"Negative\",\n",
        "        ) for idx in range(len(dataset))\n",
        "    ]\n",
        "    num_tokens = np.array([self.token_dataset[idx][0].input_ids.shape[1] for idx in range(len(dataset))])\n",
        "    self.dataset_idx = np.argwhere(num_tokens <= max_tokens).reshape(-1)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    return self.token_dataset[int(self.dataset_idx[idx])]\n",
        "\n",
        "  def get_raw_item(self, idx):\n",
        "    item = self.dataset[int(self.dataset_idx[idx])]\n",
        "    return item[\"text\"], \"Positive\" if item[\"label\"] else \"Negative\"\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataset_idx)\n",
        "\n",
        "  \n",
        "class InferencePromptGen:\n",
        "  def __init__(self, learning_examples: List[Tuple[str, str]], dataset: Dataset):\n",
        "    self.dataset = dataset\n",
        "    self.learning_examples = learning_examples\n",
        "    self.fixed_text = self._get_fixed_text()\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return f\"{self.fixed_text}\\n\\n{self._get_inference_text(idx)}\", self.dataset[idx][1]\n",
        "\n",
        "  def _get_fixed_text(self):\n",
        "    # TODO: pre-salvar os tokens das amostras e dos prompts\n",
        "    instruction = \"Instruction: Given a movie review, answer if the sentiment of the review is positive or negative.\"\n",
        "    examples = \"\\n\\n\".join([f\"\"\"Example {i}:\\nReview: {text}\\nSentiment: {label}\"\"\" for i, (text, label) in enumerate(self.learning_examples)])\n",
        "    return f\"{instruction}\\n\\n{examples}\"\n",
        "\n",
        "  def _get_inference_text(self, idx):\n",
        "    return f\"Example {len(self.learning_examples)}:\\nReview: {self.dataset.get_raw_item(idx)[0]}\\nSentiment\"\n",
        "\n",
        "\n",
        "def predict(prompt, model, tokenizer):\n",
        "  tokenized = tokenizer(prompt, return_tensors=\"pt\")\n",
        "  input_ids = tokenized.input_ids.to(device)\n",
        "  attention_mask = tokenized.attention_mask.to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    gen_tokens = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        do_sample=False,\n",
        "        temperature=1,\n",
        "        max_length=2048,\n",
        "    )\n",
        "  gen_text = tokenizer.batch_decode(gen_tokens)[0]\n",
        "  return gen_text.split(\"\\n\")[len(prompt.split(\"\\n\")) - 1].split()[1]\n",
        "\n",
        "\n",
        "imdb = load_dataset(\"imdb\")\n",
        "MAX_TOKENS = 300\n",
        "NUM_INFERENCE_SAMPLES = 200\n",
        "NUM_LEARNING_SAMPLES = 7\n",
        "\n",
        "train_dataset = Dataset(\n",
        "    dataset=imdb[\"train\"].shuffle(seed=42),\n",
        "    max_tokens=MAX_TOKENS,\n",
        ")\n",
        "\n",
        "test_dataset = Dataset(\n",
        "    dataset=imdb[\"test\"].shuffle(seed=42),\n",
        "    max_tokens=MAX_TOKENS,\n",
        ")\n",
        "\n",
        "test_prompt_gen = InferencePromptGen(\n",
        "    learning_examples=[train_dataset.get_raw_item(i) for i in range(NUM_LEARNING_SAMPLES)],\n",
        "    dataset=test_dataset,\n",
        ")\n",
        "\n",
        "samples = list(range(200))\n",
        "prompts = [test_prompt_gen[i][0] for i in samples]\n",
        "labels = [test_prompt_gen[i][1] for i in samples]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#last_hidden_states = outputs.last_hidden_state\n",
        "# torch.cuda.empty_cache()\n",
        "\n",
        "# tokenized = tokenizer(prompts[5], return_tensors=\"pt\")\n",
        "# input_ids = tokenized.input_ids.to(device)\n",
        "# attention_mask = tokenized.attention_mask.to(device)\n",
        "\n",
        "# with torch.no_grad():\n",
        "#     outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=input_ids)\n",
        "# loss = outputs.loss\n",
        "# logits = outputs.logits"
      ],
      "metadata": {
        "id": "i8H0PrP9FPQ1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perplexity\n",
        "# torch.exp(loss)"
      ],
      "metadata": {
        "id": "w-ok8N9PGkG-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "HehWLrOAdfgK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "def evaluate(model, tokenizer, prompts: List[str], labels: List[str]):\n",
        "  num_correct_preds = 0\n",
        "  for idx in range(len(prompts)):\n",
        "    if ((idx % 10) == 0) and (idx != 0):\n",
        "      print(f\"Number of samples evaluated: {idx}, Number of correct preds: {num_correct_preds}, Accuracy: {num_correct_preds / idx}\")\n",
        "    output = predict(prompts[idx], model, tokenizer)\n",
        "    print(labels[idx], output, labels[idx] == output)\n",
        "\n",
        "    if labels[idx] == output:\n",
        "      num_correct_preds += 1\n",
        "    else:\n",
        "      print(\"\\n_____________________________\\n\")\n",
        "      print(\"PROMPT\")\n",
        "      print(prompts[idx])\n",
        "      print(\"\\n_____________________________\\n\")\n",
        "      print(\"LABEL\")\n",
        "      print(labels[idx])\n",
        "      print(\"OUTPUT\")\n",
        "      print(output)\n",
        "      print(\"\\n_____________________________\\n\")\n",
        "  return num_correct_preds / len(prompts)\n",
        "\n",
        "\n",
        "def evaluate_perplexity(model, tokenizer, dataset: Dataset):\n",
        "  acc_loss = 0\n",
        "  for idx in range(len(dataset)):\n",
        "    if ((idx % 10) == 0) and (idx != 0):\n",
        "      print(f\"Number of samples evaluated: {idx}, Average perplexity: {torch.exp(acc_loss / idx)}\")\n",
        "\n",
        "    input_ids = dataset[idx][0].input_ids.to(device)\n",
        "    attention_mask = dataset[idx][0].attention_mask.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=input_ids)\n",
        "    loss = outputs.loss\n",
        "    logits = outputs.logits\n",
        "    acc_loss += loss\n",
        "\n",
        "  return torch.exp(acc_loss / len(dataset))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate(model, tokenizer, prompts, labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "Whtk2gmJ4q76",
        "outputId": "f927601c-4494-4580-e5ef-a6f022b04815"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive Positive True\n",
            "Negative Negative True\n",
            "Positive Positive True\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-97df799ff468>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-381e61844c29>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, tokenizer, prompts, labels)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Number of samples evaluated: {idx}, Number of correct preds: {num_correct_preds}, Accuracy: {num_correct_preds / idx}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-b02c311c6a37>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(prompt, model, tokenizer)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mdo_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     )\n\u001b[1;32m     62\u001b[0m   \u001b[0mgen_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, renormalize_logits, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, **model_kwargs)\u001b[0m\n\u001b[1;32m   1295\u001b[0m                 \u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m                 \u001b[0msynced_gpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynced_gpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1298\u001b[0m             )\n\u001b[1;32m   1299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgreedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1685\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1686\u001b[0m                 \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1687\u001b[0;31m                 \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1688\u001b[0m             )\n\u001b[1;32m   1689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gptj/modeling_gptj.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    825\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m         )\n\u001b[1;32m    829\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gptj/modeling_gptj.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    675\u001b[0m                     \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m                     \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m                 )\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m         \u001b[0mforward_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m         \u001b[0;31m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;31m# this function, and just call forward.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "train_dataset = Dataset(\n",
        "    dataset=imdb[\"train\"].shuffle(seed=42),\n",
        "    max_tokens=2048,\n",
        ")\n",
        "evaluate_perplexity(model, tokenizer, train_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kM1C4YBzTYi8",
        "outputId": "ff089327-0c3c-463a-889b-7e69fb0e6556"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-f700cd6f222bd13f.arrow\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples evaluated: 10, Average perplexity: 20.6875\n",
            "Number of samples evaluated: 20, Average perplexity: 20.84375\n",
            "Number of samples evaluated: 30, Average perplexity: 20.4375\n",
            "Number of samples evaluated: 40, Average perplexity: 19.3125\n",
            "Number of samples evaluated: 50, Average perplexity: 20.046875\n",
            "Number of samples evaluated: 60, Average perplexity: 19.921875\n",
            "Number of samples evaluated: 70, Average perplexity: 19.625\n",
            "Number of samples evaluated: 80, Average perplexity: 19.703125\n",
            "Number of samples evaluated: 90, Average perplexity: 19.421875\n",
            "Number of samples evaluated: 100, Average perplexity: 19.234375\n",
            "Number of samples evaluated: 110, Average perplexity: 19.28125\n",
            "Number of samples evaluated: 120, Average perplexity: 19.703125\n",
            "Number of samples evaluated: 130, Average perplexity: 19.8125\n",
            "Number of samples evaluated: 140, Average perplexity: 19.8125\n",
            "Number of samples evaluated: 150, Average perplexity: 19.734375\n",
            "Number of samples evaluated: 160, Average perplexity: 19.546875\n",
            "Number of samples evaluated: 170, Average perplexity: 19.578125\n",
            "Number of samples evaluated: 180, Average perplexity: 19.390625\n",
            "Number of samples evaluated: 190, Average perplexity: 19.3125\n",
            "Number of samples evaluated: 200, Average perplexity: 19.390625\n",
            "Number of samples evaluated: 210, Average perplexity: 19.421875\n",
            "Number of samples evaluated: 220, Average perplexity: 19.359375\n",
            "Number of samples evaluated: 230, Average perplexity: 19.3125\n",
            "Number of samples evaluated: 240, Average perplexity: 19.28125\n",
            "Number of samples evaluated: 250, Average perplexity: 19.421875\n",
            "Number of samples evaluated: 260, Average perplexity: 19.390625\n",
            "Number of samples evaluated: 270, Average perplexity: 19.203125\n",
            "Number of samples evaluated: 280, Average perplexity: 19.09375\n",
            "Number of samples evaluated: 290, Average perplexity: 18.9375\n",
            "Number of samples evaluated: 300, Average perplexity: 19.09375\n",
            "Number of samples evaluated: 310, Average perplexity: 19.203125\n",
            "Number of samples evaluated: 320, Average perplexity: 19.203125\n",
            "Number of samples evaluated: 330, Average perplexity: 19.203125\n",
            "Number of samples evaluated: 340, Average perplexity: 19.171875\n",
            "Number of samples evaluated: 350, Average perplexity: 19.3125\n",
            "Number of samples evaluated: 360, Average perplexity: 19.3125\n",
            "Number of samples evaluated: 370, Average perplexity: 19.359375\n",
            "Number of samples evaluated: 380, Average perplexity: 19.359375\n",
            "Number of samples evaluated: 390, Average perplexity: 19.46875\n",
            "Number of samples evaluated: 400, Average perplexity: 19.546875\n",
            "Number of samples evaluated: 410, Average perplexity: 19.546875\n",
            "Number of samples evaluated: 420, Average perplexity: 19.46875\n",
            "Number of samples evaluated: 430, Average perplexity: 19.421875\n",
            "Number of samples evaluated: 440, Average perplexity: 19.46875\n",
            "Number of samples evaluated: 450, Average perplexity: 19.5\n",
            "Number of samples evaluated: 460, Average perplexity: 19.546875\n",
            "Number of samples evaluated: 470, Average perplexity: 19.546875\n",
            "Number of samples evaluated: 480, Average perplexity: 19.546875\n",
            "Number of samples evaluated: 490, Average perplexity: 19.546875\n",
            "Number of samples evaluated: 500, Average perplexity: 19.578125\n",
            "Number of samples evaluated: 510, Average perplexity: 19.578125\n",
            "Number of samples evaluated: 520, Average perplexity: 19.578125\n",
            "Number of samples evaluated: 530, Average perplexity: 19.625\n",
            "Number of samples evaluated: 540, Average perplexity: 19.65625\n",
            "Number of samples evaluated: 550, Average perplexity: 19.734375\n",
            "Number of samples evaluated: 560, Average perplexity: 19.8125\n",
            "Number of samples evaluated: 570, Average perplexity: 19.703125\n",
            "Number of samples evaluated: 580, Average perplexity: 19.703125\n",
            "Number of samples evaluated: 590, Average perplexity: 19.703125\n",
            "Number of samples evaluated: 600, Average perplexity: 19.734375\n",
            "Number of samples evaluated: 610, Average perplexity: 19.78125\n",
            "Number of samples evaluated: 620, Average perplexity: 19.8125\n",
            "Number of samples evaluated: 630, Average perplexity: 19.84375\n",
            "Number of samples evaluated: 640, Average perplexity: 19.84375\n",
            "Number of samples evaluated: 650, Average perplexity: 19.84375\n",
            "Number of samples evaluated: 660, Average perplexity: 19.84375\n",
            "Number of samples evaluated: 670, Average perplexity: 19.8125\n",
            "Number of samples evaluated: 680, Average perplexity: 19.84375\n",
            "Number of samples evaluated: 690, Average perplexity: 19.921875\n",
            "Number of samples evaluated: 700, Average perplexity: 19.921875\n",
            "Number of samples evaluated: 710, Average perplexity: 19.8125\n",
            "Number of samples evaluated: 720, Average perplexity: 19.578125\n",
            "Number of samples evaluated: 730, Average perplexity: 19.65625\n",
            "Number of samples evaluated: 740, Average perplexity: 19.8125\n",
            "Number of samples evaluated: 750, Average perplexity: 19.65625\n",
            "Number of samples evaluated: 760, Average perplexity: 19.578125\n",
            "Number of samples evaluated: 770, Average perplexity: 19.578125\n",
            "Number of samples evaluated: 780, Average perplexity: 19.546875\n",
            "Number of samples evaluated: 790, Average perplexity: 19.421875\n",
            "Number of samples evaluated: 800, Average perplexity: 19.421875\n",
            "Number of samples evaluated: 810, Average perplexity: 19.46875\n",
            "Number of samples evaluated: 820, Average perplexity: 19.359375\n",
            "Number of samples evaluated: 830, Average perplexity: 19.3125\n",
            "Number of samples evaluated: 840, Average perplexity: 19.390625\n",
            "Number of samples evaluated: 850, Average perplexity: 19.3125\n",
            "Number of samples evaluated: 860, Average perplexity: 19.28125\n",
            "Number of samples evaluated: 870, Average perplexity: 19.28125\n",
            "Number of samples evaluated: 880, Average perplexity: 19.28125\n",
            "Number of samples evaluated: 890, Average perplexity: 19.28125\n",
            "Number of samples evaluated: 900, Average perplexity: 19.203125\n",
            "Number of samples evaluated: 910, Average perplexity: 19.09375\n",
            "Number of samples evaluated: 920, Average perplexity: 19.015625\n",
            "Number of samples evaluated: 930, Average perplexity: 18.90625\n",
            "Number of samples evaluated: 940, Average perplexity: 18.765625\n",
            "Number of samples evaluated: 950, Average perplexity: 18.65625\n",
            "Number of samples evaluated: 960, Average perplexity: 18.546875\n",
            "Number of samples evaluated: 970, Average perplexity: 18.546875\n",
            "Number of samples evaluated: 980, Average perplexity: 18.4375\n",
            "Number of samples evaluated: 990, Average perplexity: 18.4375\n",
            "Number of samples evaluated: 1000, Average perplexity: 18.390625\n",
            "Number of samples evaluated: 1010, Average perplexity: 18.359375\n",
            "Number of samples evaluated: 1020, Average perplexity: 18.328125\n",
            "Number of samples evaluated: 1030, Average perplexity: 18.21875\n",
            "Number of samples evaluated: 1040, Average perplexity: 18.1875\n",
            "Number of samples evaluated: 1050, Average perplexity: 18.109375\n",
            "Number of samples evaluated: 1060, Average perplexity: 18.140625\n",
            "Number of samples evaluated: 1070, Average perplexity: 18.078125\n",
            "Number of samples evaluated: 1080, Average perplexity: 18.0\n",
            "Number of samples evaluated: 1090, Average perplexity: 18.046875\n",
            "Number of samples evaluated: 1100, Average perplexity: 17.96875\n",
            "Number of samples evaluated: 1110, Average perplexity: 18.0\n",
            "Number of samples evaluated: 1120, Average perplexity: 17.9375\n",
            "Number of samples evaluated: 1130, Average perplexity: 17.90625\n",
            "Number of samples evaluated: 1140, Average perplexity: 17.90625\n",
            "Number of samples evaluated: 1150, Average perplexity: 17.828125\n",
            "Number of samples evaluated: 1160, Average perplexity: 17.796875\n",
            "Number of samples evaluated: 1170, Average perplexity: 17.765625\n",
            "Number of samples evaluated: 1180, Average perplexity: 17.796875\n",
            "Number of samples evaluated: 1190, Average perplexity: 17.71875\n",
            "Number of samples evaluated: 1200, Average perplexity: 17.6875\n",
            "Number of samples evaluated: 1210, Average perplexity: 17.765625\n",
            "Number of samples evaluated: 1220, Average perplexity: 17.796875\n",
            "Number of samples evaluated: 1230, Average perplexity: 17.796875\n",
            "Number of samples evaluated: 1240, Average perplexity: 17.765625\n",
            "Number of samples evaluated: 1250, Average perplexity: 17.765625\n",
            "Number of samples evaluated: 1260, Average perplexity: 17.796875\n",
            "Number of samples evaluated: 1270, Average perplexity: 17.765625\n",
            "Number of samples evaluated: 1280, Average perplexity: 17.765625\n",
            "Number of samples evaluated: 1290, Average perplexity: 17.765625\n",
            "Number of samples evaluated: 1300, Average perplexity: 17.6875\n",
            "Number of samples evaluated: 1310, Average perplexity: 17.625\n",
            "Number of samples evaluated: 1320, Average perplexity: 17.625\n",
            "Number of samples evaluated: 1330, Average perplexity: 17.546875\n",
            "Number of samples evaluated: 1340, Average perplexity: 17.59375\n",
            "Number of samples evaluated: 1350, Average perplexity: 17.65625\n",
            "Number of samples evaluated: 1360, Average perplexity: 17.65625\n",
            "Number of samples evaluated: 1370, Average perplexity: 17.6875\n",
            "Number of samples evaluated: 1380, Average perplexity: 17.6875\n",
            "Number of samples evaluated: 1390, Average perplexity: 17.65625\n",
            "Number of samples evaluated: 1400, Average perplexity: 17.6875\n",
            "Number of samples evaluated: 1410, Average perplexity: 17.6875\n",
            "Number of samples evaluated: 1420, Average perplexity: 17.765625\n",
            "Number of samples evaluated: 1430, Average perplexity: 17.90625\n",
            "Number of samples evaluated: 1440, Average perplexity: 18.046875\n",
            "Number of samples evaluated: 1450, Average perplexity: 18.140625\n",
            "Number of samples evaluated: 1460, Average perplexity: 18.28125\n",
            "Number of samples evaluated: 1470, Average perplexity: 18.4375\n",
            "Number of samples evaluated: 1480, Average perplexity: 18.578125\n",
            "Number of samples evaluated: 1490, Average perplexity: 18.71875\n",
            "Number of samples evaluated: 1500, Average perplexity: 18.828125\n",
            "Number of samples evaluated: 1510, Average perplexity: 18.984375\n",
            "Number of samples evaluated: 1520, Average perplexity: 19.09375\n",
            "Number of samples evaluated: 1530, Average perplexity: 19.203125\n",
            "Number of samples evaluated: 1540, Average perplexity: 19.3125\n",
            "Number of samples evaluated: 1550, Average perplexity: 19.421875\n",
            "Number of samples evaluated: 1560, Average perplexity: 19.578125\n",
            "Number of samples evaluated: 1570, Average perplexity: 19.703125\n",
            "Number of samples evaluated: 1580, Average perplexity: 19.84375\n",
            "Number of samples evaluated: 1590, Average perplexity: 19.96875\n",
            "Number of samples evaluated: 1600, Average perplexity: 20.078125\n",
            "Number of samples evaluated: 1610, Average perplexity: 20.203125\n",
            "Number of samples evaluated: 1620, Average perplexity: 20.328125\n",
            "Number of samples evaluated: 1630, Average perplexity: 20.4375\n",
            "Number of samples evaluated: 1640, Average perplexity: 20.5625\n",
            "Number of samples evaluated: 1650, Average perplexity: 20.71875\n",
            "Number of samples evaluated: 1660, Average perplexity: 20.84375\n",
            "Number of samples evaluated: 1670, Average perplexity: 20.921875\n",
            "Number of samples evaluated: 1680, Average perplexity: 21.046875\n",
            "Number of samples evaluated: 1690, Average perplexity: 21.171875\n",
            "Number of samples evaluated: 1700, Average perplexity: 21.296875\n",
            "Number of samples evaluated: 1710, Average perplexity: 21.421875\n",
            "Number of samples evaluated: 1720, Average perplexity: 21.546875\n",
            "Number of samples evaluated: 1730, Average perplexity: 21.640625\n",
            "Number of samples evaluated: 1740, Average perplexity: 21.765625\n",
            "Number of samples evaluated: 1750, Average perplexity: 21.796875\n",
            "Number of samples evaluated: 1760, Average perplexity: 21.890625\n",
            "Number of samples evaluated: 1770, Average perplexity: 22.015625\n",
            "Number of samples evaluated: 1780, Average perplexity: 22.109375\n",
            "Number of samples evaluated: 1790, Average perplexity: 22.234375\n",
            "Number of samples evaluated: 1800, Average perplexity: 22.359375\n",
            "Number of samples evaluated: 1810, Average perplexity: 22.453125\n",
            "Number of samples evaluated: 1820, Average perplexity: 22.578125\n",
            "Number of samples evaluated: 1830, Average perplexity: 22.671875\n",
            "Number of samples evaluated: 1840, Average perplexity: 22.796875\n",
            "Number of samples evaluated: 1850, Average perplexity: 22.890625\n",
            "Number of samples evaluated: 1860, Average perplexity: 22.984375\n",
            "Number of samples evaluated: 1870, Average perplexity: 23.125\n",
            "Number of samples evaluated: 1880, Average perplexity: 23.203125\n",
            "Number of samples evaluated: 1890, Average perplexity: 23.296875\n",
            "Number of samples evaluated: 1900, Average perplexity: 23.4375\n",
            "Number of samples evaluated: 1910, Average perplexity: 23.53125\n",
            "Number of samples evaluated: 1920, Average perplexity: 23.625\n",
            "Number of samples evaluated: 1930, Average perplexity: 23.71875\n",
            "Number of samples evaluated: 1940, Average perplexity: 23.859375\n",
            "Number of samples evaluated: 1950, Average perplexity: 23.953125\n",
            "Number of samples evaluated: 1960, Average perplexity: 24.046875\n",
            "Number of samples evaluated: 1970, Average perplexity: 24.140625\n",
            "Number of samples evaluated: 1980, Average perplexity: 24.234375\n",
            "Number of samples evaluated: 1990, Average perplexity: 24.328125\n",
            "Number of samples evaluated: 2000, Average perplexity: 24.421875\n",
            "Number of samples evaluated: 2010, Average perplexity: 24.515625\n",
            "Number of samples evaluated: 2020, Average perplexity: 24.609375\n",
            "Number of samples evaluated: 2030, Average perplexity: 24.703125\n",
            "Number of samples evaluated: 2040, Average perplexity: 24.796875\n",
            "Number of samples evaluated: 2050, Average perplexity: 24.90625\n",
            "Number of samples evaluated: 2060, Average perplexity: 25.0\n",
            "Number of samples evaluated: 2070, Average perplexity: 25.09375\n",
            "Number of samples evaluated: 2080, Average perplexity: 25.1875\n",
            "Number of samples evaluated: 2090, Average perplexity: 25.296875\n",
            "Number of samples evaluated: 2100, Average perplexity: 25.390625\n",
            "Number of samples evaluated: 2110, Average perplexity: 25.484375\n",
            "Number of samples evaluated: 2120, Average perplexity: 25.59375\n",
            "Number of samples evaluated: 2130, Average perplexity: 25.640625\n",
            "Number of samples evaluated: 2140, Average perplexity: 25.734375\n",
            "Number of samples evaluated: 2150, Average perplexity: 25.84375\n",
            "Number of samples evaluated: 2160, Average perplexity: 25.9375\n",
            "Number of samples evaluated: 2170, Average perplexity: 26.046875\n",
            "Number of samples evaluated: 2180, Average perplexity: 26.09375\n",
            "Number of samples evaluated: 2190, Average perplexity: 26.203125\n",
            "Number of samples evaluated: 2200, Average perplexity: 26.296875\n",
            "Number of samples evaluated: 2210, Average perplexity: 26.34375\n",
            "Number of samples evaluated: 2220, Average perplexity: 26.453125\n",
            "Number of samples evaluated: 2230, Average perplexity: 26.5625\n",
            "Number of samples evaluated: 2240, Average perplexity: 26.609375\n",
            "Number of samples evaluated: 2250, Average perplexity: 26.71875\n",
            "Number of samples evaluated: 2260, Average perplexity: 26.8125\n",
            "Number of samples evaluated: 2270, Average perplexity: 26.875\n",
            "Number of samples evaluated: 2280, Average perplexity: 26.96875\n",
            "Number of samples evaluated: 2290, Average perplexity: 27.03125\n",
            "Number of samples evaluated: 2300, Average perplexity: 27.140625\n",
            "Number of samples evaluated: 2310, Average perplexity: 27.234375\n",
            "Number of samples evaluated: 2320, Average perplexity: 27.296875\n",
            "Number of samples evaluated: 2330, Average perplexity: 27.40625\n",
            "Number of samples evaluated: 2340, Average perplexity: 27.453125\n",
            "Number of samples evaluated: 2350, Average perplexity: 27.5625\n",
            "Number of samples evaluated: 2360, Average perplexity: 27.609375\n",
            "Number of samples evaluated: 2370, Average perplexity: 27.71875\n",
            "Number of samples evaluated: 2380, Average perplexity: 27.78125\n",
            "Number of samples evaluated: 2390, Average perplexity: 27.890625\n",
            "Number of samples evaluated: 2400, Average perplexity: 27.9375\n",
            "Number of samples evaluated: 2410, Average perplexity: 28.0\n",
            "Number of samples evaluated: 2420, Average perplexity: 28.109375\n",
            "Number of samples evaluated: 2430, Average perplexity: 28.15625\n",
            "Number of samples evaluated: 2440, Average perplexity: 28.265625\n",
            "Number of samples evaluated: 2450, Average perplexity: 28.328125\n",
            "Number of samples evaluated: 2460, Average perplexity: 27.9375\n",
            "Number of samples evaluated: 2470, Average perplexity: 27.5625\n",
            "Number of samples evaluated: 2480, Average perplexity: 27.1875\n",
            "Number of samples evaluated: 2490, Average perplexity: 26.8125\n",
            "Number of samples evaluated: 2500, Average perplexity: 26.5\n",
            "Number of samples evaluated: 2510, Average perplexity: 26.140625\n",
            "Number of samples evaluated: 2520, Average perplexity: 25.796875\n",
            "Number of samples evaluated: 2530, Average perplexity: 25.484375\n",
            "Number of samples evaluated: 2540, Average perplexity: 25.234375\n",
            "Number of samples evaluated: 2550, Average perplexity: 24.90625\n",
            "Number of samples evaluated: 2560, Average perplexity: 24.609375\n",
            "Number of samples evaluated: 2570, Average perplexity: 24.328125\n",
            "Number of samples evaluated: 2580, Average perplexity: 24.0\n",
            "Number of samples evaluated: 2590, Average perplexity: 23.8125\n",
            "Number of samples evaluated: 2600, Average perplexity: 23.484375\n",
            "Number of samples evaluated: 2610, Average perplexity: 23.203125\n",
            "Number of samples evaluated: 2620, Average perplexity: 22.9375\n",
            "Number of samples evaluated: 2630, Average perplexity: 22.671875\n",
            "Number of samples evaluated: 2640, Average perplexity: 22.40625\n",
            "Number of samples evaluated: 2650, Average perplexity: 22.140625\n",
            "Number of samples evaluated: 2660, Average perplexity: 21.890625\n",
            "Number of samples evaluated: 2670, Average perplexity: 21.640625\n",
            "Number of samples evaluated: 2680, Average perplexity: 21.375\n",
            "Number of samples evaluated: 2690, Average perplexity: 21.125\n",
            "Number of samples evaluated: 2700, Average perplexity: 20.890625\n",
            "Number of samples evaluated: 2710, Average perplexity: 20.6875\n",
            "Number of samples evaluated: 2720, Average perplexity: 20.4375\n",
            "Number of samples evaluated: 2730, Average perplexity: 20.203125\n",
            "Number of samples evaluated: 2740, Average perplexity: 20.046875\n",
            "Number of samples evaluated: 2750, Average perplexity: 19.84375\n",
            "Number of samples evaluated: 2760, Average perplexity: 19.625\n",
            "Number of samples evaluated: 2770, Average perplexity: 19.421875\n",
            "Number of samples evaluated: 2780, Average perplexity: 19.203125\n",
            "Number of samples evaluated: 2790, Average perplexity: 19.015625\n",
            "Number of samples evaluated: 2800, Average perplexity: 18.796875\n",
            "Number of samples evaluated: 2810, Average perplexity: 18.609375\n",
            "Number of samples evaluated: 2820, Average perplexity: 18.4375\n",
            "Number of samples evaluated: 2830, Average perplexity: 18.21875\n",
            "Number of samples evaluated: 2840, Average perplexity: 18.046875\n",
            "Number of samples evaluated: 2850, Average perplexity: 17.859375\n",
            "Number of samples evaluated: 2860, Average perplexity: 17.71875\n",
            "Number of samples evaluated: 2870, Average perplexity: 17.546875\n",
            "Number of samples evaluated: 2880, Average perplexity: 17.421875\n",
            "Number of samples evaluated: 2890, Average perplexity: 17.25\n",
            "Number of samples evaluated: 2900, Average perplexity: 17.078125\n",
            "Number of samples evaluated: 2910, Average perplexity: 16.90625\n",
            "Number of samples evaluated: 2920, Average perplexity: 16.75\n",
            "Number of samples evaluated: 2930, Average perplexity: 16.59375\n",
            "Number of samples evaluated: 2940, Average perplexity: 16.453125\n",
            "Number of samples evaluated: 2950, Average perplexity: 16.296875\n",
            "Number of samples evaluated: 2960, Average perplexity: 16.140625\n",
            "Number of samples evaluated: 2970, Average perplexity: 16.015625\n",
            "Number of samples evaluated: 2980, Average perplexity: 15.890625\n",
            "Number of samples evaluated: 2990, Average perplexity: 15.734375\n",
            "Number of samples evaluated: 3000, Average perplexity: 15.578125\n",
            "Number of samples evaluated: 3010, Average perplexity: 15.4609375\n",
            "Number of samples evaluated: 3020, Average perplexity: 15.34375\n",
            "Number of samples evaluated: 3030, Average perplexity: 15.21875\n",
            "Number of samples evaluated: 3040, Average perplexity: 15.0703125\n",
            "Number of samples evaluated: 3050, Average perplexity: 14.953125\n",
            "Number of samples evaluated: 3060, Average perplexity: 14.8125\n",
            "Number of samples evaluated: 3070, Average perplexity: 14.6953125\n",
            "Number of samples evaluated: 3080, Average perplexity: 14.5546875\n",
            "Number of samples evaluated: 3090, Average perplexity: 14.4375\n",
            "Number of samples evaluated: 3100, Average perplexity: 14.3515625\n",
            "Number of samples evaluated: 3110, Average perplexity: 14.21875\n",
            "Number of samples evaluated: 3120, Average perplexity: 14.1015625\n",
            "Number of samples evaluated: 3130, Average perplexity: 13.9921875\n",
            "Number of samples evaluated: 3140, Average perplexity: 13.859375\n",
            "Number of samples evaluated: 3150, Average perplexity: 13.75\n",
            "Number of samples evaluated: 3160, Average perplexity: 13.640625\n",
            "Number of samples evaluated: 3170, Average perplexity: 13.5078125\n",
            "Number of samples evaluated: 3180, Average perplexity: 13.40625\n",
            "Number of samples evaluated: 3190, Average perplexity: 13.3046875\n",
            "Number of samples evaluated: 3200, Average perplexity: 13.1953125\n",
            "Number of samples evaluated: 3210, Average perplexity: 13.09375\n",
            "Number of samples evaluated: 3220, Average perplexity: 12.9921875\n",
            "Number of samples evaluated: 3230, Average perplexity: 12.890625\n",
            "Number of samples evaluated: 3240, Average perplexity: 12.8203125\n",
            "Number of samples evaluated: 3250, Average perplexity: 12.71875\n",
            "Number of samples evaluated: 3260, Average perplexity: 12.6171875\n",
            "Number of samples evaluated: 3270, Average perplexity: 12.5234375\n",
            "Number of samples evaluated: 3280, Average perplexity: 12.421875\n",
            "Number of samples evaluated: 3290, Average perplexity: 12.3515625\n",
            "Number of samples evaluated: 3300, Average perplexity: 12.2578125\n",
            "Number of samples evaluated: 3310, Average perplexity: 12.1796875\n",
            "Number of samples evaluated: 3320, Average perplexity: 12.0859375\n",
            "Number of samples evaluated: 3330, Average perplexity: 11.9921875\n",
            "Number of samples evaluated: 3340, Average perplexity: 11.8984375\n",
            "Number of samples evaluated: 3350, Average perplexity: 11.8046875\n",
            "Number of samples evaluated: 3360, Average perplexity: 11.71875\n",
            "Number of samples evaluated: 3370, Average perplexity: 11.6484375\n",
            "Number of samples evaluated: 3380, Average perplexity: 11.5546875\n",
            "Number of samples evaluated: 3390, Average perplexity: 11.46875\n",
            "Number of samples evaluated: 3400, Average perplexity: 11.3984375\n",
            "Number of samples evaluated: 3410, Average perplexity: 11.3125\n",
            "Number of samples evaluated: 3420, Average perplexity: 11.2265625\n",
            "Number of samples evaluated: 3430, Average perplexity: 11.15625\n",
            "Number of samples evaluated: 3440, Average perplexity: 11.0703125\n",
            "Number of samples evaluated: 3450, Average perplexity: 11.0078125\n",
            "Number of samples evaluated: 3460, Average perplexity: 10.921875\n",
            "Number of samples evaluated: 3470, Average perplexity: 10.859375\n",
            "Number of samples evaluated: 3480, Average perplexity: 10.7734375\n",
            "Number of samples evaluated: 3490, Average perplexity: 10.7109375\n",
            "Number of samples evaluated: 3500, Average perplexity: 10.625\n",
            "Number of samples evaluated: 3510, Average perplexity: 10.5625\n",
            "Number of samples evaluated: 3520, Average perplexity: 10.484375\n",
            "Number of samples evaluated: 3530, Average perplexity: 10.421875\n",
            "Number of samples evaluated: 3540, Average perplexity: 10.3359375\n",
            "Number of samples evaluated: 3550, Average perplexity: 10.28125\n",
            "Number of samples evaluated: 3560, Average perplexity: 10.21875\n",
            "Number of samples evaluated: 3570, Average perplexity: 10.140625\n",
            "Number of samples evaluated: 3580, Average perplexity: 10.078125\n",
            "Number of samples evaluated: 3590, Average perplexity: 10.0234375\n",
            "Number of samples evaluated: 3600, Average perplexity: 9.9453125\n",
            "Number of samples evaluated: 3610, Average perplexity: 9.8828125\n",
            "Number of samples evaluated: 3620, Average perplexity: 9.828125\n",
            "Number of samples evaluated: 3630, Average perplexity: 9.7734375\n",
            "Number of samples evaluated: 3640, Average perplexity: 9.7109375\n",
            "Number of samples evaluated: 3650, Average perplexity: 9.640625\n",
            "Number of samples evaluated: 3660, Average perplexity: 9.578125\n",
            "Number of samples evaluated: 3670, Average perplexity: 9.5234375\n",
            "Number of samples evaluated: 3680, Average perplexity: 9.46875\n",
            "Number of samples evaluated: 3690, Average perplexity: 9.4296875\n",
            "Number of samples evaluated: 3700, Average perplexity: 9.375\n",
            "Number of samples evaluated: 3710, Average perplexity: 9.3203125\n",
            "Number of samples evaluated: 3720, Average perplexity: 9.265625\n",
            "Number of samples evaluated: 3730, Average perplexity: 9.2109375\n",
            "Number of samples evaluated: 3740, Average perplexity: 9.15625\n",
            "Number of samples evaluated: 3750, Average perplexity: 9.0859375\n",
            "Number of samples evaluated: 3760, Average perplexity: 9.0390625\n",
            "Number of samples evaluated: 3770, Average perplexity: 8.984375\n",
            "Number of samples evaluated: 3780, Average perplexity: 8.9453125\n",
            "Number of samples evaluated: 3790, Average perplexity: 8.9140625\n",
            "Number of samples evaluated: 3800, Average perplexity: 8.859375\n",
            "Number of samples evaluated: 3810, Average perplexity: 8.8125\n",
            "Number of samples evaluated: 3820, Average perplexity: 8.7578125\n",
            "Number of samples evaluated: 3830, Average perplexity: 8.703125\n",
            "Number of samples evaluated: 3840, Average perplexity: 8.65625\n",
            "Number of samples evaluated: 3850, Average perplexity: 8.6015625\n",
            "Number of samples evaluated: 3860, Average perplexity: 8.5546875\n",
            "Number of samples evaluated: 3870, Average perplexity: 8.5234375\n",
            "Number of samples evaluated: 3880, Average perplexity: 8.46875\n",
            "Number of samples evaluated: 3890, Average perplexity: 8.421875\n",
            "Number of samples evaluated: 3900, Average perplexity: 8.375\n",
            "Number of samples evaluated: 3910, Average perplexity: 8.3203125\n",
            "Number of samples evaluated: 3920, Average perplexity: 8.2890625\n",
            "Number of samples evaluated: 3930, Average perplexity: 8.2421875\n",
            "Number of samples evaluated: 3940, Average perplexity: 8.1953125\n",
            "Number of samples evaluated: 3950, Average perplexity: 8.1484375\n",
            "Number of samples evaluated: 3960, Average perplexity: 8.1171875\n",
            "Number of samples evaluated: 3970, Average perplexity: 8.0703125\n",
            "Number of samples evaluated: 3980, Average perplexity: 8.0234375\n",
            "Number of samples evaluated: 3990, Average perplexity: 7.98828125\n",
            "Number of samples evaluated: 4000, Average perplexity: 7.94140625\n",
            "Number of samples evaluated: 4010, Average perplexity: 7.89453125\n",
            "Number of samples evaluated: 4020, Average perplexity: 7.8671875\n",
            "Number of samples evaluated: 4030, Average perplexity: 7.8203125\n",
            "Number of samples evaluated: 4040, Average perplexity: 7.7734375\n",
            "Number of samples evaluated: 4050, Average perplexity: 7.7578125\n",
            "Number of samples evaluated: 4060, Average perplexity: 7.71484375\n",
            "Number of samples evaluated: 4070, Average perplexity: 7.68359375\n",
            "Number of samples evaluated: 4080, Average perplexity: 7.63671875\n",
            "Number of samples evaluated: 4090, Average perplexity: 7.609375\n",
            "Number of samples evaluated: 4100, Average perplexity: 7.578125\n",
            "Number of samples evaluated: 4110, Average perplexity: 7.53515625\n",
            "Number of samples evaluated: 4120, Average perplexity: 7.50390625\n",
            "Number of samples evaluated: 4130, Average perplexity: 7.4609375\n",
            "Number of samples evaluated: 4140, Average perplexity: 7.43359375\n",
            "Number of samples evaluated: 4150, Average perplexity: 7.390625\n",
            "Number of samples evaluated: 4160, Average perplexity: 7.359375\n",
            "Number of samples evaluated: 4170, Average perplexity: 7.33984375\n",
            "Number of samples evaluated: 4180, Average perplexity: 7.3046875\n",
            "Number of samples evaluated: 4190, Average perplexity: 7.265625\n",
            "Number of samples evaluated: 4200, Average perplexity: 7.23828125\n",
            "Number of samples evaluated: 4210, Average perplexity: 7.203125\n",
            "Number of samples evaluated: 4220, Average perplexity: 7.16796875\n",
            "Number of samples evaluated: 4230, Average perplexity: 7.1328125\n",
            "Number of samples evaluated: 4240, Average perplexity: 7.09765625\n",
            "Number of samples evaluated: 4250, Average perplexity: 7.0703125\n",
            "Number of samples evaluated: 4260, Average perplexity: 7.03515625\n",
            "Number of samples evaluated: 4270, Average perplexity: 7.00390625\n",
            "Number of samples evaluated: 4280, Average perplexity: 6.9765625\n",
            "Number of samples evaluated: 4290, Average perplexity: 6.953125\n",
            "Number of samples evaluated: 4300, Average perplexity: 6.921875\n",
            "Number of samples evaluated: 4310, Average perplexity: 6.89453125\n",
            "Number of samples evaluated: 4320, Average perplexity: 6.859375\n",
            "Number of samples evaluated: 4330, Average perplexity: 6.83203125\n",
            "Number of samples evaluated: 4340, Average perplexity: 6.80078125\n",
            "Number of samples evaluated: 4350, Average perplexity: 6.7734375\n",
            "Number of samples evaluated: 4360, Average perplexity: 6.7421875\n",
            "Number of samples evaluated: 4370, Average perplexity: 6.71484375\n",
            "Number of samples evaluated: 4380, Average perplexity: 6.68359375\n",
            "Number of samples evaluated: 4390, Average perplexity: 6.65625\n",
            "Number of samples evaluated: 4400, Average perplexity: 6.625\n",
            "Number of samples evaluated: 4410, Average perplexity: 6.609375\n",
            "Number of samples evaluated: 4420, Average perplexity: 6.58984375\n",
            "Number of samples evaluated: 4430, Average perplexity: 6.56640625\n",
            "Number of samples evaluated: 4440, Average perplexity: 6.5390625\n",
            "Number of samples evaluated: 4450, Average perplexity: 6.5078125\n",
            "Number of samples evaluated: 4460, Average perplexity: 6.484375\n",
            "Number of samples evaluated: 4470, Average perplexity: 6.45703125\n",
            "Number of samples evaluated: 4480, Average perplexity: 6.42578125\n",
            "Number of samples evaluated: 4490, Average perplexity: 6.40234375\n",
            "Number of samples evaluated: 4500, Average perplexity: 6.375\n",
            "Number of samples evaluated: 4510, Average perplexity: 6.3515625\n",
            "Number of samples evaluated: 4520, Average perplexity: 6.33203125\n",
            "Number of samples evaluated: 4530, Average perplexity: 6.3203125\n",
            "Number of samples evaluated: 4540, Average perplexity: 6.296875\n",
            "Number of samples evaluated: 4550, Average perplexity: 6.26953125\n",
            "Number of samples evaluated: 4560, Average perplexity: 6.24609375\n",
            "Number of samples evaluated: 4570, Average perplexity: 6.21484375\n",
            "Number of samples evaluated: 4580, Average perplexity: 6.19140625\n",
            "Number of samples evaluated: 4590, Average perplexity: 6.16796875\n",
            "Number of samples evaluated: 4600, Average perplexity: 6.14453125\n",
            "Number of samples evaluated: 4610, Average perplexity: 6.12109375\n",
            "Number of samples evaluated: 4620, Average perplexity: 6.09765625\n",
            "Number of samples evaluated: 4630, Average perplexity: 6.0703125\n",
            "Number of samples evaluated: 4640, Average perplexity: 6.046875\n",
            "Number of samples evaluated: 4650, Average perplexity: 6.0234375\n",
            "Number of samples evaluated: 4660, Average perplexity: 6.0\n",
            "Number of samples evaluated: 4670, Average perplexity: 5.9765625\n",
            "Number of samples evaluated: 4680, Average perplexity: 5.953125\n",
            "Number of samples evaluated: 4690, Average perplexity: 5.9375\n",
            "Number of samples evaluated: 4700, Average perplexity: 5.91796875\n",
            "Number of samples evaluated: 4710, Average perplexity: 5.91015625\n",
            "Number of samples evaluated: 4720, Average perplexity: 5.88671875\n",
            "Number of samples evaluated: 4730, Average perplexity: 5.8671875\n",
            "Number of samples evaluated: 4740, Average perplexity: 5.84375\n",
            "Number of samples evaluated: 4750, Average perplexity: 5.82421875\n",
            "Number of samples evaluated: 4760, Average perplexity: 5.80078125\n",
            "Number of samples evaluated: 4770, Average perplexity: 5.77734375\n",
            "Number of samples evaluated: 4780, Average perplexity: 5.765625\n",
            "Number of samples evaluated: 4790, Average perplexity: 5.75\n",
            "Number of samples evaluated: 4800, Average perplexity: 5.7265625\n",
            "Number of samples evaluated: 4810, Average perplexity: 5.703125\n",
            "Number of samples evaluated: 4820, Average perplexity: 5.68359375\n",
            "Number of samples evaluated: 4830, Average perplexity: 5.6640625\n",
            "Number of samples evaluated: 4840, Average perplexity: 5.64453125\n",
            "Number of samples evaluated: 4850, Average perplexity: 5.62109375\n",
            "Number of samples evaluated: 4860, Average perplexity: 5.60546875\n",
            "Number of samples evaluated: 4870, Average perplexity: 5.58203125\n",
            "Number of samples evaluated: 4880, Average perplexity: 5.56640625\n",
            "Number of samples evaluated: 4890, Average perplexity: 5.546875\n",
            "Number of samples evaluated: 4900, Average perplexity: 5.53515625\n",
            "Number of samples evaluated: 4910, Average perplexity: 5.51953125\n",
            "Number of samples evaluated: 4920, Average perplexity: 5.49609375\n",
            "Number of samples evaluated: 4930, Average perplexity: 5.4765625\n",
            "Number of samples evaluated: 4940, Average perplexity: 5.4609375\n",
            "Number of samples evaluated: 4950, Average perplexity: 5.4375\n",
            "Number of samples evaluated: 4960, Average perplexity: 5.421875\n",
            "Number of samples evaluated: 4970, Average perplexity: 5.40234375\n",
            "Number of samples evaluated: 4980, Average perplexity: 5.38671875\n",
            "Number of samples evaluated: 4990, Average perplexity: 5.375\n",
            "Number of samples evaluated: 5000, Average perplexity: 5.359375\n",
            "Number of samples evaluated: 5010, Average perplexity: 5.3359375\n",
            "Number of samples evaluated: 5020, Average perplexity: 5.3203125\n",
            "Number of samples evaluated: 5030, Average perplexity: 5.30078125\n",
            "Number of samples evaluated: 5040, Average perplexity: 5.28515625\n",
            "Number of samples evaluated: 5050, Average perplexity: 5.26953125\n",
            "Number of samples evaluated: 5060, Average perplexity: 5.25\n",
            "Number of samples evaluated: 5070, Average perplexity: 5.234375\n",
            "Number of samples evaluated: 5080, Average perplexity: 5.21875\n",
            "Number of samples evaluated: 5090, Average perplexity: 5.19921875\n",
            "Number of samples evaluated: 5100, Average perplexity: 5.18359375\n",
            "Number of samples evaluated: 5110, Average perplexity: 5.16796875\n",
            "Number of samples evaluated: 5120, Average perplexity: 5.1484375\n",
            "Number of samples evaluated: 5130, Average perplexity: 5.1328125\n",
            "Number of samples evaluated: 5140, Average perplexity: 5.1171875\n",
            "Number of samples evaluated: 5150, Average perplexity: 5.1015625\n",
            "Number of samples evaluated: 5160, Average perplexity: 5.08203125\n",
            "Number of samples evaluated: 5170, Average perplexity: 5.0703125\n",
            "Number of samples evaluated: 5180, Average perplexity: 5.0546875\n",
            "Number of samples evaluated: 5190, Average perplexity: 5.0390625\n",
            "Number of samples evaluated: 5200, Average perplexity: 5.0234375\n",
            "Number of samples evaluated: 5210, Average perplexity: 5.00390625\n",
            "Number of samples evaluated: 5220, Average perplexity: 4.98828125\n",
            "Number of samples evaluated: 5230, Average perplexity: 4.9765625\n",
            "Number of samples evaluated: 5240, Average perplexity: 4.9609375\n",
            "Number of samples evaluated: 5250, Average perplexity: 4.9453125\n",
            "Number of samples evaluated: 5260, Average perplexity: 4.93359375\n",
            "Number of samples evaluated: 5270, Average perplexity: 4.91796875\n",
            "Number of samples evaluated: 5280, Average perplexity: 4.90234375\n",
            "Number of samples evaluated: 5290, Average perplexity: 4.8828125\n",
            "Number of samples evaluated: 5300, Average perplexity: 4.87890625\n",
            "Number of samples evaluated: 5310, Average perplexity: 4.86328125\n",
            "Number of samples evaluated: 5320, Average perplexity: 4.8515625\n",
            "Number of samples evaluated: 5330, Average perplexity: 4.8359375\n",
            "Number of samples evaluated: 5340, Average perplexity: 4.8203125\n",
            "Number of samples evaluated: 5350, Average perplexity: 4.80859375\n",
            "Number of samples evaluated: 5360, Average perplexity: 4.79296875\n",
            "Number of samples evaluated: 5370, Average perplexity: 4.78125\n",
            "Number of samples evaluated: 5380, Average perplexity: 4.76953125\n",
            "Number of samples evaluated: 5390, Average perplexity: 4.7578125\n",
            "Number of samples evaluated: 5400, Average perplexity: 4.7421875\n",
            "Number of samples evaluated: 5410, Average perplexity: 4.73046875\n",
            "Number of samples evaluated: 5420, Average perplexity: 4.71875\n",
            "Number of samples evaluated: 5430, Average perplexity: 4.70703125\n",
            "Number of samples evaluated: 5440, Average perplexity: 4.69140625\n",
            "Number of samples evaluated: 5450, Average perplexity: 4.6796875\n",
            "Number of samples evaluated: 5460, Average perplexity: 4.6640625\n",
            "Number of samples evaluated: 5470, Average perplexity: 4.65234375\n",
            "Number of samples evaluated: 5480, Average perplexity: 4.63671875\n",
            "Number of samples evaluated: 5490, Average perplexity: 4.625\n",
            "Number of samples evaluated: 5500, Average perplexity: 4.609375\n",
            "Number of samples evaluated: 5510, Average perplexity: 4.6015625\n",
            "Number of samples evaluated: 5520, Average perplexity: 4.58984375\n",
            "Number of samples evaluated: 5530, Average perplexity: 4.57421875\n",
            "Number of samples evaluated: 5540, Average perplexity: 4.5625\n",
            "Number of samples evaluated: 5550, Average perplexity: 4.546875\n",
            "Number of samples evaluated: 5560, Average perplexity: 4.5390625\n",
            "Number of samples evaluated: 5570, Average perplexity: 4.52734375\n",
            "Number of samples evaluated: 5580, Average perplexity: 4.51171875\n",
            "Number of samples evaluated: 5590, Average perplexity: 4.5078125\n",
            "Number of samples evaluated: 5600, Average perplexity: 4.49609375\n",
            "Number of samples evaluated: 5610, Average perplexity: 4.4921875\n",
            "Number of samples evaluated: 5620, Average perplexity: 4.4765625\n",
            "Number of samples evaluated: 5630, Average perplexity: 4.46484375\n",
            "Number of samples evaluated: 5640, Average perplexity: 4.44921875\n",
            "Number of samples evaluated: 5650, Average perplexity: 4.44140625\n",
            "Number of samples evaluated: 5660, Average perplexity: 4.4296875\n",
            "Number of samples evaluated: 5670, Average perplexity: 4.41796875\n",
            "Number of samples evaluated: 5680, Average perplexity: 4.40625\n",
            "Number of samples evaluated: 5690, Average perplexity: 4.39453125\n",
            "Number of samples evaluated: 5700, Average perplexity: 4.3828125\n",
            "Number of samples evaluated: 5710, Average perplexity: 4.375\n",
            "Number of samples evaluated: 5720, Average perplexity: 4.359375\n",
            "Number of samples evaluated: 5730, Average perplexity: 4.34765625\n",
            "Number of samples evaluated: 5740, Average perplexity: 4.33984375\n",
            "Number of samples evaluated: 5750, Average perplexity: 4.328125\n",
            "Number of samples evaluated: 5760, Average perplexity: 4.3203125\n",
            "Number of samples evaluated: 5770, Average perplexity: 4.30859375\n",
            "Number of samples evaluated: 5780, Average perplexity: 4.30078125\n",
            "Number of samples evaluated: 5790, Average perplexity: 4.2890625\n",
            "Number of samples evaluated: 5800, Average perplexity: 4.28125\n",
            "Number of samples evaluated: 5810, Average perplexity: 4.26953125\n",
            "Number of samples evaluated: 5820, Average perplexity: 4.26171875\n",
            "Number of samples evaluated: 5830, Average perplexity: 4.24609375\n",
            "Number of samples evaluated: 5840, Average perplexity: 4.234375\n",
            "Number of samples evaluated: 5850, Average perplexity: 4.2265625\n",
            "Number of samples evaluated: 5860, Average perplexity: 4.21484375\n",
            "Number of samples evaluated: 5870, Average perplexity: 4.20703125\n",
            "Number of samples evaluated: 5880, Average perplexity: 4.1953125\n",
            "Number of samples evaluated: 5890, Average perplexity: 4.1875\n",
            "Number of samples evaluated: 5900, Average perplexity: 4.171875\n",
            "Number of samples evaluated: 5910, Average perplexity: 4.1640625\n",
            "Number of samples evaluated: 5920, Average perplexity: 4.15625\n",
            "Number of samples evaluated: 5930, Average perplexity: 4.14453125\n",
            "Number of samples evaluated: 5940, Average perplexity: 4.140625\n",
            "Number of samples evaluated: 5950, Average perplexity: 4.1328125\n",
            "Number of samples evaluated: 5960, Average perplexity: 4.12109375\n",
            "Number of samples evaluated: 5970, Average perplexity: 4.11328125\n",
            "Number of samples evaluated: 5980, Average perplexity: 4.109375\n",
            "Number of samples evaluated: 5990, Average perplexity: 4.09765625\n",
            "Number of samples evaluated: 6000, Average perplexity: 4.08984375\n",
            "Number of samples evaluated: 6010, Average perplexity: 4.0859375\n",
            "Number of samples evaluated: 6020, Average perplexity: 4.07421875\n",
            "Number of samples evaluated: 6030, Average perplexity: 4.06640625\n",
            "Number of samples evaluated: 6040, Average perplexity: 4.05859375\n",
            "Number of samples evaluated: 6050, Average perplexity: 4.04296875\n",
            "Number of samples evaluated: 6060, Average perplexity: 4.03515625\n",
            "Number of samples evaluated: 6070, Average perplexity: 4.02734375\n",
            "Number of samples evaluated: 6080, Average perplexity: 4.015625\n",
            "Number of samples evaluated: 6090, Average perplexity: 4.0078125\n",
            "Number of samples evaluated: 6100, Average perplexity: 3.998046875\n",
            "Number of samples evaluated: 6110, Average perplexity: 3.990234375\n",
            "Number of samples evaluated: 6120, Average perplexity: 3.982421875\n",
            "Number of samples evaluated: 6130, Average perplexity: 3.974609375\n",
            "Number of samples evaluated: 6140, Average perplexity: 3.962890625\n",
            "Number of samples evaluated: 6150, Average perplexity: 3.958984375\n",
            "Number of samples evaluated: 6160, Average perplexity: 3.951171875\n",
            "Number of samples evaluated: 6170, Average perplexity: 3.943359375\n",
            "Number of samples evaluated: 6180, Average perplexity: 3.931640625\n",
            "Number of samples evaluated: 6190, Average perplexity: 3.923828125\n",
            "Number of samples evaluated: 6200, Average perplexity: 3.916015625\n",
            "Number of samples evaluated: 6210, Average perplexity: 3.908203125\n",
            "Number of samples evaluated: 6220, Average perplexity: 3.8984375\n",
            "Number of samples evaluated: 6230, Average perplexity: 3.890625\n",
            "Number of samples evaluated: 6240, Average perplexity: 3.8828125\n",
            "Number of samples evaluated: 6250, Average perplexity: 3.875\n",
            "Number of samples evaluated: 6260, Average perplexity: 3.8671875\n",
            "Number of samples evaluated: 6270, Average perplexity: 3.85546875\n",
            "Number of samples evaluated: 6280, Average perplexity: 3.84765625\n",
            "Number of samples evaluated: 6290, Average perplexity: 3.841796875\n",
            "Number of samples evaluated: 6300, Average perplexity: 3.833984375\n",
            "Number of samples evaluated: 6310, Average perplexity: 3.826171875\n",
            "Number of samples evaluated: 6320, Average perplexity: 3.822265625\n",
            "Number of samples evaluated: 6330, Average perplexity: 3.814453125\n",
            "Number of samples evaluated: 6340, Average perplexity: 3.802734375\n",
            "Number of samples evaluated: 6350, Average perplexity: 3.80078125\n",
            "Number of samples evaluated: 6360, Average perplexity: 3.79296875\n",
            "Number of samples evaluated: 6370, Average perplexity: 3.7890625\n",
            "Number of samples evaluated: 6380, Average perplexity: 3.7890625\n",
            "Number of samples evaluated: 6390, Average perplexity: 3.77734375\n",
            "Number of samples evaluated: 6400, Average perplexity: 3.76953125\n",
            "Number of samples evaluated: 6410, Average perplexity: 3.763671875\n",
            "Number of samples evaluated: 6420, Average perplexity: 3.755859375\n",
            "Number of samples evaluated: 6430, Average perplexity: 3.751953125\n",
            "Number of samples evaluated: 6440, Average perplexity: 3.744140625\n",
            "Number of samples evaluated: 6450, Average perplexity: 3.736328125\n",
            "Number of samples evaluated: 6460, Average perplexity: 3.734375\n",
            "Number of samples evaluated: 6470, Average perplexity: 3.7265625\n",
            "Number of samples evaluated: 6480, Average perplexity: 3.72265625\n",
            "Number of samples evaluated: 6490, Average perplexity: 3.71484375\n",
            "Number of samples evaluated: 6500, Average perplexity: 3.708984375\n",
            "Number of samples evaluated: 6510, Average perplexity: 3.701171875\n",
            "Number of samples evaluated: 6520, Average perplexity: 3.693359375\n",
            "Number of samples evaluated: 6530, Average perplexity: 3.6875\n",
            "Number of samples evaluated: 6540, Average perplexity: 3.6796875\n",
            "Number of samples evaluated: 6550, Average perplexity: 3.671875\n",
            "Number of samples evaluated: 6560, Average perplexity: 3.6640625\n",
            "Number of samples evaluated: 6570, Average perplexity: 3.658203125\n",
            "Number of samples evaluated: 6580, Average perplexity: 3.650390625\n",
            "Number of samples evaluated: 6590, Average perplexity: 3.64453125\n",
            "Number of samples evaluated: 6600, Average perplexity: 3.63671875\n",
            "Number of samples evaluated: 6610, Average perplexity: 3.62890625\n",
            "Number of samples evaluated: 6620, Average perplexity: 3.623046875\n",
            "Number of samples evaluated: 6630, Average perplexity: 3.615234375\n",
            "Number of samples evaluated: 6640, Average perplexity: 3.607421875\n",
            "Number of samples evaluated: 6650, Average perplexity: 3.6015625\n",
            "Number of samples evaluated: 6660, Average perplexity: 3.59375\n",
            "Number of samples evaluated: 6670, Average perplexity: 3.587890625\n",
            "Number of samples evaluated: 6680, Average perplexity: 3.580078125\n",
            "Number of samples evaluated: 6690, Average perplexity: 3.572265625\n",
            "Number of samples evaluated: 6700, Average perplexity: 3.56640625\n",
            "Number of samples evaluated: 6710, Average perplexity: 3.55859375\n",
            "Number of samples evaluated: 6720, Average perplexity: 3.552734375\n",
            "Number of samples evaluated: 6730, Average perplexity: 3.544921875\n",
            "Number of samples evaluated: 6740, Average perplexity: 3.544921875\n",
            "Number of samples evaluated: 6750, Average perplexity: 3.5390625\n",
            "Number of samples evaluated: 6760, Average perplexity: 3.53125\n",
            "Number of samples evaluated: 6770, Average perplexity: 3.525390625\n",
            "Number of samples evaluated: 6780, Average perplexity: 3.517578125\n",
            "Number of samples evaluated: 6790, Average perplexity: 3.513671875\n",
            "Number of samples evaluated: 6800, Average perplexity: 3.5078125\n",
            "Number of samples evaluated: 6810, Average perplexity: 3.50390625\n",
            "Number of samples evaluated: 6820, Average perplexity: 3.498046875\n",
            "Number of samples evaluated: 6830, Average perplexity: 3.494140625\n",
            "Number of samples evaluated: 6840, Average perplexity: 3.486328125\n",
            "Number of samples evaluated: 6850, Average perplexity: 3.48046875\n",
            "Number of samples evaluated: 6860, Average perplexity: 3.48046875\n",
            "Number of samples evaluated: 6870, Average perplexity: 3.47265625\n",
            "Number of samples evaluated: 6880, Average perplexity: 3.466796875\n",
            "Number of samples evaluated: 6890, Average perplexity: 3.458984375\n",
            "Number of samples evaluated: 6900, Average perplexity: 3.453125\n",
            "Number of samples evaluated: 6910, Average perplexity: 3.447265625\n",
            "Number of samples evaluated: 6920, Average perplexity: 3.447265625\n",
            "Number of samples evaluated: 6930, Average perplexity: 3.439453125\n",
            "Number of samples evaluated: 6940, Average perplexity: 3.43359375\n",
            "Number of samples evaluated: 6950, Average perplexity: 3.42578125\n",
            "Number of samples evaluated: 6960, Average perplexity: 3.419921875\n",
            "Number of samples evaluated: 6970, Average perplexity: 3.416015625\n",
            "Number of samples evaluated: 6980, Average perplexity: 3.41015625\n",
            "Number of samples evaluated: 6990, Average perplexity: 3.40234375\n",
            "Number of samples evaluated: 7000, Average perplexity: 3.396484375\n",
            "Number of samples evaluated: 7010, Average perplexity: 3.388671875\n",
            "Number of samples evaluated: 7020, Average perplexity: 3.38671875\n",
            "Number of samples evaluated: 7030, Average perplexity: 3.37890625\n",
            "Number of samples evaluated: 7040, Average perplexity: 3.373046875\n",
            "Number of samples evaluated: 7050, Average perplexity: 3.3671875\n",
            "Number of samples evaluated: 7060, Average perplexity: 3.36328125\n",
            "Number of samples evaluated: 7070, Average perplexity: 3.357421875\n",
            "Number of samples evaluated: 7080, Average perplexity: 3.349609375\n",
            "Number of samples evaluated: 7090, Average perplexity: 3.34375\n",
            "Number of samples evaluated: 7100, Average perplexity: 3.33984375\n",
            "Number of samples evaluated: 7110, Average perplexity: 3.333984375\n",
            "Number of samples evaluated: 7120, Average perplexity: 3.328125\n",
            "Number of samples evaluated: 7130, Average perplexity: 3.3203125\n",
            "Number of samples evaluated: 7140, Average perplexity: 3.318359375\n",
            "Number of samples evaluated: 7150, Average perplexity: 3.310546875\n",
            "Number of samples evaluated: 7160, Average perplexity: 3.30859375\n",
            "Number of samples evaluated: 7170, Average perplexity: 3.3046875\n",
            "Number of samples evaluated: 7180, Average perplexity: 3.298828125\n",
            "Number of samples evaluated: 7190, Average perplexity: 3.291015625\n",
            "Number of samples evaluated: 7200, Average perplexity: 3.2890625\n",
            "Number of samples evaluated: 7210, Average perplexity: 3.28125\n",
            "Number of samples evaluated: 7220, Average perplexity: 3.275390625\n",
            "Number of samples evaluated: 7230, Average perplexity: 3.2734375\n",
            "Number of samples evaluated: 7240, Average perplexity: 3.265625\n",
            "Number of samples evaluated: 7250, Average perplexity: 3.259765625\n",
            "Number of samples evaluated: 7260, Average perplexity: 3.25390625\n",
            "Number of samples evaluated: 7270, Average perplexity: 3.25390625\n",
            "Number of samples evaluated: 7280, Average perplexity: 3.24609375\n",
            "Number of samples evaluated: 7290, Average perplexity: 3.244140625\n",
            "Number of samples evaluated: 7300, Average perplexity: 3.23828125\n",
            "Number of samples evaluated: 7310, Average perplexity: 3.23046875\n",
            "Number of samples evaluated: 7320, Average perplexity: 3.228515625\n",
            "Number of samples evaluated: 7330, Average perplexity: 3.22265625\n",
            "Number of samples evaluated: 7340, Average perplexity: 3.22265625\n",
            "Number of samples evaluated: 7350, Average perplexity: 3.21484375\n",
            "Number of samples evaluated: 7360, Average perplexity: 3.208984375\n",
            "Number of samples evaluated: 7370, Average perplexity: 3.212890625\n",
            "Number of samples evaluated: 7380, Average perplexity: 3.205078125\n",
            "Number of samples evaluated: 7390, Average perplexity: 3.203125\n",
            "Number of samples evaluated: 7400, Average perplexity: 3.197265625\n",
            "Number of samples evaluated: 7410, Average perplexity: 3.197265625\n",
            "Number of samples evaluated: 7420, Average perplexity: 3.19140625\n",
            "Number of samples evaluated: 7430, Average perplexity: 3.18359375\n",
            "Number of samples evaluated: 7440, Average perplexity: 3.181640625\n",
            "Number of samples evaluated: 7450, Average perplexity: 3.177734375\n",
            "Number of samples evaluated: 7460, Average perplexity: 3.17578125\n",
            "Number of samples evaluated: 7470, Average perplexity: 3.16796875\n",
            "Number of samples evaluated: 7480, Average perplexity: 3.16796875\n",
            "Number of samples evaluated: 7490, Average perplexity: 3.162109375\n",
            "Number of samples evaluated: 7500, Average perplexity: 3.15625\n",
            "Number of samples evaluated: 7510, Average perplexity: 3.15234375\n",
            "Number of samples evaluated: 7520, Average perplexity: 3.146484375\n",
            "Number of samples evaluated: 7530, Average perplexity: 3.14453125\n",
            "Number of samples evaluated: 7540, Average perplexity: 3.140625\n",
            "Number of samples evaluated: 7550, Average perplexity: 3.138671875\n",
            "Number of samples evaluated: 7560, Average perplexity: 3.130859375\n",
            "Number of samples evaluated: 7570, Average perplexity: 3.12890625\n",
            "Number of samples evaluated: 7580, Average perplexity: 3.123046875\n",
            "Number of samples evaluated: 7590, Average perplexity: 3.119140625\n",
            "Number of samples evaluated: 7600, Average perplexity: 3.11328125\n",
            "Number of samples evaluated: 7610, Average perplexity: 3.111328125\n",
            "Number of samples evaluated: 7620, Average perplexity: 3.103515625\n",
            "Number of samples evaluated: 7630, Average perplexity: 3.09765625\n",
            "Number of samples evaluated: 7640, Average perplexity: 3.095703125\n",
            "Number of samples evaluated: 7650, Average perplexity: 3.08984375\n",
            "Number of samples evaluated: 7660, Average perplexity: 3.0859375\n",
            "Number of samples evaluated: 7670, Average perplexity: 3.080078125\n",
            "Number of samples evaluated: 7680, Average perplexity: 3.080078125\n",
            "Number of samples evaluated: 7690, Average perplexity: 3.078125\n",
            "Number of samples evaluated: 7700, Average perplexity: 3.0703125\n",
            "Number of samples evaluated: 7710, Average perplexity: 3.068359375\n",
            "Number of samples evaluated: 7720, Average perplexity: 3.0625\n",
            "Number of samples evaluated: 7730, Average perplexity: 3.05859375\n",
            "Number of samples evaluated: 7740, Average perplexity: 3.052734375\n",
            "Number of samples evaluated: 7750, Average perplexity: 3.05078125\n",
            "Number of samples evaluated: 7760, Average perplexity: 3.044921875\n",
            "Number of samples evaluated: 7770, Average perplexity: 3.044921875\n",
            "Number of samples evaluated: 7780, Average perplexity: 3.0390625\n",
            "Number of samples evaluated: 7790, Average perplexity: 3.03515625\n",
            "Number of samples evaluated: 7800, Average perplexity: 3.033203125\n",
            "Number of samples evaluated: 7810, Average perplexity: 3.029296875\n",
            "Number of samples evaluated: 7820, Average perplexity: 3.0234375\n",
            "Number of samples evaluated: 7830, Average perplexity: 3.021484375\n",
            "Number of samples evaluated: 7840, Average perplexity: 3.017578125\n",
            "Number of samples evaluated: 7850, Average perplexity: 3.01171875\n",
            "Number of samples evaluated: 7860, Average perplexity: 3.009765625\n",
            "Number of samples evaluated: 7870, Average perplexity: 3.00390625\n",
            "Number of samples evaluated: 7880, Average perplexity: 3.0\n",
            "Number of samples evaluated: 7890, Average perplexity: 2.998046875\n",
            "Number of samples evaluated: 7900, Average perplexity: 2.994140625\n",
            "Number of samples evaluated: 7910, Average perplexity: 2.9921875\n",
            "Number of samples evaluated: 7920, Average perplexity: 2.986328125\n",
            "Number of samples evaluated: 7930, Average perplexity: 2.982421875\n",
            "Number of samples evaluated: 7940, Average perplexity: 2.9765625\n",
            "Number of samples evaluated: 7950, Average perplexity: 2.974609375\n",
            "Number of samples evaluated: 7960, Average perplexity: 2.970703125\n",
            "Number of samples evaluated: 7970, Average perplexity: 2.96484375\n",
            "Number of samples evaluated: 7980, Average perplexity: 2.962890625\n",
            "Number of samples evaluated: 7990, Average perplexity: 2.95703125\n",
            "Number of samples evaluated: 8000, Average perplexity: 2.953125\n",
            "Number of samples evaluated: 8010, Average perplexity: 2.951171875\n",
            "Number of samples evaluated: 8020, Average perplexity: 2.9453125\n",
            "Number of samples evaluated: 8030, Average perplexity: 2.94140625\n",
            "Number of samples evaluated: 8040, Average perplexity: 2.935546875\n",
            "Number of samples evaluated: 8050, Average perplexity: 2.93359375\n",
            "Number of samples evaluated: 8060, Average perplexity: 2.9296875\n",
            "Number of samples evaluated: 8070, Average perplexity: 2.92578125\n",
            "Number of samples evaluated: 8080, Average perplexity: 2.921875\n",
            "Number of samples evaluated: 8090, Average perplexity: 2.919921875\n",
            "Number of samples evaluated: 8100, Average perplexity: 2.916015625\n",
            "Number of samples evaluated: 8110, Average perplexity: 2.9140625\n",
            "Number of samples evaluated: 8120, Average perplexity: 2.91015625\n",
            "Number of samples evaluated: 8130, Average perplexity: 2.904296875\n",
            "Number of samples evaluated: 8140, Average perplexity: 2.90234375\n",
            "Number of samples evaluated: 8150, Average perplexity: 2.8984375\n",
            "Number of samples evaluated: 8160, Average perplexity: 2.89453125\n",
            "Number of samples evaluated: 8170, Average perplexity: 2.89453125\n",
            "Number of samples evaluated: 8180, Average perplexity: 2.890625\n",
            "Number of samples evaluated: 8190, Average perplexity: 2.884765625\n",
            "Number of samples evaluated: 8200, Average perplexity: 2.8828125\n",
            "Number of samples evaluated: 8210, Average perplexity: 2.87890625\n",
            "Number of samples evaluated: 8220, Average perplexity: 2.873046875\n",
            "Number of samples evaluated: 8230, Average perplexity: 2.87109375\n",
            "Number of samples evaluated: 8240, Average perplexity: 2.87109375\n",
            "Number of samples evaluated: 8250, Average perplexity: 2.865234375\n",
            "Number of samples evaluated: 8260, Average perplexity: 2.86328125\n",
            "Number of samples evaluated: 8270, Average perplexity: 2.859375\n",
            "Number of samples evaluated: 8280, Average perplexity: 2.853515625\n",
            "Number of samples evaluated: 8290, Average perplexity: 2.8515625\n",
            "Number of samples evaluated: 8300, Average perplexity: 2.849609375\n",
            "Number of samples evaluated: 8310, Average perplexity: 2.845703125\n",
            "Number of samples evaluated: 8320, Average perplexity: 2.83984375\n",
            "Number of samples evaluated: 8330, Average perplexity: 2.837890625\n",
            "Number of samples evaluated: 8340, Average perplexity: 2.837890625\n",
            "Number of samples evaluated: 8350, Average perplexity: 2.83203125\n",
            "Number of samples evaluated: 8360, Average perplexity: 2.830078125\n",
            "Number of samples evaluated: 8370, Average perplexity: 2.826171875\n",
            "Number of samples evaluated: 8380, Average perplexity: 2.82421875\n",
            "Number of samples evaluated: 8390, Average perplexity: 2.818359375\n",
            "Number of samples evaluated: 8400, Average perplexity: 2.81640625\n",
            "Number of samples evaluated: 8410, Average perplexity: 2.8125\n",
            "Number of samples evaluated: 8420, Average perplexity: 2.810546875\n",
            "Number of samples evaluated: 8430, Average perplexity: 2.806640625\n",
            "Number of samples evaluated: 8440, Average perplexity: 2.8046875\n",
            "Number of samples evaluated: 8450, Average perplexity: 2.802734375\n",
            "Number of samples evaluated: 8460, Average perplexity: 2.798828125\n",
            "Number of samples evaluated: 8470, Average perplexity: 2.79296875\n",
            "Number of samples evaluated: 8480, Average perplexity: 2.791015625\n",
            "Number of samples evaluated: 8490, Average perplexity: 2.7890625\n",
            "Number of samples evaluated: 8500, Average perplexity: 2.78515625\n",
            "Number of samples evaluated: 8510, Average perplexity: 2.779296875\n",
            "Number of samples evaluated: 8520, Average perplexity: 2.77734375\n",
            "Number of samples evaluated: 8530, Average perplexity: 2.775390625\n",
            "Number of samples evaluated: 8540, Average perplexity: 2.771484375\n",
            "Number of samples evaluated: 8550, Average perplexity: 2.765625\n",
            "Number of samples evaluated: 8560, Average perplexity: 2.763671875\n",
            "Number of samples evaluated: 8570, Average perplexity: 2.76171875\n",
            "Number of samples evaluated: 8580, Average perplexity: 2.7578125\n",
            "Number of samples evaluated: 8590, Average perplexity: 2.755859375\n",
            "Number of samples evaluated: 8600, Average perplexity: 2.75\n",
            "Number of samples evaluated: 8610, Average perplexity: 2.748046875\n",
            "Number of samples evaluated: 8620, Average perplexity: 2.744140625\n",
            "Number of samples evaluated: 8630, Average perplexity: 2.7421875\n",
            "Number of samples evaluated: 8640, Average perplexity: 2.740234375\n",
            "Number of samples evaluated: 8650, Average perplexity: 2.734375\n",
            "Number of samples evaluated: 8660, Average perplexity: 2.732421875\n",
            "Number of samples evaluated: 8670, Average perplexity: 2.728515625\n",
            "Number of samples evaluated: 8680, Average perplexity: 2.7265625\n",
            "Number of samples evaluated: 8690, Average perplexity: 2.72265625\n",
            "Number of samples evaluated: 8700, Average perplexity: 2.71875\n",
            "Number of samples evaluated: 8710, Average perplexity: 2.716796875\n",
            "Number of samples evaluated: 8720, Average perplexity: 2.712890625\n",
            "Number of samples evaluated: 8730, Average perplexity: 2.7109375\n",
            "Number of samples evaluated: 8740, Average perplexity: 2.70703125\n",
            "Number of samples evaluated: 8750, Average perplexity: 2.703125\n",
            "Number of samples evaluated: 8760, Average perplexity: 2.701171875\n",
            "Number of samples evaluated: 8770, Average perplexity: 2.69921875\n",
            "Number of samples evaluated: 8780, Average perplexity: 2.6953125\n",
            "Number of samples evaluated: 8790, Average perplexity: 2.69140625\n",
            "Number of samples evaluated: 8800, Average perplexity: 2.689453125\n",
            "Number of samples evaluated: 8810, Average perplexity: 2.685546875\n",
            "Number of samples evaluated: 8820, Average perplexity: 2.68359375\n",
            "Number of samples evaluated: 8830, Average perplexity: 2.6796875\n",
            "Number of samples evaluated: 8840, Average perplexity: 2.6796875\n",
            "Number of samples evaluated: 8850, Average perplexity: 2.67578125\n",
            "Number of samples evaluated: 8860, Average perplexity: 2.673828125\n",
            "Number of samples evaluated: 8870, Average perplexity: 2.671875\n",
            "Number of samples evaluated: 8880, Average perplexity: 2.66796875\n",
            "Number of samples evaluated: 8890, Average perplexity: 2.6640625\n",
            "Number of samples evaluated: 8900, Average perplexity: 2.662109375\n",
            "Number of samples evaluated: 8910, Average perplexity: 2.658203125\n",
            "Number of samples evaluated: 8920, Average perplexity: 2.65625\n",
            "Number of samples evaluated: 8930, Average perplexity: 2.65234375\n",
            "Number of samples evaluated: 8940, Average perplexity: 2.650390625\n",
            "Number of samples evaluated: 8950, Average perplexity: 2.6484375\n",
            "Number of samples evaluated: 8960, Average perplexity: 2.64453125\n",
            "Number of samples evaluated: 8970, Average perplexity: 2.640625\n",
            "Number of samples evaluated: 8980, Average perplexity: 2.638671875\n",
            "Number of samples evaluated: 8990, Average perplexity: 2.63671875\n",
            "Number of samples evaluated: 9000, Average perplexity: 2.6328125\n",
            "Number of samples evaluated: 9010, Average perplexity: 2.62890625\n",
            "Number of samples evaluated: 9020, Average perplexity: 2.626953125\n",
            "Number of samples evaluated: 9030, Average perplexity: 2.625\n",
            "Number of samples evaluated: 9040, Average perplexity: 2.62109375\n",
            "Number of samples evaluated: 9050, Average perplexity: 2.619140625\n",
            "Number of samples evaluated: 9060, Average perplexity: 2.615234375\n",
            "Number of samples evaluated: 9070, Average perplexity: 2.61328125\n",
            "Number of samples evaluated: 9080, Average perplexity: 2.609375\n",
            "Number of samples evaluated: 9090, Average perplexity: 2.607421875\n",
            "Number of samples evaluated: 9100, Average perplexity: 2.60546875\n",
            "Number of samples evaluated: 9110, Average perplexity: 2.603515625\n",
            "Number of samples evaluated: 9120, Average perplexity: 2.599609375\n",
            "Number of samples evaluated: 9130, Average perplexity: 2.595703125\n",
            "Number of samples evaluated: 9140, Average perplexity: 2.59375\n",
            "Number of samples evaluated: 9150, Average perplexity: 2.591796875\n",
            "Number of samples evaluated: 9160, Average perplexity: 2.587890625\n",
            "Number of samples evaluated: 9170, Average perplexity: 2.5859375\n",
            "Number of samples evaluated: 9180, Average perplexity: 2.583984375\n",
            "Number of samples evaluated: 9190, Average perplexity: 2.580078125\n",
            "Number of samples evaluated: 9200, Average perplexity: 2.578125\n",
            "Number of samples evaluated: 9210, Average perplexity: 2.580078125\n",
            "Number of samples evaluated: 9220, Average perplexity: 2.578125\n",
            "Number of samples evaluated: 9230, Average perplexity: 2.57421875\n",
            "Number of samples evaluated: 9240, Average perplexity: 2.572265625\n",
            "Number of samples evaluated: 9250, Average perplexity: 2.568359375\n",
            "Number of samples evaluated: 9260, Average perplexity: 2.568359375\n",
            "Number of samples evaluated: 9270, Average perplexity: 2.568359375\n",
            "Number of samples evaluated: 9280, Average perplexity: 2.56640625\n",
            "Number of samples evaluated: 9290, Average perplexity: 2.564453125\n",
            "Number of samples evaluated: 9300, Average perplexity: 2.560546875\n",
            "Number of samples evaluated: 9310, Average perplexity: 2.556640625\n",
            "Number of samples evaluated: 9320, Average perplexity: 2.5546875\n",
            "Number of samples evaluated: 9330, Average perplexity: 2.552734375\n",
            "Number of samples evaluated: 9340, Average perplexity: 2.55078125\n",
            "Number of samples evaluated: 9350, Average perplexity: 2.546875\n",
            "Number of samples evaluated: 9360, Average perplexity: 2.546875\n",
            "Number of samples evaluated: 9370, Average perplexity: 2.544921875\n",
            "Number of samples evaluated: 9380, Average perplexity: 2.54296875\n",
            "Number of samples evaluated: 9390, Average perplexity: 2.5390625\n",
            "Number of samples evaluated: 9400, Average perplexity: 2.5390625\n",
            "Number of samples evaluated: 9410, Average perplexity: 2.537109375\n",
            "Number of samples evaluated: 9420, Average perplexity: 2.53515625\n",
            "Number of samples evaluated: 9430, Average perplexity: 2.53125\n",
            "Number of samples evaluated: 9440, Average perplexity: 2.53125\n",
            "Number of samples evaluated: 9450, Average perplexity: 2.529296875\n",
            "Number of samples evaluated: 9460, Average perplexity: 2.529296875\n",
            "Number of samples evaluated: 9470, Average perplexity: 2.529296875\n",
            "Number of samples evaluated: 9480, Average perplexity: 2.525390625\n",
            "Number of samples evaluated: 9490, Average perplexity: 2.5234375\n",
            "Number of samples evaluated: 9500, Average perplexity: 2.521484375\n",
            "Number of samples evaluated: 9510, Average perplexity: 2.51953125\n",
            "Number of samples evaluated: 9520, Average perplexity: 2.515625\n",
            "Number of samples evaluated: 9530, Average perplexity: 2.513671875\n",
            "Number of samples evaluated: 9540, Average perplexity: 2.51171875\n",
            "Number of samples evaluated: 9550, Average perplexity: 2.509765625\n",
            "Number of samples evaluated: 9560, Average perplexity: 2.505859375\n",
            "Number of samples evaluated: 9570, Average perplexity: 2.50390625\n",
            "Number of samples evaluated: 9580, Average perplexity: 2.50390625\n",
            "Number of samples evaluated: 9590, Average perplexity: 2.501953125\n",
            "Number of samples evaluated: 9600, Average perplexity: 2.5\n",
            "Number of samples evaluated: 9610, Average perplexity: 2.49609375\n",
            "Number of samples evaluated: 9620, Average perplexity: 2.494140625\n",
            "Number of samples evaluated: 9630, Average perplexity: 2.4921875\n",
            "Number of samples evaluated: 9640, Average perplexity: 2.490234375\n",
            "Number of samples evaluated: 9650, Average perplexity: 2.486328125\n",
            "Number of samples evaluated: 9660, Average perplexity: 2.484375\n",
            "Number of samples evaluated: 9670, Average perplexity: 2.482421875\n",
            "Number of samples evaluated: 9680, Average perplexity: 2.48046875\n",
            "Number of samples evaluated: 9690, Average perplexity: 2.4765625\n",
            "Number of samples evaluated: 9700, Average perplexity: 2.474609375\n",
            "Number of samples evaluated: 9710, Average perplexity: 2.47265625\n",
            "Number of samples evaluated: 9720, Average perplexity: 2.470703125\n",
            "Number of samples evaluated: 9730, Average perplexity: 2.46875\n",
            "Number of samples evaluated: 9740, Average perplexity: 2.466796875\n",
            "Number of samples evaluated: 9750, Average perplexity: 2.46484375\n",
            "Number of samples evaluated: 9760, Average perplexity: 2.4609375\n",
            "Number of samples evaluated: 9770, Average perplexity: 2.458984375\n",
            "Number of samples evaluated: 9780, Average perplexity: 2.45703125\n",
            "Number of samples evaluated: 9790, Average perplexity: 2.455078125\n",
            "Number of samples evaluated: 9800, Average perplexity: 2.453125\n",
            "Number of samples evaluated: 9810, Average perplexity: 2.44921875\n",
            "Number of samples evaluated: 9820, Average perplexity: 2.44921875\n",
            "Number of samples evaluated: 9830, Average perplexity: 2.447265625\n",
            "Number of samples evaluated: 9840, Average perplexity: 2.4453125\n",
            "Number of samples evaluated: 9850, Average perplexity: 2.443359375\n",
            "Number of samples evaluated: 9860, Average perplexity: 2.44140625\n",
            "Number of samples evaluated: 9870, Average perplexity: 2.439453125\n",
            "Number of samples evaluated: 9880, Average perplexity: 2.4375\n",
            "Number of samples evaluated: 9890, Average perplexity: 2.43359375\n",
            "Number of samples evaluated: 9900, Average perplexity: 2.431640625\n",
            "Number of samples evaluated: 9910, Average perplexity: 2.431640625\n",
            "Number of samples evaluated: 9920, Average perplexity: 2.427734375\n",
            "Number of samples evaluated: 9930, Average perplexity: 2.42578125\n",
            "Number of samples evaluated: 9940, Average perplexity: 2.423828125\n",
            "Number of samples evaluated: 9950, Average perplexity: 2.421875\n",
            "Number of samples evaluated: 9960, Average perplexity: 2.41796875\n",
            "Number of samples evaluated: 9970, Average perplexity: 2.41796875\n",
            "Number of samples evaluated: 9980, Average perplexity: 2.416015625\n",
            "Number of samples evaluated: 9990, Average perplexity: 2.412109375\n",
            "Number of samples evaluated: 10000, Average perplexity: 2.41015625\n",
            "Number of samples evaluated: 10010, Average perplexity: 2.408203125\n",
            "Number of samples evaluated: 10020, Average perplexity: 2.40625\n",
            "Number of samples evaluated: 10030, Average perplexity: 2.404296875\n",
            "Number of samples evaluated: 10040, Average perplexity: 2.40234375\n",
            "Number of samples evaluated: 10050, Average perplexity: 2.400390625\n",
            "Number of samples evaluated: 10060, Average perplexity: 2.3984375\n",
            "Number of samples evaluated: 10070, Average perplexity: 2.400390625\n",
            "Number of samples evaluated: 10080, Average perplexity: 2.3984375\n",
            "Number of samples evaluated: 10090, Average perplexity: 2.39453125\n",
            "Number of samples evaluated: 10100, Average perplexity: 2.39453125\n",
            "Number of samples evaluated: 10110, Average perplexity: 2.392578125\n",
            "Number of samples evaluated: 10120, Average perplexity: 2.392578125\n",
            "Number of samples evaluated: 10130, Average perplexity: 2.388671875\n",
            "Number of samples evaluated: 10140, Average perplexity: 2.38671875\n",
            "Number of samples evaluated: 10150, Average perplexity: 2.384765625\n",
            "Number of samples evaluated: 10160, Average perplexity: 2.384765625\n",
            "Number of samples evaluated: 10170, Average perplexity: 2.3828125\n",
            "Number of samples evaluated: 10180, Average perplexity: 2.380859375\n",
            "Number of samples evaluated: 10190, Average perplexity: 2.37890625\n",
            "Number of samples evaluated: 10200, Average perplexity: 2.376953125\n",
            "Number of samples evaluated: 10210, Average perplexity: 2.375\n",
            "Number of samples evaluated: 10220, Average perplexity: 2.375\n",
            "Number of samples evaluated: 10230, Average perplexity: 2.373046875\n",
            "Number of samples evaluated: 10240, Average perplexity: 2.37109375\n",
            "Number of samples evaluated: 10250, Average perplexity: 2.369140625\n",
            "Number of samples evaluated: 10260, Average perplexity: 2.3671875\n",
            "Number of samples evaluated: 10270, Average perplexity: 2.365234375\n",
            "Number of samples evaluated: 10280, Average perplexity: 2.36328125\n",
            "Number of samples evaluated: 10290, Average perplexity: 2.361328125\n",
            "Number of samples evaluated: 10300, Average perplexity: 2.359375\n",
            "Number of samples evaluated: 10310, Average perplexity: 2.357421875\n",
            "Number of samples evaluated: 10320, Average perplexity: 2.35546875\n",
            "Number of samples evaluated: 10330, Average perplexity: 2.353515625\n",
            "Number of samples evaluated: 10340, Average perplexity: 2.3515625\n",
            "Number of samples evaluated: 10350, Average perplexity: 2.349609375\n",
            "Number of samples evaluated: 10360, Average perplexity: 2.34765625\n",
            "Number of samples evaluated: 10370, Average perplexity: 2.345703125\n",
            "Number of samples evaluated: 10380, Average perplexity: 2.34375\n",
            "Number of samples evaluated: 10390, Average perplexity: 2.341796875\n",
            "Number of samples evaluated: 10400, Average perplexity: 2.33984375\n",
            "Number of samples evaluated: 10410, Average perplexity: 2.33984375\n",
            "Number of samples evaluated: 10420, Average perplexity: 2.33984375\n",
            "Number of samples evaluated: 10430, Average perplexity: 2.337890625\n",
            "Number of samples evaluated: 10440, Average perplexity: 2.3359375\n",
            "Number of samples evaluated: 10450, Average perplexity: 2.333984375\n",
            "Number of samples evaluated: 10460, Average perplexity: 2.33203125\n",
            "Number of samples evaluated: 10470, Average perplexity: 2.330078125\n",
            "Number of samples evaluated: 10480, Average perplexity: 2.328125\n",
            "Number of samples evaluated: 10490, Average perplexity: 2.326171875\n",
            "Number of samples evaluated: 10500, Average perplexity: 2.32421875\n",
            "Number of samples evaluated: 10510, Average perplexity: 2.322265625\n",
            "Number of samples evaluated: 10520, Average perplexity: 2.3203125\n",
            "Number of samples evaluated: 10530, Average perplexity: 2.318359375\n",
            "Number of samples evaluated: 10540, Average perplexity: 2.31640625\n",
            "Number of samples evaluated: 10550, Average perplexity: 2.314453125\n",
            "Number of samples evaluated: 10560, Average perplexity: 2.314453125\n",
            "Number of samples evaluated: 10570, Average perplexity: 2.310546875\n",
            "Number of samples evaluated: 10580, Average perplexity: 2.30859375\n",
            "Number of samples evaluated: 10590, Average perplexity: 2.30859375\n",
            "Number of samples evaluated: 10600, Average perplexity: 2.306640625\n",
            "Number of samples evaluated: 10610, Average perplexity: 2.302734375\n",
            "Number of samples evaluated: 10620, Average perplexity: 2.302734375\n",
            "Number of samples evaluated: 10630, Average perplexity: 2.30078125\n",
            "Number of samples evaluated: 10640, Average perplexity: 2.298828125\n",
            "Number of samples evaluated: 10650, Average perplexity: 2.296875\n",
            "Number of samples evaluated: 10660, Average perplexity: 2.294921875\n",
            "Number of samples evaluated: 10670, Average perplexity: 2.29296875\n",
            "Number of samples evaluated: 10680, Average perplexity: 2.291015625\n",
            "Number of samples evaluated: 10690, Average perplexity: 2.291015625\n",
            "Number of samples evaluated: 10700, Average perplexity: 2.287109375\n",
            "Number of samples evaluated: 10710, Average perplexity: 2.28515625\n",
            "Number of samples evaluated: 10720, Average perplexity: 2.28515625\n",
            "Number of samples evaluated: 10730, Average perplexity: 2.283203125\n",
            "Number of samples evaluated: 10740, Average perplexity: 2.28125\n",
            "Number of samples evaluated: 10750, Average perplexity: 2.28125\n",
            "Number of samples evaluated: 10760, Average perplexity: 2.279296875\n",
            "Number of samples evaluated: 10770, Average perplexity: 2.27734375\n",
            "Number of samples evaluated: 10780, Average perplexity: 2.275390625\n",
            "Number of samples evaluated: 10790, Average perplexity: 2.2734375\n",
            "Number of samples evaluated: 10800, Average perplexity: 2.271484375\n",
            "Number of samples evaluated: 10810, Average perplexity: 2.26953125\n",
            "Number of samples evaluated: 10820, Average perplexity: 2.26953125\n",
            "Number of samples evaluated: 10830, Average perplexity: 2.26953125\n",
            "Number of samples evaluated: 10840, Average perplexity: 2.267578125\n",
            "Number of samples evaluated: 10850, Average perplexity: 2.265625\n",
            "Number of samples evaluated: 10860, Average perplexity: 2.263671875\n",
            "Number of samples evaluated: 10870, Average perplexity: 2.26171875\n",
            "Number of samples evaluated: 10880, Average perplexity: 2.259765625\n",
            "Number of samples evaluated: 10890, Average perplexity: 2.2578125\n",
            "Number of samples evaluated: 10900, Average perplexity: 2.2578125\n",
            "Number of samples evaluated: 10910, Average perplexity: 2.25390625\n",
            "Number of samples evaluated: 10920, Average perplexity: 2.25390625\n",
            "Number of samples evaluated: 10930, Average perplexity: 2.251953125\n",
            "Number of samples evaluated: 10940, Average perplexity: 2.25\n",
            "Number of samples evaluated: 10950, Average perplexity: 2.248046875\n",
            "Number of samples evaluated: 10960, Average perplexity: 2.24609375\n",
            "Number of samples evaluated: 10970, Average perplexity: 2.24609375\n",
            "Number of samples evaluated: 10980, Average perplexity: 2.244140625\n",
            "Number of samples evaluated: 10990, Average perplexity: 2.244140625\n",
            "Number of samples evaluated: 11000, Average perplexity: 2.2421875\n",
            "Number of samples evaluated: 11010, Average perplexity: 2.240234375\n",
            "Number of samples evaluated: 11020, Average perplexity: 2.240234375\n",
            "Number of samples evaluated: 11030, Average perplexity: 2.23828125\n",
            "Number of samples evaluated: 11040, Average perplexity: 2.236328125\n",
            "Number of samples evaluated: 11050, Average perplexity: 2.234375\n",
            "Number of samples evaluated: 11060, Average perplexity: 2.234375\n",
            "Number of samples evaluated: 11070, Average perplexity: 2.232421875\n",
            "Number of samples evaluated: 11080, Average perplexity: 2.23046875\n",
            "Number of samples evaluated: 11090, Average perplexity: 2.228515625\n",
            "Number of samples evaluated: 11100, Average perplexity: 2.2265625\n",
            "Number of samples evaluated: 11110, Average perplexity: 2.224609375\n",
            "Number of samples evaluated: 11120, Average perplexity: 2.224609375\n",
            "Number of samples evaluated: 11130, Average perplexity: 2.22265625\n",
            "Number of samples evaluated: 11140, Average perplexity: 2.220703125\n",
            "Number of samples evaluated: 11150, Average perplexity: 2.21875\n",
            "Number of samples evaluated: 11160, Average perplexity: 2.216796875\n",
            "Number of samples evaluated: 11170, Average perplexity: 2.216796875\n",
            "Number of samples evaluated: 11180, Average perplexity: 2.21484375\n",
            "Number of samples evaluated: 11190, Average perplexity: 2.212890625\n",
            "Number of samples evaluated: 11200, Average perplexity: 2.2109375\n",
            "Number of samples evaluated: 11210, Average perplexity: 2.208984375\n",
            "Number of samples evaluated: 11220, Average perplexity: 2.20703125\n",
            "Number of samples evaluated: 11230, Average perplexity: 2.20703125\n",
            "Number of samples evaluated: 11240, Average perplexity: 2.205078125\n",
            "Number of samples evaluated: 11250, Average perplexity: 2.203125\n",
            "Number of samples evaluated: 11260, Average perplexity: 2.203125\n",
            "Number of samples evaluated: 11270, Average perplexity: 2.201171875\n",
            "Number of samples evaluated: 11280, Average perplexity: 2.19921875\n",
            "Number of samples evaluated: 11290, Average perplexity: 2.197265625\n",
            "Number of samples evaluated: 11300, Average perplexity: 2.1953125\n",
            "Number of samples evaluated: 11310, Average perplexity: 2.193359375\n",
            "Number of samples evaluated: 11320, Average perplexity: 2.193359375\n",
            "Number of samples evaluated: 11330, Average perplexity: 2.19140625\n",
            "Number of samples evaluated: 11340, Average perplexity: 2.189453125\n",
            "Number of samples evaluated: 11350, Average perplexity: 2.1875\n",
            "Number of samples evaluated: 11360, Average perplexity: 2.185546875\n",
            "Number of samples evaluated: 11370, Average perplexity: 2.185546875\n",
            "Number of samples evaluated: 11380, Average perplexity: 2.18359375\n",
            "Number of samples evaluated: 11390, Average perplexity: 2.181640625\n",
            "Number of samples evaluated: 11400, Average perplexity: 2.181640625\n",
            "Number of samples evaluated: 11410, Average perplexity: 2.1796875\n",
            "Number of samples evaluated: 11420, Average perplexity: 2.177734375\n",
            "Number of samples evaluated: 11430, Average perplexity: 2.17578125\n",
            "Number of samples evaluated: 11440, Average perplexity: 2.173828125\n",
            "Number of samples evaluated: 11450, Average perplexity: 2.173828125\n",
            "Number of samples evaluated: 11460, Average perplexity: 2.171875\n",
            "Number of samples evaluated: 11470, Average perplexity: 2.171875\n",
            "Number of samples evaluated: 11480, Average perplexity: 2.169921875\n",
            "Number of samples evaluated: 11490, Average perplexity: 2.169921875\n",
            "Number of samples evaluated: 11500, Average perplexity: 2.16796875\n",
            "Number of samples evaluated: 11510, Average perplexity: 2.166015625\n",
            "Number of samples evaluated: 11520, Average perplexity: 2.166015625\n",
            "Number of samples evaluated: 11530, Average perplexity: 2.162109375\n",
            "Number of samples evaluated: 11540, Average perplexity: 2.162109375\n",
            "Number of samples evaluated: 11550, Average perplexity: 2.16015625\n",
            "Number of samples evaluated: 11560, Average perplexity: 2.16015625\n",
            "Number of samples evaluated: 11570, Average perplexity: 2.158203125\n",
            "Number of samples evaluated: 11580, Average perplexity: 2.158203125\n",
            "Number of samples evaluated: 11590, Average perplexity: 2.15625\n",
            "Number of samples evaluated: 11600, Average perplexity: 2.154296875\n",
            "Number of samples evaluated: 11610, Average perplexity: 2.154296875\n",
            "Number of samples evaluated: 11620, Average perplexity: 2.15234375\n",
            "Number of samples evaluated: 11630, Average perplexity: 2.150390625\n",
            "Number of samples evaluated: 11640, Average perplexity: 2.150390625\n",
            "Number of samples evaluated: 11650, Average perplexity: 2.1484375\n",
            "Number of samples evaluated: 11660, Average perplexity: 2.1484375\n",
            "Number of samples evaluated: 11670, Average perplexity: 2.146484375\n",
            "Number of samples evaluated: 11680, Average perplexity: 2.146484375\n",
            "Number of samples evaluated: 11690, Average perplexity: 2.14453125\n",
            "Number of samples evaluated: 11700, Average perplexity: 2.142578125\n",
            "Number of samples evaluated: 11710, Average perplexity: 2.142578125\n",
            "Number of samples evaluated: 11720, Average perplexity: 2.140625\n",
            "Number of samples evaluated: 11730, Average perplexity: 2.140625\n",
            "Number of samples evaluated: 11740, Average perplexity: 2.138671875\n",
            "Number of samples evaluated: 11750, Average perplexity: 2.138671875\n",
            "Number of samples evaluated: 11760, Average perplexity: 2.13671875\n",
            "Number of samples evaluated: 11770, Average perplexity: 2.134765625\n",
            "Number of samples evaluated: 11780, Average perplexity: 2.1328125\n",
            "Number of samples evaluated: 11790, Average perplexity: 2.1328125\n",
            "Number of samples evaluated: 11800, Average perplexity: 2.1328125\n",
            "Number of samples evaluated: 11810, Average perplexity: 2.130859375\n",
            "Number of samples evaluated: 11820, Average perplexity: 2.12890625\n",
            "Number of samples evaluated: 11830, Average perplexity: 2.12890625\n",
            "Number of samples evaluated: 11840, Average perplexity: 2.126953125\n",
            "Number of samples evaluated: 11850, Average perplexity: 2.126953125\n",
            "Number of samples evaluated: 11860, Average perplexity: 2.125\n",
            "Number of samples evaluated: 11870, Average perplexity: 2.125\n",
            "Number of samples evaluated: 11880, Average perplexity: 2.125\n",
            "Number of samples evaluated: 11890, Average perplexity: 2.123046875\n",
            "Number of samples evaluated: 11900, Average perplexity: 2.123046875\n",
            "Number of samples evaluated: 11910, Average perplexity: 2.119140625\n",
            "Number of samples evaluated: 11920, Average perplexity: 2.119140625\n",
            "Number of samples evaluated: 11930, Average perplexity: 2.119140625\n",
            "Number of samples evaluated: 11940, Average perplexity: 2.1171875\n",
            "Number of samples evaluated: 11950, Average perplexity: 2.1171875\n",
            "Number of samples evaluated: 11960, Average perplexity: 2.115234375\n",
            "Number of samples evaluated: 11970, Average perplexity: 2.11328125\n",
            "Number of samples evaluated: 11980, Average perplexity: 2.11328125\n",
            "Number of samples evaluated: 11990, Average perplexity: 2.11328125\n",
            "Number of samples evaluated: 12000, Average perplexity: 2.111328125\n",
            "Number of samples evaluated: 12010, Average perplexity: 2.109375\n",
            "Number of samples evaluated: 12020, Average perplexity: 2.109375\n",
            "Number of samples evaluated: 12030, Average perplexity: 2.107421875\n",
            "Number of samples evaluated: 12040, Average perplexity: 2.10546875\n",
            "Number of samples evaluated: 12050, Average perplexity: 2.10546875\n",
            "Number of samples evaluated: 12060, Average perplexity: 2.103515625\n",
            "Number of samples evaluated: 12070, Average perplexity: 2.103515625\n",
            "Number of samples evaluated: 12080, Average perplexity: 2.099609375\n",
            "Number of samples evaluated: 12090, Average perplexity: 2.099609375\n",
            "Number of samples evaluated: 12100, Average perplexity: 2.09765625\n",
            "Number of samples evaluated: 12110, Average perplexity: 2.09765625\n",
            "Number of samples evaluated: 12120, Average perplexity: 2.095703125\n",
            "Number of samples evaluated: 12130, Average perplexity: 2.09375\n",
            "Number of samples evaluated: 12140, Average perplexity: 2.09375\n",
            "Number of samples evaluated: 12150, Average perplexity: 2.09375\n",
            "Number of samples evaluated: 12160, Average perplexity: 2.091796875\n",
            "Number of samples evaluated: 12170, Average perplexity: 2.091796875\n",
            "Number of samples evaluated: 12180, Average perplexity: 2.08984375\n",
            "Number of samples evaluated: 12190, Average perplexity: 2.087890625\n",
            "Number of samples evaluated: 12200, Average perplexity: 2.087890625\n",
            "Number of samples evaluated: 12210, Average perplexity: 2.0859375\n",
            "Number of samples evaluated: 12220, Average perplexity: 2.083984375\n",
            "Number of samples evaluated: 12230, Average perplexity: 2.083984375\n",
            "Number of samples evaluated: 12240, Average perplexity: 2.08203125\n",
            "Number of samples evaluated: 12250, Average perplexity: 2.08203125\n",
            "Number of samples evaluated: 12260, Average perplexity: 2.078125\n",
            "Number of samples evaluated: 12270, Average perplexity: 2.078125\n",
            "Number of samples evaluated: 12280, Average perplexity: 2.076171875\n",
            "Number of samples evaluated: 12290, Average perplexity: 2.076171875\n",
            "Number of samples evaluated: 12300, Average perplexity: 2.076171875\n",
            "Number of samples evaluated: 12310, Average perplexity: 2.07421875\n",
            "Number of samples evaluated: 12320, Average perplexity: 2.072265625\n",
            "Number of samples evaluated: 12330, Average perplexity: 2.072265625\n",
            "Number of samples evaluated: 12340, Average perplexity: 2.0703125\n",
            "Number of samples evaluated: 12350, Average perplexity: 2.0703125\n",
            "Number of samples evaluated: 12360, Average perplexity: 2.0703125\n",
            "Number of samples evaluated: 12370, Average perplexity: 2.068359375\n",
            "Number of samples evaluated: 12380, Average perplexity: 2.068359375\n",
            "Number of samples evaluated: 12390, Average perplexity: 2.06640625\n",
            "Number of samples evaluated: 12400, Average perplexity: 2.064453125\n",
            "Number of samples evaluated: 12410, Average perplexity: 2.064453125\n",
            "Number of samples evaluated: 12420, Average perplexity: 2.0625\n",
            "Number of samples evaluated: 12430, Average perplexity: 2.0625\n",
            "Number of samples evaluated: 12440, Average perplexity: 2.060546875\n",
            "Number of samples evaluated: 12450, Average perplexity: 2.05859375\n",
            "Number of samples evaluated: 12460, Average perplexity: 2.05859375\n",
            "Number of samples evaluated: 12470, Average perplexity: 2.056640625\n",
            "Number of samples evaluated: 12480, Average perplexity: 2.056640625\n",
            "Number of samples evaluated: 12490, Average perplexity: 2.0546875\n",
            "Number of samples evaluated: 12500, Average perplexity: 2.0546875\n",
            "Number of samples evaluated: 12510, Average perplexity: 2.052734375\n",
            "Number of samples evaluated: 12520, Average perplexity: 2.052734375\n",
            "Number of samples evaluated: 12530, Average perplexity: 2.05078125\n",
            "Number of samples evaluated: 12540, Average perplexity: 2.05078125\n",
            "Number of samples evaluated: 12550, Average perplexity: 2.05078125\n",
            "Number of samples evaluated: 12560, Average perplexity: 2.048828125\n",
            "Number of samples evaluated: 12570, Average perplexity: 2.048828125\n",
            "Number of samples evaluated: 12580, Average perplexity: 2.044921875\n",
            "Number of samples evaluated: 12590, Average perplexity: 2.044921875\n",
            "Number of samples evaluated: 12600, Average perplexity: 2.04296875\n",
            "Number of samples evaluated: 12610, Average perplexity: 2.04296875\n",
            "Number of samples evaluated: 12620, Average perplexity: 2.04296875\n",
            "Number of samples evaluated: 12630, Average perplexity: 2.041015625\n",
            "Number of samples evaluated: 12640, Average perplexity: 2.041015625\n",
            "Number of samples evaluated: 12650, Average perplexity: 2.0390625\n",
            "Number of samples evaluated: 12660, Average perplexity: 2.0390625\n",
            "Number of samples evaluated: 12670, Average perplexity: 2.0390625\n",
            "Number of samples evaluated: 12680, Average perplexity: 2.037109375\n",
            "Number of samples evaluated: 12690, Average perplexity: 2.03515625\n",
            "Number of samples evaluated: 12700, Average perplexity: 2.03515625\n",
            "Number of samples evaluated: 12710, Average perplexity: 2.033203125\n",
            "Number of samples evaluated: 12720, Average perplexity: 2.033203125\n",
            "Number of samples evaluated: 12730, Average perplexity: 2.03125\n",
            "Number of samples evaluated: 12740, Average perplexity: 2.03125\n",
            "Number of samples evaluated: 12750, Average perplexity: 2.029296875\n",
            "Number of samples evaluated: 12760, Average perplexity: 2.029296875\n",
            "Number of samples evaluated: 12770, Average perplexity: 2.029296875\n",
            "Number of samples evaluated: 12780, Average perplexity: 2.02734375\n",
            "Number of samples evaluated: 12790, Average perplexity: 2.025390625\n",
            "Number of samples evaluated: 12800, Average perplexity: 2.025390625\n",
            "Number of samples evaluated: 12810, Average perplexity: 2.0234375\n",
            "Number of samples evaluated: 12820, Average perplexity: 2.0234375\n",
            "Number of samples evaluated: 12830, Average perplexity: 2.0234375\n",
            "Number of samples evaluated: 12840, Average perplexity: 2.021484375\n",
            "Number of samples evaluated: 12850, Average perplexity: 2.021484375\n",
            "Number of samples evaluated: 12860, Average perplexity: 2.01953125\n",
            "Number of samples evaluated: 12870, Average perplexity: 2.01953125\n",
            "Number of samples evaluated: 12880, Average perplexity: 2.01953125\n",
            "Number of samples evaluated: 12890, Average perplexity: 2.017578125\n",
            "Number of samples evaluated: 12900, Average perplexity: 2.015625\n",
            "Number of samples evaluated: 12910, Average perplexity: 2.015625\n",
            "Number of samples evaluated: 12920, Average perplexity: 2.013671875\n",
            "Number of samples evaluated: 12930, Average perplexity: 2.013671875\n",
            "Number of samples evaluated: 12940, Average perplexity: 2.01171875\n",
            "Number of samples evaluated: 12950, Average perplexity: 2.01171875\n",
            "Number of samples evaluated: 12960, Average perplexity: 2.009765625\n",
            "Number of samples evaluated: 12970, Average perplexity: 2.009765625\n",
            "Number of samples evaluated: 12980, Average perplexity: 2.0078125\n",
            "Number of samples evaluated: 12990, Average perplexity: 2.0078125\n",
            "Number of samples evaluated: 13000, Average perplexity: 2.005859375\n",
            "Number of samples evaluated: 13010, Average perplexity: 2.00390625\n",
            "Number of samples evaluated: 13020, Average perplexity: 2.00390625\n",
            "Number of samples evaluated: 13030, Average perplexity: 2.00390625\n",
            "Number of samples evaluated: 13040, Average perplexity: 2.001953125\n",
            "Number of samples evaluated: 13050, Average perplexity: 2.001953125\n",
            "Number of samples evaluated: 13060, Average perplexity: 2.0\n",
            "Number of samples evaluated: 13070, Average perplexity: 1.9990234375\n",
            "Number of samples evaluated: 13080, Average perplexity: 1.998046875\n",
            "Number of samples evaluated: 13090, Average perplexity: 1.9970703125\n",
            "Number of samples evaluated: 13100, Average perplexity: 1.99609375\n",
            "Number of samples evaluated: 13110, Average perplexity: 1.9951171875\n",
            "Number of samples evaluated: 13120, Average perplexity: 1.994140625\n",
            "Number of samples evaluated: 13130, Average perplexity: 1.9931640625\n",
            "Number of samples evaluated: 13140, Average perplexity: 1.9912109375\n",
            "Number of samples evaluated: 13150, Average perplexity: 1.990234375\n",
            "Number of samples evaluated: 13160, Average perplexity: 1.9892578125\n",
            "Number of samples evaluated: 13170, Average perplexity: 1.98828125\n",
            "Number of samples evaluated: 13180, Average perplexity: 1.9873046875\n",
            "Number of samples evaluated: 13190, Average perplexity: 1.986328125\n",
            "Number of samples evaluated: 13200, Average perplexity: 1.9853515625\n",
            "Number of samples evaluated: 13210, Average perplexity: 1.984375\n",
            "Number of samples evaluated: 13220, Average perplexity: 1.984375\n",
            "Number of samples evaluated: 13230, Average perplexity: 1.9833984375\n",
            "Number of samples evaluated: 13240, Average perplexity: 1.9833984375\n",
            "Number of samples evaluated: 13250, Average perplexity: 1.982421875\n",
            "Number of samples evaluated: 13260, Average perplexity: 1.9814453125\n",
            "Number of samples evaluated: 13270, Average perplexity: 1.98046875\n",
            "Number of samples evaluated: 13280, Average perplexity: 1.9794921875\n",
            "Number of samples evaluated: 13290, Average perplexity: 1.978515625\n",
            "Number of samples evaluated: 13300, Average perplexity: 1.9775390625\n",
            "Number of samples evaluated: 13310, Average perplexity: 1.9765625\n",
            "Number of samples evaluated: 13320, Average perplexity: 1.9755859375\n",
            "Number of samples evaluated: 13330, Average perplexity: 1.974609375\n",
            "Number of samples evaluated: 13340, Average perplexity: 1.9736328125\n",
            "Number of samples evaluated: 13350, Average perplexity: 1.9716796875\n",
            "Number of samples evaluated: 13360, Average perplexity: 1.970703125\n",
            "Number of samples evaluated: 13370, Average perplexity: 1.9697265625\n",
            "Number of samples evaluated: 13380, Average perplexity: 1.96875\n",
            "Number of samples evaluated: 13390, Average perplexity: 1.9677734375\n",
            "Number of samples evaluated: 13400, Average perplexity: 1.966796875\n",
            "Number of samples evaluated: 13410, Average perplexity: 1.9658203125\n",
            "Number of samples evaluated: 13420, Average perplexity: 1.96484375\n",
            "Number of samples evaluated: 13430, Average perplexity: 1.9638671875\n",
            "Number of samples evaluated: 13440, Average perplexity: 1.962890625\n",
            "Number of samples evaluated: 13450, Average perplexity: 1.9619140625\n",
            "Number of samples evaluated: 13460, Average perplexity: 1.9609375\n",
            "Number of samples evaluated: 13470, Average perplexity: 1.9599609375\n",
            "Number of samples evaluated: 13480, Average perplexity: 1.958984375\n",
            "Number of samples evaluated: 13490, Average perplexity: 1.9580078125\n",
            "Number of samples evaluated: 13500, Average perplexity: 1.95703125\n",
            "Number of samples evaluated: 13510, Average perplexity: 1.95703125\n",
            "Number of samples evaluated: 13520, Average perplexity: 1.9560546875\n",
            "Number of samples evaluated: 13530, Average perplexity: 1.955078125\n",
            "Number of samples evaluated: 13540, Average perplexity: 1.9541015625\n",
            "Number of samples evaluated: 13550, Average perplexity: 1.953125\n",
            "Number of samples evaluated: 13560, Average perplexity: 1.9521484375\n",
            "Number of samples evaluated: 13570, Average perplexity: 1.951171875\n",
            "Number of samples evaluated: 13580, Average perplexity: 1.951171875\n",
            "Number of samples evaluated: 13590, Average perplexity: 1.9501953125\n",
            "Number of samples evaluated: 13600, Average perplexity: 1.94921875\n",
            "Number of samples evaluated: 13610, Average perplexity: 1.9482421875\n",
            "Number of samples evaluated: 13620, Average perplexity: 1.947265625\n",
            "Number of samples evaluated: 13630, Average perplexity: 1.9462890625\n",
            "Number of samples evaluated: 13640, Average perplexity: 1.9453125\n",
            "Number of samples evaluated: 13650, Average perplexity: 1.9462890625\n",
            "Number of samples evaluated: 13660, Average perplexity: 1.9453125\n",
            "Number of samples evaluated: 13670, Average perplexity: 1.9443359375\n",
            "Number of samples evaluated: 13680, Average perplexity: 1.943359375\n",
            "Number of samples evaluated: 13690, Average perplexity: 1.9423828125\n",
            "Number of samples evaluated: 13700, Average perplexity: 1.94140625\n",
            "Number of samples evaluated: 13710, Average perplexity: 1.9404296875\n",
            "Number of samples evaluated: 13720, Average perplexity: 1.939453125\n",
            "Number of samples evaluated: 13730, Average perplexity: 1.9384765625\n",
            "Number of samples evaluated: 13740, Average perplexity: 1.9375\n",
            "Number of samples evaluated: 13750, Average perplexity: 1.9365234375\n",
            "Number of samples evaluated: 13760, Average perplexity: 1.9365234375\n",
            "Number of samples evaluated: 13770, Average perplexity: 1.935546875\n",
            "Number of samples evaluated: 13780, Average perplexity: 1.9345703125\n",
            "Number of samples evaluated: 13790, Average perplexity: 1.93359375\n",
            "Number of samples evaluated: 13800, Average perplexity: 1.9326171875\n",
            "Number of samples evaluated: 13810, Average perplexity: 1.931640625\n",
            "Number of samples evaluated: 13820, Average perplexity: 1.9306640625\n",
            "Number of samples evaluated: 13830, Average perplexity: 1.9296875\n",
            "Number of samples evaluated: 13840, Average perplexity: 1.9287109375\n",
            "Number of samples evaluated: 13850, Average perplexity: 1.927734375\n",
            "Number of samples evaluated: 13860, Average perplexity: 1.9267578125\n",
            "Number of samples evaluated: 13870, Average perplexity: 1.92578125\n",
            "Number of samples evaluated: 13880, Average perplexity: 1.9248046875\n",
            "Number of samples evaluated: 13890, Average perplexity: 1.923828125\n",
            "Number of samples evaluated: 13900, Average perplexity: 1.923828125\n",
            "Number of samples evaluated: 13910, Average perplexity: 1.9228515625\n",
            "Number of samples evaluated: 13920, Average perplexity: 1.9228515625\n",
            "Number of samples evaluated: 13930, Average perplexity: 1.921875\n",
            "Number of samples evaluated: 13940, Average perplexity: 1.921875\n",
            "Number of samples evaluated: 13950, Average perplexity: 1.9208984375\n",
            "Number of samples evaluated: 13960, Average perplexity: 1.919921875\n",
            "Number of samples evaluated: 13970, Average perplexity: 1.9189453125\n",
            "Number of samples evaluated: 13980, Average perplexity: 1.9189453125\n",
            "Number of samples evaluated: 13990, Average perplexity: 1.91796875\n",
            "Number of samples evaluated: 14000, Average perplexity: 1.9169921875\n",
            "Number of samples evaluated: 14010, Average perplexity: 1.916015625\n",
            "Number of samples evaluated: 14020, Average perplexity: 1.9150390625\n",
            "Number of samples evaluated: 14030, Average perplexity: 1.9140625\n",
            "Number of samples evaluated: 14040, Average perplexity: 1.9130859375\n",
            "Number of samples evaluated: 14050, Average perplexity: 1.912109375\n",
            "Number of samples evaluated: 14060, Average perplexity: 1.9111328125\n",
            "Number of samples evaluated: 14070, Average perplexity: 1.9111328125\n",
            "Number of samples evaluated: 14080, Average perplexity: 1.9111328125\n",
            "Number of samples evaluated: 14090, Average perplexity: 1.9111328125\n",
            "Number of samples evaluated: 14100, Average perplexity: 1.91015625\n",
            "Number of samples evaluated: 14110, Average perplexity: 1.9091796875\n",
            "Number of samples evaluated: 14120, Average perplexity: 1.908203125\n",
            "Number of samples evaluated: 14130, Average perplexity: 1.9072265625\n",
            "Number of samples evaluated: 14140, Average perplexity: 1.90625\n",
            "Number of samples evaluated: 14150, Average perplexity: 1.9052734375\n",
            "Number of samples evaluated: 14160, Average perplexity: 1.904296875\n",
            "Number of samples evaluated: 14170, Average perplexity: 1.9033203125\n",
            "Number of samples evaluated: 14180, Average perplexity: 1.90234375\n",
            "Number of samples evaluated: 14190, Average perplexity: 1.9013671875\n",
            "Number of samples evaluated: 14200, Average perplexity: 1.900390625\n",
            "Number of samples evaluated: 14210, Average perplexity: 1.8994140625\n",
            "Number of samples evaluated: 14220, Average perplexity: 1.8984375\n",
            "Number of samples evaluated: 14230, Average perplexity: 1.8984375\n",
            "Number of samples evaluated: 14240, Average perplexity: 1.8984375\n",
            "Number of samples evaluated: 14250, Average perplexity: 1.8974609375\n",
            "Number of samples evaluated: 14260, Average perplexity: 1.896484375\n",
            "Number of samples evaluated: 14270, Average perplexity: 1.8955078125\n",
            "Number of samples evaluated: 14280, Average perplexity: 1.89453125\n",
            "Number of samples evaluated: 14290, Average perplexity: 1.8935546875\n",
            "Number of samples evaluated: 14300, Average perplexity: 1.892578125\n",
            "Number of samples evaluated: 14310, Average perplexity: 1.892578125\n",
            "Number of samples evaluated: 14320, Average perplexity: 1.8916015625\n",
            "Number of samples evaluated: 14330, Average perplexity: 1.8916015625\n",
            "Number of samples evaluated: 14340, Average perplexity: 1.890625\n",
            "Number of samples evaluated: 14350, Average perplexity: 1.8896484375\n",
            "Number of samples evaluated: 14360, Average perplexity: 1.888671875\n",
            "Number of samples evaluated: 14370, Average perplexity: 1.888671875\n",
            "Number of samples evaluated: 14380, Average perplexity: 1.8876953125\n",
            "Number of samples evaluated: 14390, Average perplexity: 1.88671875\n",
            "Number of samples evaluated: 14400, Average perplexity: 1.8857421875\n",
            "Number of samples evaluated: 14410, Average perplexity: 1.884765625\n",
            "Number of samples evaluated: 14420, Average perplexity: 1.884765625\n",
            "Number of samples evaluated: 14430, Average perplexity: 1.884765625\n",
            "Number of samples evaluated: 14440, Average perplexity: 1.8837890625\n",
            "Number of samples evaluated: 14450, Average perplexity: 1.8828125\n",
            "Number of samples evaluated: 14460, Average perplexity: 1.8828125\n",
            "Number of samples evaluated: 14470, Average perplexity: 1.8818359375\n",
            "Number of samples evaluated: 14480, Average perplexity: 1.880859375\n",
            "Number of samples evaluated: 14490, Average perplexity: 1.880859375\n",
            "Number of samples evaluated: 14500, Average perplexity: 1.8798828125\n",
            "Number of samples evaluated: 14510, Average perplexity: 1.87890625\n",
            "Number of samples evaluated: 14520, Average perplexity: 1.8779296875\n",
            "Number of samples evaluated: 14530, Average perplexity: 1.8779296875\n",
            "Number of samples evaluated: 14540, Average perplexity: 1.876953125\n",
            "Number of samples evaluated: 14550, Average perplexity: 1.876953125\n",
            "Number of samples evaluated: 14560, Average perplexity: 1.8759765625\n",
            "Number of samples evaluated: 14570, Average perplexity: 1.8759765625\n",
            "Number of samples evaluated: 14580, Average perplexity: 1.875\n",
            "Number of samples evaluated: 14590, Average perplexity: 1.8740234375\n",
            "Number of samples evaluated: 14600, Average perplexity: 1.873046875\n",
            "Number of samples evaluated: 14610, Average perplexity: 1.8720703125\n",
            "Number of samples evaluated: 14620, Average perplexity: 1.87109375\n",
            "Number of samples evaluated: 14630, Average perplexity: 1.8701171875\n",
            "Number of samples evaluated: 14640, Average perplexity: 1.869140625\n",
            "Number of samples evaluated: 14650, Average perplexity: 1.8701171875\n",
            "Number of samples evaluated: 14660, Average perplexity: 1.869140625\n",
            "Number of samples evaluated: 14670, Average perplexity: 1.8681640625\n",
            "Number of samples evaluated: 14680, Average perplexity: 1.8671875\n",
            "Number of samples evaluated: 14690, Average perplexity: 1.8671875\n",
            "Number of samples evaluated: 14700, Average perplexity: 1.8662109375\n",
            "Number of samples evaluated: 14710, Average perplexity: 1.8662109375\n",
            "Number of samples evaluated: 14720, Average perplexity: 1.865234375\n",
            "Number of samples evaluated: 14730, Average perplexity: 1.8642578125\n",
            "Number of samples evaluated: 14740, Average perplexity: 1.86328125\n",
            "Number of samples evaluated: 14750, Average perplexity: 1.8623046875\n",
            "Number of samples evaluated: 14760, Average perplexity: 1.8623046875\n",
            "Number of samples evaluated: 14770, Average perplexity: 1.861328125\n",
            "Number of samples evaluated: 14780, Average perplexity: 1.8603515625\n",
            "Number of samples evaluated: 14790, Average perplexity: 1.8603515625\n",
            "Number of samples evaluated: 14800, Average perplexity: 1.859375\n",
            "Number of samples evaluated: 14810, Average perplexity: 1.8583984375\n",
            "Number of samples evaluated: 14820, Average perplexity: 1.857421875\n",
            "Number of samples evaluated: 14830, Average perplexity: 1.8564453125\n",
            "Number of samples evaluated: 14840, Average perplexity: 1.85546875\n",
            "Number of samples evaluated: 14850, Average perplexity: 1.8544921875\n",
            "Number of samples evaluated: 14860, Average perplexity: 1.8544921875\n",
            "Number of samples evaluated: 14870, Average perplexity: 1.853515625\n",
            "Number of samples evaluated: 14880, Average perplexity: 1.8525390625\n",
            "Number of samples evaluated: 14890, Average perplexity: 1.8515625\n",
            "Number of samples evaluated: 14900, Average perplexity: 1.8505859375\n",
            "Number of samples evaluated: 14910, Average perplexity: 1.849609375\n",
            "Number of samples evaluated: 14920, Average perplexity: 1.849609375\n",
            "Number of samples evaluated: 14930, Average perplexity: 1.849609375\n",
            "Number of samples evaluated: 14940, Average perplexity: 1.8486328125\n",
            "Number of samples evaluated: 14950, Average perplexity: 1.84765625\n",
            "Number of samples evaluated: 14960, Average perplexity: 1.8466796875\n",
            "Number of samples evaluated: 14970, Average perplexity: 1.845703125\n",
            "Number of samples evaluated: 14980, Average perplexity: 1.845703125\n",
            "Number of samples evaluated: 14990, Average perplexity: 1.8447265625\n",
            "Number of samples evaluated: 15000, Average perplexity: 1.84375\n",
            "Number of samples evaluated: 15010, Average perplexity: 1.8427734375\n",
            "Number of samples evaluated: 15020, Average perplexity: 1.841796875\n",
            "Number of samples evaluated: 15030, Average perplexity: 1.8408203125\n",
            "Number of samples evaluated: 15040, Average perplexity: 1.83984375\n",
            "Number of samples evaluated: 15050, Average perplexity: 1.83984375\n",
            "Number of samples evaluated: 15060, Average perplexity: 1.8388671875\n",
            "Number of samples evaluated: 15070, Average perplexity: 1.8388671875\n",
            "Number of samples evaluated: 15080, Average perplexity: 1.837890625\n",
            "Number of samples evaluated: 15090, Average perplexity: 1.8369140625\n",
            "Number of samples evaluated: 15100, Average perplexity: 1.8369140625\n",
            "Number of samples evaluated: 15110, Average perplexity: 1.8359375\n",
            "Number of samples evaluated: 15120, Average perplexity: 1.8349609375\n",
            "Number of samples evaluated: 15130, Average perplexity: 1.833984375\n",
            "Number of samples evaluated: 15140, Average perplexity: 1.8330078125\n",
            "Number of samples evaluated: 15150, Average perplexity: 1.83203125\n",
            "Number of samples evaluated: 15160, Average perplexity: 1.83203125\n",
            "Number of samples evaluated: 15170, Average perplexity: 1.8310546875\n",
            "Number of samples evaluated: 15180, Average perplexity: 1.830078125\n",
            "Number of samples evaluated: 15190, Average perplexity: 1.8291015625\n",
            "Number of samples evaluated: 15200, Average perplexity: 1.828125\n",
            "Number of samples evaluated: 15210, Average perplexity: 1.828125\n",
            "Number of samples evaluated: 15220, Average perplexity: 1.828125\n",
            "Number of samples evaluated: 15230, Average perplexity: 1.828125\n",
            "Number of samples evaluated: 15240, Average perplexity: 1.8271484375\n",
            "Number of samples evaluated: 15250, Average perplexity: 1.8271484375\n",
            "Number of samples evaluated: 15260, Average perplexity: 1.8271484375\n",
            "Number of samples evaluated: 15270, Average perplexity: 1.826171875\n",
            "Number of samples evaluated: 15280, Average perplexity: 1.8251953125\n",
            "Number of samples evaluated: 15290, Average perplexity: 1.82421875\n",
            "Number of samples evaluated: 15300, Average perplexity: 1.8232421875\n",
            "Number of samples evaluated: 15310, Average perplexity: 1.82421875\n",
            "Number of samples evaluated: 15320, Average perplexity: 1.8232421875\n",
            "Number of samples evaluated: 15330, Average perplexity: 1.822265625\n",
            "Number of samples evaluated: 15340, Average perplexity: 1.8212890625\n",
            "Number of samples evaluated: 15350, Average perplexity: 1.8203125\n",
            "Number of samples evaluated: 15360, Average perplexity: 1.8203125\n",
            "Number of samples evaluated: 15370, Average perplexity: 1.8193359375\n",
            "Number of samples evaluated: 15380, Average perplexity: 1.818359375\n",
            "Number of samples evaluated: 15390, Average perplexity: 1.8173828125\n",
            "Number of samples evaluated: 15400, Average perplexity: 1.8173828125\n",
            "Number of samples evaluated: 15410, Average perplexity: 1.8173828125\n",
            "Number of samples evaluated: 15420, Average perplexity: 1.8173828125\n",
            "Number of samples evaluated: 15430, Average perplexity: 1.8173828125\n",
            "Number of samples evaluated: 15440, Average perplexity: 1.81640625\n",
            "Number of samples evaluated: 15450, Average perplexity: 1.81640625\n",
            "Number of samples evaluated: 15460, Average perplexity: 1.8154296875\n",
            "Number of samples evaluated: 15470, Average perplexity: 1.814453125\n",
            "Number of samples evaluated: 15480, Average perplexity: 1.8134765625\n",
            "Number of samples evaluated: 15490, Average perplexity: 1.814453125\n",
            "Number of samples evaluated: 15500, Average perplexity: 1.8134765625\n",
            "Number of samples evaluated: 15510, Average perplexity: 1.8125\n",
            "Number of samples evaluated: 15520, Average perplexity: 1.8115234375\n",
            "Number of samples evaluated: 15530, Average perplexity: 1.810546875\n",
            "Number of samples evaluated: 15540, Average perplexity: 1.810546875\n",
            "Number of samples evaluated: 15550, Average perplexity: 1.8095703125\n",
            "Number of samples evaluated: 15560, Average perplexity: 1.80859375\n",
            "Number of samples evaluated: 15570, Average perplexity: 1.80859375\n",
            "Number of samples evaluated: 15580, Average perplexity: 1.80859375\n",
            "Number of samples evaluated: 15590, Average perplexity: 1.8076171875\n",
            "Number of samples evaluated: 15600, Average perplexity: 1.806640625\n",
            "Number of samples evaluated: 15610, Average perplexity: 1.8056640625\n",
            "Number of samples evaluated: 15620, Average perplexity: 1.8046875\n",
            "Number of samples evaluated: 15630, Average perplexity: 1.8046875\n",
            "Number of samples evaluated: 15640, Average perplexity: 1.8037109375\n",
            "Number of samples evaluated: 15650, Average perplexity: 1.802734375\n",
            "Number of samples evaluated: 15660, Average perplexity: 1.8037109375\n",
            "Number of samples evaluated: 15670, Average perplexity: 1.8037109375\n",
            "Number of samples evaluated: 15680, Average perplexity: 1.802734375\n",
            "Number of samples evaluated: 15690, Average perplexity: 1.8017578125\n",
            "Number of samples evaluated: 15700, Average perplexity: 1.80078125\n",
            "Number of samples evaluated: 15710, Average perplexity: 1.80078125\n",
            "Number of samples evaluated: 15720, Average perplexity: 1.7998046875\n",
            "Number of samples evaluated: 15730, Average perplexity: 1.798828125\n",
            "Number of samples evaluated: 15740, Average perplexity: 1.798828125\n",
            "Number of samples evaluated: 15750, Average perplexity: 1.7978515625\n",
            "Number of samples evaluated: 15760, Average perplexity: 1.7978515625\n",
            "Number of samples evaluated: 15770, Average perplexity: 1.796875\n",
            "Number of samples evaluated: 15780, Average perplexity: 1.7958984375\n",
            "Number of samples evaluated: 15790, Average perplexity: 1.794921875\n",
            "Number of samples evaluated: 15800, Average perplexity: 1.794921875\n",
            "Number of samples evaluated: 15810, Average perplexity: 1.7939453125\n",
            "Number of samples evaluated: 15820, Average perplexity: 1.79296875\n",
            "Number of samples evaluated: 15830, Average perplexity: 1.7919921875\n",
            "Number of samples evaluated: 15840, Average perplexity: 1.7919921875\n",
            "Number of samples evaluated: 15850, Average perplexity: 1.7919921875\n",
            "Number of samples evaluated: 15860, Average perplexity: 1.791015625\n",
            "Number of samples evaluated: 15870, Average perplexity: 1.791015625\n",
            "Number of samples evaluated: 15880, Average perplexity: 1.791015625\n",
            "Number of samples evaluated: 15890, Average perplexity: 1.791015625\n",
            "Number of samples evaluated: 15900, Average perplexity: 1.7900390625\n",
            "Number of samples evaluated: 15910, Average perplexity: 1.7890625\n",
            "Number of samples evaluated: 15920, Average perplexity: 1.7890625\n",
            "Number of samples evaluated: 15930, Average perplexity: 1.7880859375\n",
            "Number of samples evaluated: 15940, Average perplexity: 1.787109375\n",
            "Number of samples evaluated: 15950, Average perplexity: 1.7861328125\n",
            "Number of samples evaluated: 15960, Average perplexity: 1.7861328125\n",
            "Number of samples evaluated: 15970, Average perplexity: 1.78515625\n",
            "Number of samples evaluated: 15980, Average perplexity: 1.7841796875\n",
            "Number of samples evaluated: 15990, Average perplexity: 1.7841796875\n",
            "Number of samples evaluated: 16000, Average perplexity: 1.783203125\n",
            "Number of samples evaluated: 16010, Average perplexity: 1.7822265625\n",
            "Number of samples evaluated: 16020, Average perplexity: 1.7822265625\n",
            "Number of samples evaluated: 16030, Average perplexity: 1.7822265625\n",
            "Number of samples evaluated: 16040, Average perplexity: 1.78125\n",
            "Number of samples evaluated: 16050, Average perplexity: 1.7802734375\n",
            "Number of samples evaluated: 16060, Average perplexity: 1.779296875\n",
            "Number of samples evaluated: 16070, Average perplexity: 1.779296875\n",
            "Number of samples evaluated: 16080, Average perplexity: 1.7783203125\n",
            "Number of samples evaluated: 16090, Average perplexity: 1.77734375\n",
            "Number of samples evaluated: 16100, Average perplexity: 1.7763671875\n",
            "Number of samples evaluated: 16110, Average perplexity: 1.7763671875\n",
            "Number of samples evaluated: 16120, Average perplexity: 1.775390625\n",
            "Number of samples evaluated: 16130, Average perplexity: 1.7744140625\n",
            "Number of samples evaluated: 16140, Average perplexity: 1.7744140625\n",
            "Number of samples evaluated: 16150, Average perplexity: 1.7744140625\n",
            "Number of samples evaluated: 16160, Average perplexity: 1.7734375\n",
            "Number of samples evaluated: 16170, Average perplexity: 1.7724609375\n",
            "Number of samples evaluated: 16180, Average perplexity: 1.7724609375\n",
            "Number of samples evaluated: 16190, Average perplexity: 1.771484375\n",
            "Number of samples evaluated: 16200, Average perplexity: 1.7705078125\n",
            "Number of samples evaluated: 16210, Average perplexity: 1.76953125\n",
            "Number of samples evaluated: 16220, Average perplexity: 1.76953125\n",
            "Number of samples evaluated: 16230, Average perplexity: 1.7685546875\n",
            "Number of samples evaluated: 16240, Average perplexity: 1.7685546875\n",
            "Number of samples evaluated: 16250, Average perplexity: 1.76953125\n",
            "Number of samples evaluated: 16260, Average perplexity: 1.7685546875\n",
            "Number of samples evaluated: 16270, Average perplexity: 1.767578125\n",
            "Number of samples evaluated: 16280, Average perplexity: 1.767578125\n",
            "Number of samples evaluated: 16290, Average perplexity: 1.767578125\n",
            "Number of samples evaluated: 16300, Average perplexity: 1.767578125\n",
            "Number of samples evaluated: 16310, Average perplexity: 1.7666015625\n",
            "Number of samples evaluated: 16320, Average perplexity: 1.7666015625\n",
            "Number of samples evaluated: 16330, Average perplexity: 1.765625\n",
            "Number of samples evaluated: 16340, Average perplexity: 1.7646484375\n",
            "Number of samples evaluated: 16350, Average perplexity: 1.763671875\n",
            "Number of samples evaluated: 16360, Average perplexity: 1.763671875\n",
            "Number of samples evaluated: 16370, Average perplexity: 1.7626953125\n",
            "Number of samples evaluated: 16380, Average perplexity: 1.76171875\n",
            "Number of samples evaluated: 16390, Average perplexity: 1.76171875\n",
            "Number of samples evaluated: 16400, Average perplexity: 1.7607421875\n",
            "Number of samples evaluated: 16410, Average perplexity: 1.759765625\n",
            "Number of samples evaluated: 16420, Average perplexity: 1.759765625\n",
            "Number of samples evaluated: 16430, Average perplexity: 1.759765625\n",
            "Number of samples evaluated: 16440, Average perplexity: 1.759765625\n",
            "Number of samples evaluated: 16450, Average perplexity: 1.7587890625\n",
            "Number of samples evaluated: 16460, Average perplexity: 1.7587890625\n",
            "Number of samples evaluated: 16470, Average perplexity: 1.7578125\n",
            "Number of samples evaluated: 16480, Average perplexity: 1.7568359375\n",
            "Number of samples evaluated: 16490, Average perplexity: 1.7568359375\n",
            "Number of samples evaluated: 16500, Average perplexity: 1.755859375\n",
            "Number of samples evaluated: 16510, Average perplexity: 1.7548828125\n",
            "Number of samples evaluated: 16520, Average perplexity: 1.75390625\n",
            "Number of samples evaluated: 16530, Average perplexity: 1.7548828125\n",
            "Number of samples evaluated: 16540, Average perplexity: 1.7548828125\n",
            "Number of samples evaluated: 16550, Average perplexity: 1.75390625\n",
            "Number of samples evaluated: 16560, Average perplexity: 1.75390625\n",
            "Number of samples evaluated: 16570, Average perplexity: 1.7529296875\n",
            "Number of samples evaluated: 16580, Average perplexity: 1.7529296875\n",
            "Number of samples evaluated: 16590, Average perplexity: 1.7529296875\n",
            "Number of samples evaluated: 16600, Average perplexity: 1.751953125\n",
            "Number of samples evaluated: 16610, Average perplexity: 1.7509765625\n",
            "Number of samples evaluated: 16620, Average perplexity: 1.7509765625\n",
            "Number of samples evaluated: 16630, Average perplexity: 1.7509765625\n",
            "Number of samples evaluated: 16640, Average perplexity: 1.75\n",
            "Number of samples evaluated: 16650, Average perplexity: 1.7490234375\n",
            "Number of samples evaluated: 16660, Average perplexity: 1.7490234375\n",
            "Number of samples evaluated: 16670, Average perplexity: 1.748046875\n",
            "Number of samples evaluated: 16680, Average perplexity: 1.7470703125\n",
            "Number of samples evaluated: 16690, Average perplexity: 1.7470703125\n",
            "Number of samples evaluated: 16700, Average perplexity: 1.74609375\n",
            "Number of samples evaluated: 16710, Average perplexity: 1.74609375\n",
            "Number of samples evaluated: 16720, Average perplexity: 1.74609375\n",
            "Number of samples evaluated: 16730, Average perplexity: 1.74609375\n",
            "Number of samples evaluated: 16740, Average perplexity: 1.74609375\n",
            "Number of samples evaluated: 16750, Average perplexity: 1.74609375\n",
            "Number of samples evaluated: 16760, Average perplexity: 1.7451171875\n",
            "Number of samples evaluated: 16770, Average perplexity: 1.744140625\n",
            "Number of samples evaluated: 16780, Average perplexity: 1.7431640625\n",
            "Number of samples evaluated: 16790, Average perplexity: 1.7431640625\n",
            "Number of samples evaluated: 16800, Average perplexity: 1.7421875\n",
            "Number of samples evaluated: 16810, Average perplexity: 1.7412109375\n",
            "Number of samples evaluated: 16820, Average perplexity: 1.7412109375\n",
            "Number of samples evaluated: 16830, Average perplexity: 1.7412109375\n",
            "Number of samples evaluated: 16840, Average perplexity: 1.740234375\n",
            "Number of samples evaluated: 16850, Average perplexity: 1.740234375\n",
            "Number of samples evaluated: 16860, Average perplexity: 1.740234375\n",
            "Number of samples evaluated: 16870, Average perplexity: 1.740234375\n",
            "Number of samples evaluated: 16880, Average perplexity: 1.740234375\n",
            "Number of samples evaluated: 16890, Average perplexity: 1.7392578125\n",
            "Number of samples evaluated: 16900, Average perplexity: 1.7392578125\n",
            "Number of samples evaluated: 16910, Average perplexity: 1.7392578125\n",
            "Number of samples evaluated: 16920, Average perplexity: 1.73828125\n",
            "Number of samples evaluated: 16930, Average perplexity: 1.7373046875\n",
            "Number of samples evaluated: 16940, Average perplexity: 1.7373046875\n",
            "Number of samples evaluated: 16950, Average perplexity: 1.7373046875\n",
            "Number of samples evaluated: 16960, Average perplexity: 1.736328125\n",
            "Number of samples evaluated: 16970, Average perplexity: 1.736328125\n",
            "Number of samples evaluated: 16980, Average perplexity: 1.7353515625\n",
            "Number of samples evaluated: 16990, Average perplexity: 1.734375\n",
            "Number of samples evaluated: 17000, Average perplexity: 1.734375\n",
            "Number of samples evaluated: 17010, Average perplexity: 1.7333984375\n",
            "Number of samples evaluated: 17020, Average perplexity: 1.7333984375\n",
            "Number of samples evaluated: 17030, Average perplexity: 1.7333984375\n",
            "Number of samples evaluated: 17040, Average perplexity: 1.7333984375\n",
            "Number of samples evaluated: 17050, Average perplexity: 1.732421875\n",
            "Number of samples evaluated: 17060, Average perplexity: 1.732421875\n",
            "Number of samples evaluated: 17070, Average perplexity: 1.7314453125\n",
            "Number of samples evaluated: 17080, Average perplexity: 1.73046875\n",
            "Number of samples evaluated: 17090, Average perplexity: 1.73046875\n",
            "Number of samples evaluated: 17100, Average perplexity: 1.7294921875\n",
            "Number of samples evaluated: 17110, Average perplexity: 1.7294921875\n",
            "Number of samples evaluated: 17120, Average perplexity: 1.7294921875\n",
            "Number of samples evaluated: 17130, Average perplexity: 1.728515625\n",
            "Number of samples evaluated: 17140, Average perplexity: 1.728515625\n",
            "Number of samples evaluated: 17150, Average perplexity: 1.728515625\n",
            "Number of samples evaluated: 17160, Average perplexity: 1.7275390625\n",
            "Number of samples evaluated: 17170, Average perplexity: 1.7265625\n",
            "Number of samples evaluated: 17180, Average perplexity: 1.7265625\n",
            "Number of samples evaluated: 17190, Average perplexity: 1.7265625\n",
            "Number of samples evaluated: 17200, Average perplexity: 1.7255859375\n",
            "Number of samples evaluated: 17210, Average perplexity: 1.7255859375\n",
            "Number of samples evaluated: 17220, Average perplexity: 1.724609375\n",
            "Number of samples evaluated: 17230, Average perplexity: 1.7236328125\n",
            "Number of samples evaluated: 17240, Average perplexity: 1.7236328125\n",
            "Number of samples evaluated: 17250, Average perplexity: 1.72265625\n",
            "Number of samples evaluated: 17260, Average perplexity: 1.7216796875\n",
            "Number of samples evaluated: 17270, Average perplexity: 1.7216796875\n",
            "Number of samples evaluated: 17280, Average perplexity: 1.720703125\n",
            "Number of samples evaluated: 17290, Average perplexity: 1.720703125\n",
            "Number of samples evaluated: 17300, Average perplexity: 1.720703125\n",
            "Number of samples evaluated: 17310, Average perplexity: 1.7197265625\n",
            "Number of samples evaluated: 17320, Average perplexity: 1.7197265625\n",
            "Number of samples evaluated: 17330, Average perplexity: 1.7197265625\n",
            "Number of samples evaluated: 17340, Average perplexity: 1.71875\n",
            "Number of samples evaluated: 17350, Average perplexity: 1.71875\n",
            "Number of samples evaluated: 17360, Average perplexity: 1.7177734375\n",
            "Number of samples evaluated: 17370, Average perplexity: 1.716796875\n",
            "Number of samples evaluated: 17380, Average perplexity: 1.716796875\n",
            "Number of samples evaluated: 17390, Average perplexity: 1.7158203125\n",
            "Number of samples evaluated: 17400, Average perplexity: 1.71484375\n",
            "Number of samples evaluated: 17410, Average perplexity: 1.71484375\n",
            "Number of samples evaluated: 17420, Average perplexity: 1.71484375\n",
            "Number of samples evaluated: 17430, Average perplexity: 1.71484375\n",
            "Number of samples evaluated: 17440, Average perplexity: 1.7138671875\n",
            "Number of samples evaluated: 17450, Average perplexity: 1.712890625\n",
            "Number of samples evaluated: 17460, Average perplexity: 1.712890625\n",
            "Number of samples evaluated: 17470, Average perplexity: 1.7119140625\n",
            "Number of samples evaluated: 17480, Average perplexity: 1.7109375\n",
            "Number of samples evaluated: 17490, Average perplexity: 1.7109375\n",
            "Number of samples evaluated: 17500, Average perplexity: 1.7099609375\n",
            "Number of samples evaluated: 17510, Average perplexity: 1.7099609375\n",
            "Number of samples evaluated: 17520, Average perplexity: 1.708984375\n",
            "Number of samples evaluated: 17530, Average perplexity: 1.708984375\n",
            "Number of samples evaluated: 17540, Average perplexity: 1.708984375\n",
            "Number of samples evaluated: 17550, Average perplexity: 1.7080078125\n",
            "Number of samples evaluated: 17560, Average perplexity: 1.70703125\n",
            "Number of samples evaluated: 17570, Average perplexity: 1.70703125\n",
            "Number of samples evaluated: 17580, Average perplexity: 1.7060546875\n",
            "Number of samples evaluated: 17590, Average perplexity: 1.7060546875\n",
            "Number of samples evaluated: 17600, Average perplexity: 1.7060546875\n",
            "Number of samples evaluated: 17610, Average perplexity: 1.705078125\n",
            "Number of samples evaluated: 17620, Average perplexity: 1.705078125\n",
            "Number of samples evaluated: 17630, Average perplexity: 1.7041015625\n",
            "Number of samples evaluated: 17640, Average perplexity: 1.703125\n",
            "Number of samples evaluated: 17650, Average perplexity: 1.703125\n",
            "Number of samples evaluated: 17660, Average perplexity: 1.703125\n",
            "Number of samples evaluated: 17670, Average perplexity: 1.7021484375\n",
            "Number of samples evaluated: 17680, Average perplexity: 1.703125\n",
            "Number of samples evaluated: 17690, Average perplexity: 1.7021484375\n",
            "Number of samples evaluated: 17700, Average perplexity: 1.7021484375\n",
            "Number of samples evaluated: 17710, Average perplexity: 1.701171875\n",
            "Number of samples evaluated: 17720, Average perplexity: 1.7001953125\n",
            "Number of samples evaluated: 17730, Average perplexity: 1.7001953125\n",
            "Number of samples evaluated: 17740, Average perplexity: 1.69921875\n",
            "Number of samples evaluated: 17750, Average perplexity: 1.6982421875\n",
            "Number of samples evaluated: 17760, Average perplexity: 1.6982421875\n",
            "Number of samples evaluated: 17770, Average perplexity: 1.697265625\n",
            "Number of samples evaluated: 17780, Average perplexity: 1.697265625\n",
            "Number of samples evaluated: 17790, Average perplexity: 1.697265625\n",
            "Number of samples evaluated: 17800, Average perplexity: 1.697265625\n",
            "Number of samples evaluated: 17810, Average perplexity: 1.697265625\n",
            "Number of samples evaluated: 17820, Average perplexity: 1.697265625\n",
            "Number of samples evaluated: 17830, Average perplexity: 1.6962890625\n",
            "Number of samples evaluated: 17840, Average perplexity: 1.6962890625\n",
            "Number of samples evaluated: 17850, Average perplexity: 1.6953125\n",
            "Number of samples evaluated: 17860, Average perplexity: 1.6953125\n",
            "Number of samples evaluated: 17870, Average perplexity: 1.6943359375\n",
            "Number of samples evaluated: 17880, Average perplexity: 1.693359375\n",
            "Number of samples evaluated: 17890, Average perplexity: 1.693359375\n",
            "Number of samples evaluated: 17900, Average perplexity: 1.6923828125\n",
            "Number of samples evaluated: 17910, Average perplexity: 1.6923828125\n",
            "Number of samples evaluated: 17920, Average perplexity: 1.6923828125\n",
            "Number of samples evaluated: 17930, Average perplexity: 1.69140625\n",
            "Number of samples evaluated: 17940, Average perplexity: 1.69140625\n",
            "Number of samples evaluated: 17950, Average perplexity: 1.69140625\n",
            "Number of samples evaluated: 17960, Average perplexity: 1.69140625\n",
            "Number of samples evaluated: 17970, Average perplexity: 1.6904296875\n",
            "Number of samples evaluated: 17980, Average perplexity: 1.689453125\n",
            "Number of samples evaluated: 17990, Average perplexity: 1.689453125\n",
            "Number of samples evaluated: 18000, Average perplexity: 1.6884765625\n",
            "Number of samples evaluated: 18010, Average perplexity: 1.6884765625\n",
            "Number of samples evaluated: 18020, Average perplexity: 1.6875\n",
            "Number of samples evaluated: 18030, Average perplexity: 1.6865234375\n",
            "Number of samples evaluated: 18040, Average perplexity: 1.6865234375\n",
            "Number of samples evaluated: 18050, Average perplexity: 1.6865234375\n",
            "Number of samples evaluated: 18060, Average perplexity: 1.6865234375\n",
            "Number of samples evaluated: 18070, Average perplexity: 1.685546875\n",
            "Number of samples evaluated: 18080, Average perplexity: 1.6845703125\n",
            "Number of samples evaluated: 18090, Average perplexity: 1.6845703125\n",
            "Number of samples evaluated: 18100, Average perplexity: 1.68359375\n",
            "Number of samples evaluated: 18110, Average perplexity: 1.6845703125\n",
            "Number of samples evaluated: 18120, Average perplexity: 1.68359375\n",
            "Number of samples evaluated: 18130, Average perplexity: 1.6826171875\n",
            "Number of samples evaluated: 18140, Average perplexity: 1.6826171875\n",
            "Number of samples evaluated: 18150, Average perplexity: 1.681640625\n",
            "Number of samples evaluated: 18160, Average perplexity: 1.6826171875\n",
            "Number of samples evaluated: 18170, Average perplexity: 1.6826171875\n",
            "Number of samples evaluated: 18180, Average perplexity: 1.681640625\n",
            "Number of samples evaluated: 18190, Average perplexity: 1.6826171875\n",
            "Number of samples evaluated: 18200, Average perplexity: 1.681640625\n",
            "Number of samples evaluated: 18210, Average perplexity: 1.681640625\n",
            "Number of samples evaluated: 18220, Average perplexity: 1.681640625\n",
            "Number of samples evaluated: 18230, Average perplexity: 1.6806640625\n",
            "Number of samples evaluated: 18240, Average perplexity: 1.6806640625\n",
            "Number of samples evaluated: 18250, Average perplexity: 1.6796875\n",
            "Number of samples evaluated: 18260, Average perplexity: 1.6787109375\n",
            "Number of samples evaluated: 18270, Average perplexity: 1.6787109375\n",
            "Number of samples evaluated: 18280, Average perplexity: 1.677734375\n",
            "Number of samples evaluated: 18290, Average perplexity: 1.677734375\n",
            "Number of samples evaluated: 18300, Average perplexity: 1.6767578125\n",
            "Number of samples evaluated: 18310, Average perplexity: 1.6767578125\n",
            "Number of samples evaluated: 18320, Average perplexity: 1.6767578125\n",
            "Number of samples evaluated: 18330, Average perplexity: 1.67578125\n",
            "Number of samples evaluated: 18340, Average perplexity: 1.67578125\n",
            "Number of samples evaluated: 18350, Average perplexity: 1.6748046875\n",
            "Number of samples evaluated: 18360, Average perplexity: 1.6748046875\n",
            "Number of samples evaluated: 18370, Average perplexity: 1.673828125\n",
            "Number of samples evaluated: 18380, Average perplexity: 1.673828125\n",
            "Number of samples evaluated: 18390, Average perplexity: 1.6728515625\n",
            "Number of samples evaluated: 18400, Average perplexity: 1.671875\n",
            "Number of samples evaluated: 18410, Average perplexity: 1.671875\n",
            "Number of samples evaluated: 18420, Average perplexity: 1.671875\n",
            "Number of samples evaluated: 18430, Average perplexity: 1.671875\n",
            "Number of samples evaluated: 18440, Average perplexity: 1.6708984375\n",
            "Number of samples evaluated: 18450, Average perplexity: 1.6708984375\n",
            "Number of samples evaluated: 18460, Average perplexity: 1.669921875\n",
            "Number of samples evaluated: 18470, Average perplexity: 1.6689453125\n",
            "Number of samples evaluated: 18480, Average perplexity: 1.6689453125\n",
            "Number of samples evaluated: 18490, Average perplexity: 1.66796875\n",
            "Number of samples evaluated: 18500, Average perplexity: 1.66796875\n",
            "Number of samples evaluated: 18510, Average perplexity: 1.6669921875\n",
            "Number of samples evaluated: 18520, Average perplexity: 1.6669921875\n",
            "Number of samples evaluated: 18530, Average perplexity: 1.6669921875\n",
            "Number of samples evaluated: 18540, Average perplexity: 1.666015625\n",
            "Number of samples evaluated: 18550, Average perplexity: 1.666015625\n",
            "Number of samples evaluated: 18560, Average perplexity: 1.666015625\n",
            "Number of samples evaluated: 18570, Average perplexity: 1.666015625\n",
            "Number of samples evaluated: 18580, Average perplexity: 1.6650390625\n",
            "Number of samples evaluated: 18590, Average perplexity: 1.6640625\n",
            "Number of samples evaluated: 18600, Average perplexity: 1.6640625\n",
            "Number of samples evaluated: 18610, Average perplexity: 1.6630859375\n",
            "Number of samples evaluated: 18620, Average perplexity: 1.6630859375\n",
            "Number of samples evaluated: 18630, Average perplexity: 1.662109375\n",
            "Number of samples evaluated: 18640, Average perplexity: 1.662109375\n",
            "Number of samples evaluated: 18650, Average perplexity: 1.662109375\n",
            "Number of samples evaluated: 18660, Average perplexity: 1.662109375\n",
            "Number of samples evaluated: 18670, Average perplexity: 1.6611328125\n",
            "Number of samples evaluated: 18680, Average perplexity: 1.66015625\n",
            "Number of samples evaluated: 18690, Average perplexity: 1.66015625\n",
            "Number of samples evaluated: 18700, Average perplexity: 1.66015625\n",
            "Number of samples evaluated: 18710, Average perplexity: 1.66015625\n",
            "Number of samples evaluated: 18720, Average perplexity: 1.6591796875\n",
            "Number of samples evaluated: 18730, Average perplexity: 1.66015625\n",
            "Number of samples evaluated: 18740, Average perplexity: 1.66015625\n",
            "Number of samples evaluated: 18750, Average perplexity: 1.6591796875\n",
            "Number of samples evaluated: 18760, Average perplexity: 1.66015625\n",
            "Number of samples evaluated: 18770, Average perplexity: 1.6591796875\n",
            "Number of samples evaluated: 18780, Average perplexity: 1.658203125\n",
            "Number of samples evaluated: 18790, Average perplexity: 1.6591796875\n",
            "Number of samples evaluated: 18800, Average perplexity: 1.658203125\n",
            "Number of samples evaluated: 18810, Average perplexity: 1.658203125\n",
            "Number of samples evaluated: 18820, Average perplexity: 1.6572265625\n",
            "Number of samples evaluated: 18830, Average perplexity: 1.6572265625\n",
            "Number of samples evaluated: 18840, Average perplexity: 1.6572265625\n",
            "Number of samples evaluated: 18850, Average perplexity: 1.65625\n",
            "Number of samples evaluated: 18860, Average perplexity: 1.65625\n",
            "Number of samples evaluated: 18870, Average perplexity: 1.6552734375\n",
            "Number of samples evaluated: 18880, Average perplexity: 1.6552734375\n",
            "Number of samples evaluated: 18890, Average perplexity: 1.654296875\n",
            "Number of samples evaluated: 18900, Average perplexity: 1.654296875\n",
            "Number of samples evaluated: 18910, Average perplexity: 1.6533203125\n",
            "Number of samples evaluated: 18920, Average perplexity: 1.6533203125\n",
            "Number of samples evaluated: 18930, Average perplexity: 1.65234375\n",
            "Number of samples evaluated: 18940, Average perplexity: 1.65234375\n",
            "Number of samples evaluated: 18950, Average perplexity: 1.65234375\n",
            "Number of samples evaluated: 18960, Average perplexity: 1.6513671875\n",
            "Number of samples evaluated: 18970, Average perplexity: 1.6513671875\n",
            "Number of samples evaluated: 18980, Average perplexity: 1.650390625\n",
            "Number of samples evaluated: 18990, Average perplexity: 1.650390625\n",
            "Number of samples evaluated: 19000, Average perplexity: 1.6494140625\n",
            "Number of samples evaluated: 19010, Average perplexity: 1.6494140625\n",
            "Number of samples evaluated: 19020, Average perplexity: 1.6484375\n",
            "Number of samples evaluated: 19030, Average perplexity: 1.6484375\n",
            "Number of samples evaluated: 19040, Average perplexity: 1.6474609375\n",
            "Number of samples evaluated: 19050, Average perplexity: 1.6474609375\n",
            "Number of samples evaluated: 19060, Average perplexity: 1.6474609375\n",
            "Number of samples evaluated: 19070, Average perplexity: 1.646484375\n",
            "Number of samples evaluated: 19080, Average perplexity: 1.646484375\n",
            "Number of samples evaluated: 19090, Average perplexity: 1.6455078125\n",
            "Number of samples evaluated: 19100, Average perplexity: 1.6455078125\n",
            "Number of samples evaluated: 19110, Average perplexity: 1.6455078125\n",
            "Number of samples evaluated: 19120, Average perplexity: 1.64453125\n",
            "Number of samples evaluated: 19130, Average perplexity: 1.64453125\n",
            "Number of samples evaluated: 19140, Average perplexity: 1.6435546875\n",
            "Number of samples evaluated: 19150, Average perplexity: 1.6435546875\n",
            "Number of samples evaluated: 19160, Average perplexity: 1.642578125\n",
            "Number of samples evaluated: 19170, Average perplexity: 1.642578125\n",
            "Number of samples evaluated: 19180, Average perplexity: 1.6416015625\n",
            "Number of samples evaluated: 19190, Average perplexity: 1.6416015625\n",
            "Number of samples evaluated: 19200, Average perplexity: 1.640625\n",
            "Number of samples evaluated: 19210, Average perplexity: 1.640625\n",
            "Number of samples evaluated: 19220, Average perplexity: 1.640625\n",
            "Number of samples evaluated: 19230, Average perplexity: 1.640625\n",
            "Number of samples evaluated: 19240, Average perplexity: 1.640625\n",
            "Number of samples evaluated: 19250, Average perplexity: 1.6396484375\n",
            "Number of samples evaluated: 19260, Average perplexity: 1.6396484375\n",
            "Number of samples evaluated: 19270, Average perplexity: 1.638671875\n",
            "Number of samples evaluated: 19280, Average perplexity: 1.638671875\n",
            "Number of samples evaluated: 19290, Average perplexity: 1.6376953125\n",
            "Number of samples evaluated: 19300, Average perplexity: 1.6376953125\n",
            "Number of samples evaluated: 19310, Average perplexity: 1.63671875\n",
            "Number of samples evaluated: 19320, Average perplexity: 1.63671875\n",
            "Number of samples evaluated: 19330, Average perplexity: 1.63671875\n",
            "Number of samples evaluated: 19340, Average perplexity: 1.6357421875\n",
            "Number of samples evaluated: 19350, Average perplexity: 1.6357421875\n",
            "Number of samples evaluated: 19360, Average perplexity: 1.634765625\n",
            "Number of samples evaluated: 19370, Average perplexity: 1.634765625\n",
            "Number of samples evaluated: 19380, Average perplexity: 1.634765625\n",
            "Number of samples evaluated: 19390, Average perplexity: 1.6337890625\n",
            "Number of samples evaluated: 19400, Average perplexity: 1.6337890625\n",
            "Number of samples evaluated: 19410, Average perplexity: 1.6328125\n",
            "Number of samples evaluated: 19420, Average perplexity: 1.6328125\n",
            "Number of samples evaluated: 19430, Average perplexity: 1.6318359375\n",
            "Number of samples evaluated: 19440, Average perplexity: 1.6318359375\n",
            "Number of samples evaluated: 19450, Average perplexity: 1.6318359375\n",
            "Number of samples evaluated: 19460, Average perplexity: 1.6318359375\n",
            "Number of samples evaluated: 19470, Average perplexity: 1.630859375\n",
            "Number of samples evaluated: 19480, Average perplexity: 1.630859375\n",
            "Number of samples evaluated: 19490, Average perplexity: 1.6298828125\n",
            "Number of samples evaluated: 19500, Average perplexity: 1.6298828125\n",
            "Number of samples evaluated: 19510, Average perplexity: 1.6298828125\n",
            "Number of samples evaluated: 19520, Average perplexity: 1.62890625\n",
            "Number of samples evaluated: 19530, Average perplexity: 1.6298828125\n",
            "Number of samples evaluated: 19540, Average perplexity: 1.6298828125\n",
            "Number of samples evaluated: 19550, Average perplexity: 1.6298828125\n",
            "Number of samples evaluated: 19560, Average perplexity: 1.62890625\n",
            "Number of samples evaluated: 19570, Average perplexity: 1.62890625\n",
            "Number of samples evaluated: 19580, Average perplexity: 1.6279296875\n",
            "Number of samples evaluated: 19590, Average perplexity: 1.6279296875\n",
            "Number of samples evaluated: 19600, Average perplexity: 1.62890625\n",
            "Number of samples evaluated: 19610, Average perplexity: 1.62890625\n",
            "Number of samples evaluated: 19620, Average perplexity: 1.6279296875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#last_hidden_states = outputs.last_hidden_state\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "tokenized = tokenizer(prompts[0], return_tensors=\"pt\")\n",
        "input_ids = tokenized.input_ids.to(device)\n",
        "attention_mask = tokenized.attention_mask.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "  output = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask,\n",
        "      # pad_token_id=tokenizer.eos_token_id,\n",
        "      # do_sample=False,\n",
        "      # temperature=1,\n",
        "      # max_length=2048,\n",
        "  )\n",
        "output"
      ],
      "metadata": {
        "id": "Z5WlOfjK8ejR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(prompts[0], return_tensors=\"pt\").attention_mask.shape"
      ],
      "metadata": {
        "id": "ccWZbNiuAPSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar balanceamento\n",
        "# Obter baseline (perplexidade) com predict de proxima palavra no IMDB em paralelo. Fixar N amostras para obter essas avaliações.\n",
        "# Implementar um pruning de uma cabeça especificada por um indice"
      ],
      "metadata": {
        "id": "kstjihUo7hom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwhTqfm3OpPE"
      },
      "outputs": [],
      "source": [
        "# Acuracia no treino: 93%, NUM_INFERENCE_SAMPLES: 200 5 examples, 93,5% com 7 exemplos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGdKU0iO-dr7"
      },
      "outputs": [],
      "source": [
        "# Acuracia no teste: 93,5%, NUM_INFERENCE_SAMPLES: 200 5 examples"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Pruning - GPT-J - Sentiment Analysis",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "332d26fba85f40139fbe10b83c30d2eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1112eaa0351e45b287278408131f4748",
              "IPY_MODEL_b6f1d6d03d0642179258d0a296404a22",
              "IPY_MODEL_106621504092406dbf11c7e8e310873c"
            ],
            "layout": "IPY_MODEL_51ab14f3c95a4d5ca7cd3f70e3027b9c"
          }
        },
        "1112eaa0351e45b287278408131f4748": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cea11e81dbb24eeaaae0d027dae7cc35",
            "placeholder": "​",
            "style": "IPY_MODEL_07347a64789e447d82518c8038ddca72",
            "value": "100%"
          }
        },
        "b6f1d6d03d0642179258d0a296404a22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f6baf71b6da4965bc0e0509535111cc",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_41113ff3877842eeb27521656d875c38",
            "value": 3
          }
        },
        "106621504092406dbf11c7e8e310873c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77af4bfa7a97490ab60885d4c1fe8383",
            "placeholder": "​",
            "style": "IPY_MODEL_5a541bbb71c741c9bd7b0b7087f377b1",
            "value": " 3/3 [00:00&lt;00:00, 71.05it/s]"
          }
        },
        "51ab14f3c95a4d5ca7cd3f70e3027b9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cea11e81dbb24eeaaae0d027dae7cc35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07347a64789e447d82518c8038ddca72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f6baf71b6da4965bc0e0509535111cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41113ff3877842eeb27521656d875c38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "77af4bfa7a97490ab60885d4c1fe8383": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a541bbb71c741c9bd7b0b7087f377b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}