{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "toc": {
      "nav_menu": {
        "height": "318px",
        "width": "252px"
      },
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "name": "Aula 4 - Exercício - Template",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabiormazza/IA025_2022S1/blob/main/Aula_4_Exerc%C3%ADcio_Template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3R2-_YuQT1r"
      },
      "source": [
        "# Regressão Softmax com dados do MNIST utilizando gradiente descendente estocástico por minibatches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkfGTqMVQT1u"
      },
      "source": [
        "Este exercicío consiste em treinar um modelo de uma única camada linear no MNIST **sem** usar as seguintes funções do pytorch:\n",
        "\n",
        "- torch.nn.Linear\n",
        "- torch.nn.CrossEntropyLoss\n",
        "- torch.nn.NLLLoss\n",
        "- torch.nn.LogSoftmax\n",
        "- torch.optim.SGD\n",
        "- torch.utils.data.Dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFNf4RPxQT1w"
      },
      "source": [
        "## Importação das bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-21T14:08:14.033692Z",
          "start_time": "2018-08-21T14:08:11.179981Z"
        },
        "id": "-fLUSHaCQT1x"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision.datasets import MNIST"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fixando as seeds"
      ],
      "metadata": {
        "id": "7_Po22b5ykhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(123)\n",
        "np.random.seed(123)\n",
        "torch.manual_seed(123)"
      ],
      "metadata": {
        "id": "y-7WWWgLyoRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEMUsfJpQT11"
      },
      "source": [
        "## Dataset e dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHoQjDs_QT12"
      },
      "source": [
        "### Definição do tamanho do minibatch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-21T14:08:20.282474Z",
          "start_time": "2018-08-21T14:08:20.275450Z"
        },
        "id": "tEQYUr4TQT13"
      },
      "source": [
        "batch_size = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc7Rv_2BQT16"
      },
      "source": [
        "### Carregamento, criação dataset e do dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-21T14:10:45.430605Z",
          "start_time": "2018-08-21T14:10:04.953051Z"
        },
        "id": "G0dEKCn-QT17"
      },
      "source": [
        "dataset_dir = '../data/'\n",
        "\n",
        "dataset_train_full = MNIST(dataset_dir, train=True, download=True,\n",
        "                           transform=torchvision.transforms.ToTensor())\n",
        "print(dataset_train_full.data.shape)\n",
        "print(dataset_train_full.targets.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rOy9ntrQT2D"
      },
      "source": [
        "### Usando apenas 1000 amostras do MNIST\n",
        "\n",
        "Neste exercício utilizaremos 1000 amostras de treinamento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNF2XjLBWWe7"
      },
      "source": [
        "indices = torch.randperm(len(dataset_train_full))[:1000]\n",
        "dataset_train = torch.utils.data.Subset(dataset_train_full, indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSNLD2JyA2e-"
      },
      "source": [
        "# Escreva aqui o equivalente do código abaixo:\n",
        "# loader_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-21T13:30:35.209157Z",
          "start_time": "2018-08-21T13:30:34.757103Z"
        },
        "id": "w52KGYlIQT2A"
      },
      "source": [
        "print('Número de minibatches de trenamento:', len(loader_train))\n",
        "\n",
        "x_train, y_train = next(iter(loader_train))\n",
        "print(\"\\nDimensões dos dados de um minibatch:\", x_train.size())\n",
        "print(\"Valores mínimo e máximo dos pixels: \", torch.min(x_train), torch.max(x_train))\n",
        "print(\"Tipo dos dados das imagens:         \", type(x_train))\n",
        "print(\"Tipo das classes das imagens:       \", type(y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQA9Zg7GQT2G"
      },
      "source": [
        "## Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-20T21:03:10.802708Z",
          "start_time": "2018-08-20T21:03:10.793287Z"
        },
        "id": "_8Eg4h_kQT2H"
      },
      "source": [
        "# Escreva aqui o codigo para criar um modelo cujo o equivalente é: \n",
        "# model = torch.nn.Linear(28*28, 10)\n",
        "# model.load_state_dict(dict(weight=torch.zeros(model.weight.shape), bias=torch.zeros(model.bias.shape)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NHQB4wGQT2K"
      },
      "source": [
        "## Treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqs2JhJoQT2L"
      },
      "source": [
        "### Inicialização dos parâmetros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-20T21:03:14.146259Z",
          "start_time": "2018-08-20T21:03:14.139515Z"
        },
        "id": "oZuYEkn_QT2M"
      },
      "source": [
        "n_epochs = 50\n",
        "lr = 0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGeMCRw5kQMU"
      },
      "source": [
        "## Definição da Loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcqFzpSTkYtk"
      },
      "source": [
        "# Escreva aqui o equivalente de:\n",
        "# criterion = torch.nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definição do Optimizer"
      ],
      "metadata": {
        "id": "01BDueU2x4ox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Escreva aqui o equivalente de:\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr)"
      ],
      "metadata": {
        "id": "tIlnR_Z8x85O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmXarXeIQT2O"
      },
      "source": [
        "### Laço de treinamento dos parâmetros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-20T21:03:40.796410Z",
          "start_time": "2018-08-20T21:03:39.771981Z"
        },
        "id": "L5T_jZZPQT2P"
      },
      "source": [
        "epochs = []\n",
        "loss_history = []\n",
        "loss_epoch_end = []\n",
        "total_trained_samples = 0\n",
        "for i in range(n_epochs):\n",
        "    # Substitua aqui o loader_train de acordo com sua implementação do dataloader.\n",
        "    for x_train, y_train in loader_train:\n",
        "        # Transforma a entrada para uma dimensão\n",
        "        inputs = x_train.view(-1, 28 * 28)\n",
        "        # predict da rede\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # calcula a perda\n",
        "        loss = criterion(outputs, y_train)\n",
        "\n",
        "        # zero, backpropagation, ajusta parâmetros pelo gradiente descendente\n",
        "        # Escreva aqui o código cujo o resultado é equivalente às 3 linhas abaixo:\n",
        "        # optimizer.zero_grad()\n",
        "        # loss.backward()\n",
        "        # optimizer.step()\n",
        "\n",
        "        total_trained_samples += x_train.size(0)\n",
        "        epochs.append(total_trained_samples / len(dataset_train))\n",
        "        loss_history.append(loss.item())\n",
        "\n",
        "    loss_epoch_end.append(loss.item())\n",
        "    print(f'Epoch: {i:d}/{n_epochs - 1:d} Loss: {loss.item()}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dYK0nqsQT2U"
      },
      "source": [
        "### Visualizando gráfico de perda durante o treinamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-20T21:03:52.026752Z",
          "start_time": "2018-08-20T21:03:51.756518Z"
        },
        "id": "LIyUI6AHQT2V"
      },
      "source": [
        "plt.plot(epochs, loss_history)\n",
        "plt.xlabel('época')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLL-GQlKQT2Y"
      },
      "source": [
        "### Visualização usual da perda, somente no final de cada minibatch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-20T21:03:55.246851Z",
          "start_time": "2018-08-20T21:03:54.994428Z"
        },
        "id": "w38EtNxhQT2Z"
      },
      "source": [
        "n_batches_train = len(loader_train)\n",
        "plt.plot(epochs[::n_batches_train], loss_history[::n_batches_train])\n",
        "plt.xlabel('época')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-20T21:03:48.786969Z",
          "start_time": "2018-08-20T21:03:48.781787Z"
        },
        "id": "PiuMsjYtQT2R"
      },
      "source": [
        "# Assert do histórico de losses\n",
        "target_loss_epoch_end = np.array([\n",
        "    1.1979684829711914,\n",
        "    0.867622971534729,\n",
        "    0.7226786613464355,\n",
        "    0.6381281018257141,\n",
        "    0.5809749960899353,\n",
        "    0.5387411713600159,\n",
        "    0.5056464076042175,\n",
        "    0.4786270558834076,\n",
        "    0.4558936357498169,\n",
        "    0.4363219141960144,\n",
        "    0.4191650450229645,\n",
        "    0.4039044976234436,\n",
        "    0.3901679515838623,\n",
        "    0.3776799440383911,\n",
        "    0.3662314713001251,\n",
        "    0.35566139221191406,\n",
        "    0.34584277868270874,\n",
        "    0.33667415380477905,\n",
        "    0.32807353138923645,\n",
        "    0.31997355818748474,\n",
        "    0.312318354845047,\n",
        "    0.3050611615180969,\n",
        "    0.29816246032714844,\n",
        "    0.29158851504325867,\n",
        "    0.28531041741371155,\n",
        "    0.2793029546737671,\n",
        "    0.273544579744339,\n",
        "    0.2680158317089081,\n",
        "    0.26270008087158203,\n",
        "    0.2575823664665222,\n",
        "    0.25264936685562134,\n",
        "    0.24788929522037506,\n",
        "    0.24329163134098053,\n",
        "    0.23884665966033936,\n",
        "    0.23454584181308746,\n",
        "    0.23038141429424286,\n",
        "    0.22634628415107727,\n",
        "    0.22243399918079376,\n",
        "    0.2186385989189148,\n",
        "    0.21495483815670013,\n",
        "    0.21137762069702148,\n",
        "    0.20790249109268188,\n",
        "    0.20452524721622467,\n",
        "    0.20124195516109467,\n",
        "    0.19804897904396057,\n",
        "    0.1949428766965866,\n",
        "    0.19192075729370117,\n",
        "    0.188979372382164,\n",
        "    0.18611609935760498,\n",
        "    0.1833282858133316])\n",
        "\n",
        "assert np.allclose(np.array(loss_epoch_end), target_loss_epoch_end, atol=1e-6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fptnTktx_1rh"
      },
      "source": [
        "## Exercício \n",
        "\n",
        "Escreva um código que responda às seguintes perguntas:\n",
        "\n",
        "Qual é a amostra classificada corretamente, com maior probabilidade?\n",
        "\n",
        "Qual é a amostra classificada erradamente, com maior probabilidade?\n",
        "\n",
        "Qual é a amostra classificada corretamente, com menor probabilidade?\n",
        "\n",
        "Qual é a amostra classificada erradamente, com menor probabilidade?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzH8iMGt_1Rr"
      },
      "source": [
        "# Escreva o código aqui:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xmj1GWXUoNs"
      },
      "source": [
        "## Exercício Bonus\n",
        "\n",
        "Implemente um dataloader que aceite como parâmetro de entrada a distribuição probabilidade das classes que deverão compor um batch.\n",
        "Por exemplo, se a distribuição de probabilidade passada como entrada for:\n",
        "\n",
        "`[0.01, 0.01, 0.72, 0.2, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01]`\n",
        "\n",
        "Em média, 72% dos exemplos do batch deverão ser da classe 2, 20% deverão ser da classe 3, e os demais deverão ser das outras classes.\n",
        "\n",
        "Mostre também que sua implementação está correta.\n"
      ]
    }
  ]
}