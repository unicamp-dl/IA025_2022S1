{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercícios IA025 - Pedro Guilherme Siqueira Moreira",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {
        "height": "117px",
        "width": "252px"
      },
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pg1992/IA025_2022S1/blob/pedro_moreira/ex01/pedro_moreira/solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTVOQpMfhgLM"
      },
      "source": [
        "Esté um notebook Colab contendo exercícios de programação em python, numpy e pytorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMoyGt5gXMgK"
      },
      "source": [
        "## Coloque seu nome"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBHbXcibXPRe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "442710a5-cad6-4c39-fcd3-b8bc05fd59ad"
      },
      "source": [
        "print('Meu nome é: Pedro Guilherme Siqueira Moreira')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meu nome é: Pedro Guilherme Siqueira Moreira\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9S5acRbm1Zr"
      },
      "source": [
        "# Parte 1:\n",
        "\n",
        "##Exercícios de Processamento de Dados\n",
        "\n",
        "Nesta parte pode-se usar as bibliotecas nativas do python como a `collections`, `re` e `random`. Também pode-se usar o NumPy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxS5h1V8nDn6"
      },
      "source": [
        "##Exercício 1.1\n",
        "Crie um dicionário com os `k` itens mais frequentes de uma lista.\n",
        "\n",
        "Por exemplo, dada a lista de itens `L=['a', 'a', 'd', 'b', 'd', 'c', 'e', 'a', 'b', 'e', 'e', 'a']` e `k=2`, o resultado deve ser um dicionário cuja chave é o item e o valor é a sua frequência: {'a': 4, 'e': 3}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gT08b5Z_nC-j"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "def top_k(L, k):\n",
        "    return dict(Counter(L).most_common(k))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLD_e3C9p4xO"
      },
      "source": [
        "Mostre que sua implementação está correta usando uma entrada com poucos itens:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMW9NiBgnkvA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a14c19f7-91df-46cf-dfcd-0abcf44e634b"
      },
      "source": [
        "L = ['f', 'a', 'a', 'd', 'b', 'd', 'c', 'e', 'a', 'b', 'e', 'e', 'a', 'd']\n",
        "k = 3\n",
        "resultado = top_k(L=L, k=k)\n",
        "print(f'resultado: {resultado}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resultado: {'a': 4, 'd': 3, 'e': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBeqZScQqJ0a"
      },
      "source": [
        "Mostre que sua implementação é eficiente usando uma entrada com 10M de itens:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_lhcm4ko8bY"
      },
      "source": [
        "import random\n",
        "L = random.choices('abcdefghijklmnopqrstuvwxyz', k=10_000_000)\n",
        "k = 10000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9U-Bgs2o-f_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3dc9356-eb66-48b0-d9ed-c6a62458202f"
      },
      "source": [
        "%%timeit\n",
        "resultado = top_k(L=L, k=k)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 570 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJHDaOz_tK38"
      },
      "source": [
        "## Exercício 1.2\n",
        "\n",
        "Em processamento de linguagem natural, é comum convertemos as palavras de um texto para uma lista de identificadores dessas palavras. Dado o dicionário `V` abaixo onde as chaves são palavras e os valores são seus respectivos identificadores, converta o texto `D` para uma lista de identificadores.\n",
        "\n",
        "Palavras que não existem no dicionário deverão ser convertidas para o identificador do token `unknown`.\n",
        "\n",
        "O código deve ser insensível a maiúsculas (case-insensitive).\n",
        "\n",
        "Se atente que pontuações (vírgulas, ponto final, etc) também são consideradas palavras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVzv89trtTPc"
      },
      "source": [
        "import re\n",
        "\n",
        "def tokens_to_ids(text, vocabulary):\n",
        "  p = re.compile(r'\\w+|\\.')\n",
        "  l = p.findall(text.lower())\n",
        "  return [vocabulary.get(x, -1) for x in l]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCGZeiqkY-sm"
      },
      "source": [
        "Mostre que sua implementação esta correta com um exemplo pequeno:\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iApR1h7gY98E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bc79be3-00fe-4179-ef4a-cbafb5d730c0"
      },
      "source": [
        "V = {'eu': 1, 'de': 2, 'gosto': 3, 'comer': 4, '.': 5, 'unknown': -1}\n",
        "D = 'Eu gosto de comer pizza.'\n",
        "\n",
        "print(tokens_to_ids(D, V))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 3, 2, 4, -1, 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWtTMxlXZN25"
      },
      "source": [
        "Mostre que sua implementação é eficiente com um exemplo grande:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxT_g-ZxZUsX"
      },
      "source": [
        "V = {'eu': 1, 'de': 2, 'gosto': 3, 'comer': 4, '.': 5, 'unknown': -1}\n",
        "D = ' '.join(1_000_000 * ['Eu gosto de comer pizza.'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kp1nataGZU-V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5daf6cc2-b806-4628-f980-7c993f7df989"
      },
      "source": [
        "%%timeit\n",
        "resultado = tokens_to_ids(D, V)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 2.28 s per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRfaKfXwRXn_"
      },
      "source": [
        "## Exercício 1.3\n",
        "\n",
        "Em aprendizado profundo é comum termos que lidar com arquivos muito grandes.\n",
        "\n",
        "Dado um arquivo de texto onde cada item é separado por `\\n`, escreva um programa que amostre `k` itens desse arquivo aleatoriamente.\n",
        "\n",
        "Nota 1: Assuma amostragem de uma distribuição uniforme, ou seja, todos os itens tem a mesma probablidade de amostragem.\n",
        "\n",
        "Nota 2: Assuma que o arquivo não cabe em memória.\n",
        "\n",
        "Nota 3: Utilize apenas bibliotecas nativas do python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PsadE9SRG_9"
      },
      "source": [
        "import random\n",
        "\n",
        "def sample(path: str, k: int):\n",
        "    with open(path, 'r') as fd:\n",
        "      return random.choices(fd.readlines(), k=k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycEnlFWxSt0i"
      },
      "source": [
        "Mostre que sua implementação está correta com um exemplo pequeno:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyLJ1e2ZSzC9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60537455-e255-4184-8d74-a8c2b6a9df5c"
      },
      "source": [
        "filename = 'small.txt'\n",
        "total_size = 100\n",
        "n_samples = 10\n",
        "\n",
        "with open(filename, 'w') as fout:\n",
        "    fout.write('\\n'.join(f'line {i}' for i in range(total_size)))\n",
        "\n",
        "samples = sample(path=filename, k=n_samples)\n",
        "print(samples)\n",
        "print(len(samples) == n_samples)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['line 84\\n', 'line 12\\n', 'line 5\\n', 'line 14\\n', 'line 63\\n', 'line 59\\n', 'line 54\\n', 'line 76\\n', 'line 62\\n', 'line 27\\n']\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2r4FMiMj12Xg"
      },
      "source": [
        "Mostre que sua implementação é eficiente com um exemplo grande:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUwnNMGg18Ty"
      },
      "source": [
        "filename = 'large.txt'\n",
        "total_size = 1_000_000\n",
        "n_samples = 10000\n",
        "\n",
        "with open(filename, 'w') as fout:\n",
        "    fout.write('\\n'.join(f'line {i}' for i in range(total_size)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA9sAZmo0UDN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c037c69-99d5-4855-dea7-cfbb94306793"
      },
      "source": [
        "%%timeit\n",
        "samples = sample(path=filename, k=n_samples)\n",
        "assert len(samples) == n_samples"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 loops, best of 5: 90 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udS0Ns4etoJs"
      },
      "source": [
        "# Parte 2:\n",
        "\n",
        "##Exercícios de Numpy\n",
        "\n",
        "Nesta parte deve-se usar apenas a biblioteca NumPy. Aqui não se pode usar o PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcMz3Vzjt144"
      },
      "source": [
        "##Exercício 2.1\n",
        "\n",
        "Quantos operações de ponto flutuante (flops) de soma e de multiplicação tem a multiplicação matricial $AB$, sendo que a matriz $A$ tem tamanho $m \\times n$ e a matriz $B$ tem tamanho $n \\times p$?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gNXj45RJqUm"
      },
      "source": [
        "Resposta:\n",
        "- número de somas: $m \\cdot (n - 1) \\cdot p$\n",
        "- número de multiplicações: $m \\cdot n \\cdot p$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iI7udBFeDlP"
      },
      "source": [
        "## Exercício 2.2\n",
        "\n",
        "Em programação matricial, não se faz o loop em cada elemento da matriz,\n",
        "mas sim, utiliza-se operações matriciais.\n",
        "\n",
        "Dada a matriz `A` abaixo, calcule a média dos valores de cada linha sem utilizar laços explícitos.\n",
        "\n",
        "Utilize apenas a biblioteca numpy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjrXf18N5KrK"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fqxgNBW27Z0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f1468ed-2434-4bd2-9822-744f83564780"
      },
      "source": [
        "A = np.arange(24).reshape(4, 6)\n",
        "print(A)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  1  2  3  4  5]\n",
            " [ 6  7  8  9 10 11]\n",
            " [12 13 14 15 16 17]\n",
            " [18 19 20 21 22 23]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1EmKFrT5g7B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26afab93-f3ea-4093-ceb4-e4ec775942ec"
      },
      "source": [
        "A_mean = np.mean(A, axis=1)\n",
        "print(A_mean)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 2.5  8.5 14.5 20.5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtgSAAKjUfcO"
      },
      "source": [
        "## Exercício 2.3\n",
        "\n",
        "Seja a matriz $C$ que é a normalização da matriz $A$:\n",
        "$$ C(i,j) = \\frac{A(i,j) - A_{min}}{A_{max} - A_{min}} $$\n",
        "\n",
        "Normalizar a matriz `A` do exercício acima de forma que seus valores fiquem entre 0 e 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-12-11T00:00:34.072719Z",
          "start_time": "2019-12-11T00:00:34.036017Z"
        },
        "id": "_pDhb2-0eDlS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f914ce21-3b1a-4b29-8438-4f2aee52efa0"
      },
      "source": [
        "A_min = np.min(A)\n",
        "A_max = np.max(A)\n",
        "C = (A - A_min) / (A_max - A_min)\n",
        "print(C)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.04347826 0.08695652 0.13043478 0.17391304 0.2173913 ]\n",
            " [0.26086957 0.30434783 0.34782609 0.39130435 0.43478261 0.47826087]\n",
            " [0.52173913 0.56521739 0.60869565 0.65217391 0.69565217 0.73913043]\n",
            " [0.7826087  0.82608696 0.86956522 0.91304348 0.95652174 1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF_P_GARU62m"
      },
      "source": [
        "## Exercício 2.4\n",
        "\n",
        "Modificar o exercício anterior de forma que os valores de cada *coluna* da matriz `A` sejam normalizados entre 0 e 1 independentemente dos valores das outras colunas.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NgVzFOYeDla",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ac8151d-85fd-4c01-8d74-db689d951b11"
      },
      "source": [
        "A_col_min = np.min(A, axis=0)\n",
        "A_col_max = np.max(A, axis=0)\n",
        "C_col = (A - A_col_min) / (A_col_max - A_col_min)\n",
        "print(C_col)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.         0.         0.         0.         0.        ]\n",
            " [0.33333333 0.33333333 0.33333333 0.33333333 0.33333333 0.33333333]\n",
            " [0.66666667 0.66666667 0.66666667 0.66666667 0.66666667 0.66666667]\n",
            " [1.         1.         1.         1.         1.         1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbXIXsDIUmtp"
      },
      "source": [
        "## Exercício 2.5\n",
        "\n",
        "Modificar o exercício anterior de forma que os valores de cada *linha* da matriz `A` sejam normalizados entre 0 e 1 independentemente dos valores das outras linhas.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-12-10T17:56:40.413601Z",
          "start_time": "2019-12-10T17:56:40.405056Z"
        },
        "id": "i-5Hv8-heDlW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5bc499b-db49-40be-a42f-2d0e902bd04c"
      },
      "source": [
        "A_row_min = np.min(A, axis=1)[:, np.newaxis]\n",
        "A_row_max = np.max(A, axis=1)[:, np.newaxis]\n",
        "C_row = (A - A_row_min) / (A_row_max - A_row_min)\n",
        "print(C_row)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.  0.2 0.4 0.6 0.8 1. ]\n",
            " [0.  0.2 0.4 0.6 0.8 1. ]\n",
            " [0.  0.2 0.4 0.6 0.8 1. ]\n",
            " [0.  0.2 0.4 0.6 0.8 1. ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKnLAyL7zgpa"
      },
      "source": [
        "## Exercício 2.6\n",
        "\n",
        "A [função softmax](https://en.wikipedia.org/wiki/Softmax_function) é bastante usada em apredizado de máquina para converter uma lista de números para uma distribuição de probabilidade, isto é, os números ficarão normalizados entre zero e um e sua soma será igual à um.\n",
        "\n",
        "Implemente a função softmax com suporte para batches, ou seja, o softmax deve ser aplicado a cada linha da matriz. Deve-se usar apenas a biblioteca numpy. Se atente que a exponenciação gera estouro de representação quando os números da entrada são muito grandes. Tente corrigir isto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lA5W9vxNEmOj"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def softmax(A):\n",
        "    '''\n",
        "    Aplica a função de softmax à matriz `A`.\n",
        "\n",
        "    Entrada:\n",
        "      `A` é uma matriz M x N, onde M é o número de exemplos a serem processados\n",
        "      independentemente e N é o tamanho de cada exemplo.\n",
        "    \n",
        "    Saída:\n",
        "      Uma matriz M x N, onde a soma de cada linha é igual a um.\n",
        "    '''\n",
        "    A_norm = A - np.max(A, axis=1)[:, np.newaxis]\n",
        "    exps = np.exp(A_norm)\n",
        "    return exps / np.sum(exps, axis=1)[:, np.newaxis]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpxlbh4ND54q"
      },
      "source": [
        "Mostre que sua implementação está correta usando uma matriz pequena como entrada:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6EZ5ZD7HFao",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bfe46f8-279c-4a5e-c672-e36c0ed3b6cf"
      },
      "source": [
        "A = np.array([[0.5, -1, 1000],\n",
        "              [-2,   0, 0.5]])\n",
        "softmax(A)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 1.        ],\n",
              "       [0.04861082, 0.35918811, 0.59220107]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9j2uXmKH8HF4"
      },
      "source": [
        "O código a seguir verifica se sua implementação do softmax está correta. \n",
        "- A soma de cada linha de A deve ser 1;\n",
        "- Os valores devem estar entre 0 e 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-sN4STk7qyN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c624a4d-b6e7-416d-e9ad-a27c199cbe01"
      },
      "source": [
        "np.allclose(softmax(A).sum(axis=1), 1) and softmax(A).min() >= 0 and softmax(A).max() <= 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5_ZRWRfCZtI"
      },
      "source": [
        "Mostre que sua implementação é eficiente usando uma matriz grande como entrada:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhUeyrGaJ3J2"
      },
      "source": [
        "A = np.random.uniform(low=-10, high=10, size=(128, 100_000))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaa-C8XkKJin",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39117390-024e-48c4-d02f-08730ce614e1"
      },
      "source": [
        "%%timeit\n",
        "softmax(A)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 276 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XE6LaWi81zZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae179e56-11a2-4d01-ce82-565547f78b81"
      },
      "source": [
        "SM = softmax(A)\n",
        "np.allclose(SM.sum(axis=1), 1) and SM.min() >= 0 and SM.max() <= 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Flr1lI5o-HpG"
      },
      "source": [
        "## Exercício 2.7\n",
        "\n",
        "A codificação one-hot é usada para codificar entradas categóricas. É uma codificação onde apenas um bit é 1 e os demais são zero, conforme a tabela a seguir.\n",
        "\n",
        "| Decimal | Binary | One-hot\n",
        "| ------- | ------ | -------\n",
        "| 0 | 000    | 1 0 0 0 0 0 0 0\n",
        "| 1 | 001    | 0 1 0 0 0 0 0 0\n",
        "| 2 | 010    | 0 0 1 0 0 0 0 0\n",
        "| 3 | 011    | 0 0 0 1 0 0 0 0\n",
        "| 4 | 100    | 0 0 0 0 1 0 0 0\n",
        "| 5 | 101    | 0 0 0 0 0 1 0 0\n",
        "| 6 | 110    | 0 0 0 0 0 0 1 0\n",
        "| 7 | 111    | 0 0 0 0 0 0 0 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CqXP_5ABbfo"
      },
      "source": [
        "Implemente a função one_hot(y, n_classes) que codifique o vetor de inteiros y que possuem valores entre 0 e n_classes-1.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "la-02w7qCH7L"
      },
      "source": [
        "def one_hot(y, n_classes):\n",
        "    return np.ones(y.size, dtype=int) << (n_classes - 1 - y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zf5zyZO5Aiz_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f33b4eef-cf4d-41eb-a1b8-3fb65bb8cdd9"
      },
      "source": [
        "N_CLASSES = 9\n",
        "N_SAMPLES = 10\n",
        "y = (np.random.rand((N_SAMPLES)) * N_CLASSES).astype(np.int)\n",
        "print(y)\n",
        "print(one_hot(y, N_CLASSES))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6 8 7 4 0 0 0 2 6 6]\n",
            "[  4   1   2  16 256 256 256  64   4   4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nwuKnQUCzve"
      },
      "source": [
        "Mostre que sua implementação é eficiente usando uma matriz grande como entrada:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwuFy5rWC2tA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57dab222-3eb8-40d4-f2d0-ce393dfb2429"
      },
      "source": [
        "N_SAMPLES = 100_000\n",
        "N_CLASSES = 1_000\n",
        "y = (np.random.rand((N_SAMPLES)) * N_CLASSES).astype(np.int)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7azMtF7wDJ2_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2753fa70-b433-4532-ebc8-0a139d27979b"
      },
      "source": [
        "%%timeit\n",
        "one_hot(y, N_CLASSES)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000 loops, best of 5: 442 µs per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqMroZay2ubi"
      },
      "source": [
        "## Exercício 2.8\n",
        "\n",
        "Implemente uma classe que normalize um array de pontos flutuantes `array_a` para a mesma média e desvio padrão de um outro array `array_b`, conforme exemplo abaixo:\n",
        "```\n",
        "array_a = np.array([-1, 1.5, 0])\n",
        "array_b = np.array([1.4, 0.8, 0.3, 2.5])\n",
        "normalize = Normalizer(array_b)\n",
        "normalized_array = normalize(array_a)\n",
        "print(normalized_array)  # Deve imprimir [0.3187798  2.31425165 1.11696854]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaedJ5Cf5Oy2"
      },
      "source": [
        "def Normalizer(arr):\n",
        "  std = np.std(arr)\n",
        "  mean = np.mean(arr)\n",
        "  def n(arr_b):\n",
        "    a = (arr_b - np.mean(arr_b)) / np.std(arr_b)\n",
        "    return a * std + mean\n",
        "  return n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlkNNU6h5RbR"
      },
      "source": [
        "Mostre que seu código está correto com o exemplo abaixo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gad6zsbh5a0D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b316e921-d1b2-4b48-a909-84ff3cb93ea1"
      },
      "source": [
        "array_a = [-1, 1.5, 0]\n",
        "array_b = [1.4, 0.8, 0.3, 2.5]\n",
        "normalize = Normalizer(array_b)\n",
        "normalized_array = normalize(array_a)\n",
        "print(normalized_array)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.3187798  2.31425165 1.11696854]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrGVQFUYI_LP"
      },
      "source": [
        "# Parte 3:\n",
        "\n",
        "##Exercícios Pytorch: Grafo Computacional e Gradientes\n",
        "\n",
        "Nesta parte pode-se usar quaisquer bibliotecas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIlQdKAuCZtR"
      },
      "source": [
        "Um dos principais fundamentos para que o PyTorch seja adequado para deep learning é a sua habilidade de calcular o gradiente automaticamente a partir da expressões definidas. Essa facilidade é implementada através do cálculo automático do gradiente e construção dinâmica do grafo computacional."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF_-dJ2nCZtT"
      },
      "source": [
        "## Grafo computacional\n",
        "\n",
        "Seja um exemplo simples de uma função de perda J dada pela Soma dos Erros ao Quadrado (SEQ - Sum of Squared Errors): \n",
        "$$ J = \\sum_i (x_i w - y_i)^2 $$\n",
        "que pode ser reescrita como:\n",
        "$$ \\hat{y_i} = x_i w $$\n",
        "$$ e_i = \\hat{y_i} - y_i $$\n",
        "$$ e2_i = e_i^2 $$\n",
        "$$ J = \\sum_i e2_i $$\n",
        "\n",
        "As redes neurais são treinadas através da minimização de uma função de perda usando o método do gradiente descendente. Para ajustar o parâmetro $w$ precisamos calcular o gradiente $  \\frac{ \\partial J}{\\partial w} $. Usando a\n",
        "regra da cadeia podemos escrever:\n",
        "$$ \\frac{ \\partial J}{\\partial w} = \\frac{ \\partial J}{\\partial e2_i} \\frac{ \\partial e2_i}{\\partial e_i} \\frac{ \\partial e_i}{\\partial \\hat{y_i} } \\frac{ \\partial \\hat{y_i}}{\\partial w}$$ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jboejVQMCZtU"
      },
      "source": [
        "```\n",
        "    y_pred = x * w\n",
        "    e = y_pred - y\n",
        "    e2 = e**2\n",
        "    J = e2.sum()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7JmU6qhc2Y2"
      },
      "source": [
        "As quatro expressões acima, para o cálculo do J podem ser representadas pelo grafo computacional visualizado a seguir: os círculos são as variáveis (tensores), os quadrados são as operações, os números em preto são os cálculos durante a execução das quatro expressões para calcular o J (forward, predict). O cálculo do gradiente, mostrado em vermelho, é calculado pela regra da cadeia, de trás para frente (backward)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeeEBKl4CZtV"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/robertoalotufo/files/master/figures/GrafoComputacional.png\" width=\"600pt\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yZun7wrCZtX"
      },
      "source": [
        "Para entender melhor o funcionamento do grafo computacional com os tensores, recomenda-se leitura em:\n",
        "\n",
        "https://pytorch.org/docs/stable/notes/autograd.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-12-11T00:23:00.431853Z",
          "start_time": "2019-12-11T00:23:00.414813Z"
        },
        "id": "HlT2d-4fCZtZ"
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-12-11T00:23:00.863228Z",
          "start_time": "2019-12-11T00:23:00.844457Z"
        },
        "id": "xX0QwUduCZtf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6b217c3c-4c99-430a-a1a9-af48da410497"
      },
      "source": [
        "torch.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.10.0+cu111'"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsqzALS4CZtl"
      },
      "source": [
        "**Tensor com atributo .requires_grad=True**\n",
        "\n",
        "Quando um tensor possui o atributo `requires_grad` como verdadeiro, qualquer expressão que utilizar esse tensor irá construir um grafo computacional para permitir posteriormente, após calcular a função a ser derivada, poder usar a regra da cadeia e calcular o gradiente da função em termos dos tensores que possuem o atributo `requires_grad`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-29T03:07:22.117010Z",
          "start_time": "2019-09-29T03:07:22.041861Z"
        },
        "id": "foaAb94aCZtm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "070a1092-b434-432e-f22d-e4bbe58cdeeb"
      },
      "source": [
        "y = torch.arange(0, 8, 2).float()\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 2., 4., 6.])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-29T03:07:28.610934Z",
          "start_time": "2019-09-29T03:07:28.598223Z"
        },
        "id": "no6SdSyICZtr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "535ef031-d909-43de-ca29-fd429d2a5057"
      },
      "source": [
        "x = torch.arange(0, 4).float()\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 1., 2., 3.])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-29T03:07:31.523762Z",
          "start_time": "2019-09-29T03:07:31.497683Z"
        },
        "id": "eL_i1mwGCZtw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9f74b83-fcaa-489e-b9e7-c05121f89668"
      },
      "source": [
        "w = torch.ones(1, requires_grad=True)\n",
        "w"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjEl-0l7CZt0"
      },
      "source": [
        "## Cálculo automático do gradiente da função perda J"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pUh-SCnCZt1"
      },
      "source": [
        "Seja a expressão: $$ J = \\sum_i ((x_i  w) - y_i)^2 $$\n",
        "\n",
        "Queremos calcular a derivada de $J$ em relação a $w$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMwwVtJ1CZt2"
      },
      "source": [
        "## Forward pass\n",
        "\n",
        "Durante a execução da expressão, o grafo computacional é criado. Compare os valores de cada parcela calculada com os valores em preto da figura ilustrativa do grafo computacional."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-29T03:07:36.290122Z",
          "start_time": "2019-09-29T03:07:36.273229Z"
        },
        "id": "zp2aK4YhCZt3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f63856fb-afad-4dfa-ba3e-a58e36c2c6be"
      },
      "source": [
        "# predict (forward)\n",
        "y_pred = x * w; print('y_pred =', y_pred)\n",
        "\n",
        "# cálculo da perda J: loss\n",
        "e = y_pred - y; print('e =',e)\n",
        "e2 = e.pow(2) ; print('e2 =', e2)\n",
        "J = e2.sum()  ; print('J =', J)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_pred = tensor([0., 1., 2., 3.], grad_fn=<MulBackward0>)\n",
            "e = tensor([ 0., -1., -2., -3.], grad_fn=<SubBackward0>)\n",
            "e2 = tensor([0., 1., 4., 9.], grad_fn=<PowBackward0>)\n",
            "J = tensor(14., grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC96wB7PCZt8"
      },
      "source": [
        "## Backward pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-10-04T15:55:45.308858",
          "start_time": "2017-10-04T15:55:45.304654"
        },
        "id": "kKbf4D0CCZt-"
      },
      "source": [
        "O `backward()` varre o grafo computacional a partir da variável a ele associada (raiz) e calcula o gradiente para todos os tensores que possuem o atributo `requires_grad` como verdadeiro.\n",
        "Observe que os tensores que tiverem o atributo `requires_grad` serão sempre folhas no grafo computacional.\n",
        "O `backward()` destroi o grafo após sua execução. Esse comportamento é padrão no PyTorch. \n",
        "\n",
        "A título ilustrativo, se quisermos depurar os gradientes dos nós que não são folhas no grafo computacional, precisamos primeiro invocar `retain_grad()` em cada um desses nós, como a seguir. Entretanto nos exemplos reais não há necessidade de verificar o gradiente desses nós."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-CjLPu6clVo"
      },
      "source": [
        "e2.retain_grad()\n",
        "e.retain_grad()\n",
        "y_pred.retain_grad()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtsZS2Bicof-"
      },
      "source": [
        "E agora calculamos os gradientes com o `backward()`.\n",
        "\n",
        "w.grad é o gradiente de J em relação a w."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-29T03:07:40.267334Z",
          "start_time": "2019-09-29T03:07:40.247422Z"
        },
        "id": "Z1lnkb0GCZt_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d57c681c-c48d-4ef7-ce3c-0f5316a35a94"
      },
      "source": [
        "if w.grad: w.grad.zero_()\n",
        "J.backward()\n",
        "print(w.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-28.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1xYDPR_uOcZ"
      },
      "source": [
        "Mostramos agora os gradientes que estão grafados em vermelho no grafo computacional:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Enuk2tf0sDyO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ce646cd-48f4-4193-f854-ad7b7dcf436f"
      },
      "source": [
        "print(e2.grad)\n",
        "print(e.grad)\n",
        "print(y_pred.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1.])\n",
            "tensor([ 0., -2., -4., -6.])\n",
            "tensor([ 0., -2., -4., -6.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsOThnt8fDJV"
      },
      "source": [
        "##Exercício 3.1\n",
        "Calcule o mesmo gradiente ilustrado no exemplo anterior usando a regra das diferenças finitas, de acordo com a equação a seguir, utilizando um valor de $\\Delta w$ bem pequeno.\n",
        "\n",
        "$$ \\frac{\\partial J}{\\partial w} = \\frac{J(w + \\Delta w) - J(w - \\Delta w)}{2 \\Delta w} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "62nZAfUoCZu5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f647ad2-fb59-40c9-bf1a-320672791a8e"
      },
      "source": [
        "def J_func(w, x, y):\n",
        "  y_pred = x * w\n",
        "  e = y_pred - y\n",
        "  e2 = e**2\n",
        "  return e2.sum()\n",
        "\n",
        "# Calcule o gradiente usando a regra diferenças finitas\n",
        "# Confira com o valor já calculado anteriormente\n",
        "x = torch.arange(0, 4).float()\n",
        "y = torch.arange(0, 8, 2).float()\n",
        "w = torch.ones(1)\n",
        "dw = 1e-3 * torch.ones(1)\n",
        "grad = (J_func(w + dw, x, y) - J_func(w - dw, x, y)) / (2*dw)\n",
        "print('grad=', grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grad= tensor([-28.0008])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_Sx1QXZxJ3u"
      },
      "source": [
        "##Exercício 3.2\n",
        "\n",
        "Minimizando $J$ pelo gradiente descendente\n",
        "\n",
        "$$ w_{k+1} = w_k - \\lambda \\frac {\\partial J}{\\partial w} $$\n",
        "\n",
        "Supondo que valor inicial ($k=0$) $w_0 = 1$, use learning rate $\\lambda = 0.01$ para calcular o valor do novo $w_{20}$, ou seja, fazendo 20 atualizações de gradientes. Deve-se usar a função `J_func` criada no exercício anterior.\n",
        "\n",
        "Confira se o valor do primeiro gradiente está de acordo com os valores já calculado acima"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNszCOED1Wtu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f8783994-70e2-4f98-8bfe-94ad8bf697f3"
      },
      "source": [
        "learning_rate = 0.01\n",
        "iteracoes = 20\n",
        "\n",
        "x = torch.arange(0, 4).float()\n",
        "y = torch.arange(0, 8, 2).float()\n",
        "w = torch.ones(1)\n",
        "\n",
        "iters = np.arange(iteracoes)\n",
        "losses = np.zeros(iteracoes)\n",
        "for i in range(iteracoes):\n",
        "    print('i =', i)\n",
        "    J = J_func(w, x, y)\n",
        "    losses[i] = J\n",
        "    print('J=', J)\n",
        "    dw = 1e-3 * torch.ones(1)\n",
        "    grad = (J_func(w + dw, x, y) - J_func(w - dw, x, y)) / (2*dw)\n",
        "    print('grad =',grad)\n",
        "    w = w - learning_rate * grad\n",
        "    print('w =', w)\n",
        "\n",
        "# Plote o gráfico da loss J pela iteração i\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "ax.plot(iters, losses, 'ko-', label=r'$J = \\sum_i (x_i*w - y_i)$')\n",
        "ax.set_xlabel('Iteração')\n",
        "ax.set_ylabel('Perda (loss)')\n",
        "ax.set_xticks(iters)\n",
        "ax.grid()\n",
        "ax.set_title('Aprendizado por gradient descent (diferenças finitas)')\n",
        "ax.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i = 0\n",
            "J= tensor(14.)\n",
            "grad = tensor([-28.0008])\n",
            "w = tensor([1.2800])\n",
            "i = 1\n",
            "J= tensor(7.2574)\n",
            "grad = tensor([-20.1611])\n",
            "w = tensor([1.4816])\n",
            "i = 2\n",
            "J= tensor(3.7621)\n",
            "grad = tensor([-14.5156])\n",
            "w = tensor([1.6268])\n",
            "i = 3\n",
            "J= tensor(1.9501)\n",
            "grad = tensor([-10.4510])\n",
            "w = tensor([1.7313])\n",
            "i = 4\n",
            "J= tensor(1.0109)\n",
            "grad = tensor([-7.5245])\n",
            "w = tensor([1.8065])\n",
            "i = 5\n",
            "J= tensor(0.5240)\n",
            "grad = tensor([-5.4175])\n",
            "w = tensor([1.8607])\n",
            "i = 6\n",
            "J= tensor(0.2716)\n",
            "grad = tensor([-3.9003])\n",
            "w = tensor([1.8997])\n",
            "i = 7\n",
            "J= tensor(0.1408)\n",
            "grad = tensor([-2.8083])\n",
            "w = tensor([1.9278])\n",
            "i = 8\n",
            "J= tensor(0.0730)\n",
            "grad = tensor([-2.0218])\n",
            "w = tensor([1.9480])\n",
            "i = 9\n",
            "J= tensor(0.0378)\n",
            "grad = tensor([-1.4557])\n",
            "w = tensor([1.9626])\n",
            "i = 10\n",
            "J= tensor(0.0196)\n",
            "grad = tensor([-1.0482])\n",
            "w = tensor([1.9731])\n",
            "i = 11\n",
            "J= tensor(0.0102)\n",
            "grad = tensor([-0.7546])\n",
            "w = tensor([1.9806])\n",
            "i = 12\n",
            "J= tensor(0.0053)\n",
            "grad = tensor([-0.5433])\n",
            "w = tensor([1.9860])\n",
            "i = 13\n",
            "J= tensor(0.0027)\n",
            "grad = tensor([-0.3912])\n",
            "w = tensor([1.9899])\n",
            "i = 14\n",
            "J= tensor(0.0014)\n",
            "grad = tensor([-0.2816])\n",
            "w = tensor([1.9928])\n",
            "i = 15\n",
            "J= tensor(0.0007)\n",
            "grad = tensor([-0.2028])\n",
            "w = tensor([1.9948])\n",
            "i = 16\n",
            "J= tensor(0.0004)\n",
            "grad = tensor([-0.1460])\n",
            "w = tensor([1.9962])\n",
            "i = 17\n",
            "J= tensor(0.0002)\n",
            "grad = tensor([-0.1051])\n",
            "w = tensor([1.9973])\n",
            "i = 18\n",
            "J= tensor(0.0001)\n",
            "grad = tensor([-0.0757])\n",
            "w = tensor([1.9981])\n",
            "i = 19\n",
            "J= tensor(5.3023e-05)\n",
            "grad = tensor([-0.0545])\n",
            "w = tensor([1.9986])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fd47fd5bcd0>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBXxBmWGK3IU"
      },
      "source": [
        "##Exercício 3.3\n",
        "\n",
        "Repita o exercício 2 mas usando agora o calculando o gradiente usando o método backward() do pytorch. Confira se o primeiro valor do gradiente está de acordo com os valores anteriores. Execute essa próxima célula duas vezes. Os valores devem ser iguais.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMP4d5vtHtqy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "eda54947-e082-4867-d304-e602539adbb0"
      },
      "source": [
        "learning_rate = 0.01\n",
        "iteracoes = 20\n",
        "\n",
        "x = torch.arange(0, 4).float()\n",
        "y = torch.arange(0, 8, 2).float()\n",
        "w = torch.ones(1, requires_grad=True)\n",
        "\n",
        "iters = np.arange(iteracoes)\n",
        "losses = np.zeros(iteracoes)\n",
        "for i in range(iteracoes):\n",
        "    print('i =', i)\n",
        "    J = J_func(w, x, y)\n",
        "    J.backward()\n",
        "    losses[i] = J\n",
        "    print('J=', J)\n",
        "    grad = w.grad\n",
        "    print('grad =',grad)\n",
        "    w = w - learning_rate * grad\n",
        "    w.retain_grad()\n",
        "    print('w =', w)\n",
        "\n",
        "# Plote aqui a loss pela iteração\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "ax.plot(iters, losses, 'ko-', label=r'$J = \\sum_i (x_i*w - y_i)$')\n",
        "ax.set_xlabel('Iteração')\n",
        "ax.set_ylabel('Perda (loss)')\n",
        "ax.set_xticks(iters)\n",
        "ax.grid()\n",
        "ax.set_title('Aprendizado por gradient descent (autograd)')\n",
        "ax.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i = 0\n",
            "J= tensor(14., grad_fn=<SumBackward0>)\n",
            "grad = tensor([-28.])\n",
            "w = tensor([1.2800], grad_fn=<SubBackward0>)\n",
            "i = 1\n",
            "J= tensor(7.2576, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-20.1600])\n",
            "w = tensor([1.4816], grad_fn=<SubBackward0>)\n",
            "i = 2\n",
            "J= tensor(3.7623, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-14.5152])\n",
            "w = tensor([1.6268], grad_fn=<SubBackward0>)\n",
            "i = 3\n",
            "J= tensor(1.9504, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-10.4509])\n",
            "w = tensor([1.7313], grad_fn=<SubBackward0>)\n",
            "i = 4\n",
            "J= tensor(1.0111, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-7.5247])\n",
            "w = tensor([1.8065], grad_fn=<SubBackward0>)\n",
            "i = 5\n",
            "J= tensor(0.5241, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-5.4178])\n",
            "w = tensor([1.8607], grad_fn=<SubBackward0>)\n",
            "i = 6\n",
            "J= tensor(0.2717, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-3.9008])\n",
            "w = tensor([1.8997], grad_fn=<SubBackward0>)\n",
            "i = 7\n",
            "J= tensor(0.1409, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-2.8086])\n",
            "w = tensor([1.9278], grad_fn=<SubBackward0>)\n",
            "i = 8\n",
            "J= tensor(0.0730, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-2.0222])\n",
            "w = tensor([1.9480], grad_fn=<SubBackward0>)\n",
            "i = 9\n",
            "J= tensor(0.0379, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-1.4560])\n",
            "w = tensor([1.9626], grad_fn=<SubBackward0>)\n",
            "i = 10\n",
            "J= tensor(0.0196, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-1.0483])\n",
            "w = tensor([1.9730], grad_fn=<SubBackward0>)\n",
            "i = 11\n",
            "J= tensor(0.0102, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.7548])\n",
            "w = tensor([1.9806], grad_fn=<SubBackward0>)\n",
            "i = 12\n",
            "J= tensor(0.0053, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.5434])\n",
            "w = tensor([1.9860], grad_fn=<SubBackward0>)\n",
            "i = 13\n",
            "J= tensor(0.0027, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.3913])\n",
            "w = tensor([1.9899], grad_fn=<SubBackward0>)\n",
            "i = 14\n",
            "J= tensor(0.0014, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.2817])\n",
            "w = tensor([1.9928], grad_fn=<SubBackward0>)\n",
            "i = 15\n",
            "J= tensor(0.0007, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.2028])\n",
            "w = tensor([1.9948], grad_fn=<SubBackward0>)\n",
            "i = 16\n",
            "J= tensor(0.0004, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.1460])\n",
            "w = tensor([1.9962], grad_fn=<SubBackward0>)\n",
            "i = 17\n",
            "J= tensor(0.0002, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.1052])\n",
            "w = tensor([1.9973], grad_fn=<SubBackward0>)\n",
            "i = 18\n",
            "J= tensor(0.0001, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.0757])\n",
            "w = tensor([1.9981], grad_fn=<SubBackward0>)\n",
            "i = 19\n",
            "J= tensor(5.3059e-05, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.0545])\n",
            "w = tensor([1.9986], grad_fn=<SubBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fd47fcbb990>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GulfYtzBMx2e"
      },
      "source": [
        "##Exercício 3.4\n",
        "\n",
        "Quais são as restrições na escolha dos valores de $\\Delta w$ no cálculo do gradiente por diferenças finitas?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXQGEyvtiTAR"
      },
      "source": [
        "Resposta: um valor muito pequeno de $\\Delta w$ pode resultar em erro de truncamento devido à precisão finita da arquitetura do processador em que o gradiente é calculado, já um valor grande de $\\Delta w$ não aproximaria corretamente o gradiente no ponto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsrSF8GEiXk4"
      },
      "source": [
        "##Exercício 3.5\n",
        "\n",
        "Até agora trabalhamos com $w$ contendo apenas um parâmetro. Suponha agora que $w$ seja uma matriz com $N$ parâmetros e que o custo para executar $(x_i w - y_i)^2$ seja $O(N)$.\n",
        "> a) Qual é o custo computacional para fazer uma única atualização (um passo de gradiente) dos parâmetros de $w$ usando o método das diferencas finitas?\n",
        ">\n",
        "> b) Qual é o custo computacional para fazer uma única atualização (um passo de gradiente) dos parâmetros de $w$ usando o método do backpropagation?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4Pna3bcicHj"
      },
      "source": [
        "Resposta (justifique):\n",
        "\n",
        "a) $O(KN^2)$, onde $K$ é o número de amostras para treinamento.\n",
        "\n",
        "> Justificativa: Seja $K$ o número de amostras de treinamento, então levaria\n",
        "> $O(KN)$ para calcular $J(w + \\Delta w)$. Como o custo deve ser calculado 2\n",
        "> vezes para encontrar o gradiente na direção de $\\Delta w$, então o\n",
        "> custo total em uma direção é $O(2KN) \\sim O(KN)$; calculando em todas as\n",
        "> $N$ direções de $w$, temos que o custo é $O(KN^2)$.\n",
        "\n",
        "b) $O(KN^2)$, onde $K$ é o número de amostras para treinamento.\n",
        "\n",
        "> Justificativa: Seja $K$ o número de amostras para treinamento,\n",
        "> calculando a derivada parcial da função de custo $J$ em relação à\n",
        "> $w_s$, temos que\n",
        "> $$\n",
        "\\frac{\\partial J}{\\partial w_s} = \\sum_{i=0}^{K-1} (x_i w - y_i)x_{i,s}\n",
        "$$\n",
        "> Como a soma tem $K$ termos e cada termo tem custo $\\sim O(N)$ para\n",
        "> ser calculado, o custo para calcular $\\partial J/\\partial w_s$ é $O(KN)$.\n",
        "> Calculando em $N$ direções de $w$, o custo é $O(KN^2)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35I5w8EZdjIo"
      },
      "source": [
        "##Exercício 3.6\n",
        "\n",
        "Qual o custo (entropia cruzada) esperado para um exemplo (uma amostra) no começo do treinamento de um classificador inicializado aleatoriamente?\n",
        "\n",
        "A equação da entropia cruzada é:\n",
        "$$L = - \\sum_{j=0}^{K-1} y_j \\log p_j, $$\n",
        "Onde:\n",
        "\n",
        "- K é o número de classes;\n",
        "\n",
        "- $y_j=1$ se $j$ é a classe do exemplo (ground-truth), 0 caso contrário. Ou seja, $y$ é um vetor one-hot;\n",
        "\n",
        "- $p_j$ é a probabilidade predita pelo modelo para a classe $j$.\n",
        "\n",
        "A resposta tem que ser em função de uma ou mais das seguintes variáveis:\n",
        "\n",
        "- K = número de classes\n",
        "\n",
        "- B = batch size\n",
        "\n",
        "- D = dimensão de qualquer vetor do modelo\n",
        "\n",
        "- LR = learning rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swTOphiVs6eN"
      },
      "source": [
        "Resposta: $L = \\log K$\n",
        "\n",
        "> Justificativa: No início do treinamento, se o classificador for inicializado\n",
        "> aleatoriamente, cada classe é predita com igual probabilidade, portanto\n",
        "> $p_j = 1/K$. Como $y_j = 1$ somente para uma única classe, temos que\n",
        "> $$\n",
        "L = -\\log\\frac{1}{K} = \\log K\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UNdHqgSB6S9"
      },
      "source": [
        "Fim do notebook."
      ]
    }
  ]
}