{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercícios - 20210718",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {
        "height": "117px",
        "width": "252px"
      },
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unicamp-dl/IA025_2022S1/blob/main/ex01/rodrigo_cabrera_castaldoni/Exerc%C3%ADcios_20210718.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTVOQpMfhgLM"
      },
      "source": [
        "Esté um notebook Colab contendo exercícios de programação em python, numpy e pytorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMoyGt5gXMgK"
      },
      "source": [
        "## Coloque seu nome"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBHbXcibXPRe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32b1eef6-a36e-445c-f4d4-7496319dc5ea"
      },
      "source": [
        "print('Meu nome é: Rodrigo Cabrera Castaldoni')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meu nome é: Rodrigo Cabrera Castaldoni\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9S5acRbm1Zr"
      },
      "source": [
        "# Parte 1:\n",
        "\n",
        "##Exercícios de Processamento de Dados\n",
        "\n",
        "Nesta parte pode-se usar as bibliotecas nativas do python como a `collections`, `re` e `random`. Também pode-se usar o NumPy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxS5h1V8nDn6"
      },
      "source": [
        "##Exercício 1.1\n",
        "Crie um dicionário com os `k` itens mais frequentes de uma lista.\n",
        "\n",
        "Por exemplo, dada a lista de itens `L=['a', 'a', 'd', 'b', 'd', 'c', 'e', 'a', 'b', 'e', 'e', 'a']` e `k=2`, o resultado deve ser um dicionário cuja chave é o item e o valor é a sua frequência: {'a': 4, 'e': 3}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gT08b5Z_nC-j"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "def top_k(L, k):\n",
        "  frequency_dict = Counter(L)\n",
        "  ordered_dict = sorted(frequency_dict.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "  return dict(ordered_dict[:k])\n",
        "\n",
        "L = ['f', 'a', 'a', 'd', 'b', 'd', 'c', 'e', 'a', 'b', 'e', 'e', 'a', 'd']\n",
        "k = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLD_e3C9p4xO"
      },
      "source": [
        "Mostre que sua implementação está correta usando uma entrada com poucos itens:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMW9NiBgnkvA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52005ef6-ba1c-41e2-ca5a-258d13ab70ba"
      },
      "source": [
        "L = ['f', 'a', 'a', 'd', 'b', 'd', 'c', 'e', 'a', 'b', 'e', 'e', 'a', 'd']\n",
        "k = 3\n",
        "resultado = top_k(L=L, k=k)\n",
        "print(f'resultado: {resultado}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resultado: {'a': 4, 'd': 3, 'e': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBeqZScQqJ0a"
      },
      "source": [
        "Mostre que sua implementação é eficiente usando uma entrada com 10M de itens:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_lhcm4ko8bY"
      },
      "source": [
        "import random\n",
        "L = random.choices('abcdefghijklmnopqrstuvwxyz', k=10_000_000)\n",
        "k = 10000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9U-Bgs2o-f_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e68a81e5-97df-44bc-f404-d4ece0978464"
      },
      "source": [
        "%%timeit\n",
        "resultado = top_k(L=L, k=k)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 542 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJHDaOz_tK38"
      },
      "source": [
        "## Exercício 1.2\n",
        "\n",
        "Em processamento de linguagem natural, é comum convertemos as palavras de um texto para uma lista de identificadores dessas palavras. Dado o dicionário `V` abaixo onde as chaves são palavras e os valores são seus respectivos identificadores, converta o texto `D` para uma lista de identificadores.\n",
        "\n",
        "Palavras que não existem no dicionário deverão ser convertidas para o identificador do token `unknown`.\n",
        "\n",
        "O código deve ser insensível a maiúsculas (case-insensitive).\n",
        "\n",
        "Se atente que pontuações (vírgulas, ponto final, etc) também são consideradas palavras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVzv89trtTPc"
      },
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "def tokens_to_ids(text, vocabulary):\n",
        "  aux = re.sub(f\"[{string.punctuation}]\", r' \\g<0>', D)\n",
        "  return [vocabulary.get(word, vocabulary[\"unknown\"]) for word in aux.lower().split()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCGZeiqkY-sm"
      },
      "source": [
        "Mostre que sua implementação esta correta com um exemplo pequeno:\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iApR1h7gY98E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d81256f7-9ef7-474e-8be5-fc6b7e7b23e5"
      },
      "source": [
        "V = {'eu': 1, 'de': 2, 'gosto': 3, 'comer': 4, '.': 5, 'unknown': -1}\n",
        "D = 'Eu gosto de comer pizza.'\n",
        "\n",
        "print(tokens_to_ids(D, V))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 3, 2, 4, -1, 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWtTMxlXZN25"
      },
      "source": [
        "Mostre que sua implementação é eficiente com um exemplo grande:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxT_g-ZxZUsX"
      },
      "source": [
        "V = {'eu': 1, 'de': 2, 'gosto': 3, 'comer': 4, '.': 5, 'unknown': -1}\n",
        "D = ' '.join(1_000_000 * ['Eu gosto de comer pizza.'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kp1nataGZU-V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1818458-1301-46f8-fb40-7b9bc41e601a"
      },
      "source": [
        "%%timeit\n",
        "resultado = tokens_to_ids(D, V)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 2.83 s per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRfaKfXwRXn_"
      },
      "source": [
        "## Exercício 1.3\n",
        "\n",
        "Em aprendizado profundo é comum termos que lidar com arquivos muito grandes.\n",
        "\n",
        "Dado um arquivo de texto onde cada item é separado por `\\n`, escreva um programa que amostre `k` itens desse arquivo aleatoriamente.\n",
        "\n",
        "Nota 1: Assuma amostragem de uma distribuição uniforme, ou seja, todos os itens tem a mesma probablidade de amostragem.\n",
        "\n",
        "Nota 2: Assuma que o arquivo não cabe em memória.\n",
        "\n",
        "Nota 3: Utilize apenas bibliotecas nativas do python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PsadE9SRG_9"
      },
      "source": [
        "import random\n",
        "from collections import Counter\n",
        "def sample(path: str, k: int):\n",
        "    \n",
        "    with open(path) as fp:\n",
        "        max_lines = sum(1 for _ in fp)\n",
        "        \n",
        "    samples2get = Counter([int(random.uniform(0, max_lines)) for _ in range(k)])\n",
        "    amostras = []\n",
        "    with open(path) as fp:\n",
        "        for i, line in enumerate(fp):\n",
        "            for _ in range(samples2get.get(i,0)):\n",
        "                amostras.append(line.strip(\"\\n\"))\n",
        "\n",
        "    return amostras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycEnlFWxSt0i"
      },
      "source": [
        "Mostre que sua implementação está correta com um exemplo pequeno:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyLJ1e2ZSzC9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ba7ee15-bf7e-463d-89c4-34152b59c181"
      },
      "source": [
        "filename = 'small.txt'\n",
        "total_size = 100\n",
        "n_samples = 10\n",
        "\n",
        "with open(filename, 'w') as fout:\n",
        "    fout.write('\\n'.join(f'line {i}' for i in range(total_size)))\n",
        "\n",
        "samples = sample(path=filename, k=n_samples)\n",
        "print(samples)\n",
        "print(len(samples) == n_samples)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['line 25', 'line 28', 'line 33', 'line 42', 'line 43', 'line 55', 'line 60', 'line 74', 'line 75', 'line 80']\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2r4FMiMj12Xg"
      },
      "source": [
        "Mostre que sua implementação é eficiente com um exemplo grande:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUwnNMGg18Ty"
      },
      "source": [
        "filename = 'large.txt'\n",
        "total_size = 1_000_000\n",
        "n_samples = 10000\n",
        "\n",
        "with open(filename, 'w') as fout:\n",
        "    fout.write('\\n'.join(f'line {i}' for i in range(total_size)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA9sAZmo0UDN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06b5555c-bac0-4fdf-a06b-9a38c8b18585"
      },
      "source": [
        "%%timeit\n",
        "samples = sample(path=filename, k=n_samples)\n",
        "assert len(samples) == n_samples"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 534 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udS0Ns4etoJs"
      },
      "source": [
        "# Parte 2:\n",
        "\n",
        "##Exercícios de Numpy\n",
        "\n",
        "Nesta parte deve-se usar apenas a biblioteca NumPy. Aqui não se pode usar o PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcMz3Vzjt144"
      },
      "source": [
        "##Exercício 2.1\n",
        "\n",
        "Quantos operações de ponto flutuante (flops) de soma e de multiplicação tem a multiplicação matricial $AB$, sendo que a matriz $A$ tem tamanho $m \\times n$ e a matriz $B$ tem tamanho $n \\times p$?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "import numpy as np\n",
        "\"\"\"\n",
        "No caso vou analisar a implementação mais simples de multiplicação matricial,\n",
        "isto é O(mnp) quando m=n=p O(n^3).\n",
        "\"\"\"\n",
        "def mul_matriz(A, B):\n",
        "  m, _ = A.shape\n",
        "  n, p = B.shape\n",
        "  C = np.zeros((m,p))\n",
        "\n",
        "  for i in range(m):\n",
        "    for j in range(p):\n",
        "      C[i,j] = A[i,0]*B[0,j]\n",
        "      for k in range(1, n):\n",
        "        C[i, j] = C[i,j] + A[i,k]*B[k,j]\n",
        "  return C\n",
        "```"
      ],
      "metadata": {
        "id": "p0kyQ_SvDbVH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gNXj45RJqUm"
      },
      "source": [
        "Resposta:\n",
        "- número de somas: $m\\cdot p\\cdot (n-1)$\n",
        "- número de multiplicações: $m \\cdot p \\cdot n$\n",
        "\n",
        "Assim sendo, no total temos:\n",
        "\n",
        "$m\\cdot p\\cdot (n-1) + m \\cdot p \\cdot n = m\\cdot p\\cdot (2n−1)$ flops\n",
        "\n",
        "Explicação:\n",
        "\n",
        "Como mostrado no código somamos somente $(n-1)$ vezes enquanto acontecem $n$ multiplicações $(n-1)$ no laço mais interno e 1 fora do laço mais interno."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iI7udBFeDlP"
      },
      "source": [
        "## Exercício 2.2\n",
        "\n",
        "Em programação matricial, não se faz o loop em cada elemento da matriz,\n",
        "mas sim, utiliza-se operações matriciais.\n",
        "\n",
        "Dada a matriz `A` abaixo, calcule a média dos valores de cada linha sem utilizar laços explícitos.\n",
        "\n",
        "Utilize apenas a biblioteca numpy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjrXf18N5KrK"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fqxgNBW27Z0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa297134-5d3d-4cb4-9ee2-27d6092879a6"
      },
      "source": [
        "A = np.arange(24).reshape(4, 6)\n",
        "print(A)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  1  2  3  4  5]\n",
            " [ 6  7  8  9 10 11]\n",
            " [12 13 14 15 16 17]\n",
            " [18 19 20 21 22 23]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1EmKFrT5g7B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c343d5d1-5148-4bbf-fedd-8c0191d4f8ab"
      },
      "source": [
        "# Escreva sua solução aqui.\n",
        "A.mean(axis=1, keepdims=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2.5],\n",
              "       [ 8.5],\n",
              "       [14.5],\n",
              "       [20.5]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtgSAAKjUfcO"
      },
      "source": [
        "## Exercício 2.3\n",
        "\n",
        "Seja a matriz $C$ que é a normalização da matriz $A$:\n",
        "$$ C(i,j) = \\frac{A(i,j) - A_{min}}{A_{max} - A_{min}} $$\n",
        "\n",
        "Normalizar a matriz `A` do exercício acima de forma que seus valores fiquem entre 0 e 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-12-11T00:00:34.072719Z",
          "start_time": "2019-12-11T00:00:34.036017Z"
        },
        "id": "_pDhb2-0eDlS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71a045d8-c6a9-452e-9a04-578d6e5381ea"
      },
      "source": [
        "# Escreva sua solução aqui.\n",
        "a_min = A.min()\n",
        "a_max = A.max()\n",
        "C = (A - a_min)/(a_max - a_min)\n",
        "C"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.04347826, 0.08695652, 0.13043478, 0.17391304,\n",
              "        0.2173913 ],\n",
              "       [0.26086957, 0.30434783, 0.34782609, 0.39130435, 0.43478261,\n",
              "        0.47826087],\n",
              "       [0.52173913, 0.56521739, 0.60869565, 0.65217391, 0.69565217,\n",
              "        0.73913043],\n",
              "       [0.7826087 , 0.82608696, 0.86956522, 0.91304348, 0.95652174,\n",
              "        1.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF_P_GARU62m"
      },
      "source": [
        "## Exercício 2.4\n",
        "\n",
        "Modificar o exercício anterior de forma que os valores de cada *coluna* da matriz `A` sejam normalizados entre 0 e 1 independentemente dos valores das outras colunas.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NgVzFOYeDla",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bc9d7a1-6c5b-4342-9b5d-f9af78049fda"
      },
      "source": [
        "# Escreva sua solução aqui.\n",
        "# Escreva sua solução aqui.\n",
        "min_cols = A.min(axis=0, keepdims=True)\n",
        "max_cols = A.max(axis=0, keepdims=True)\n",
        "C = (A - min_cols)/(max_cols - min_cols)\n",
        "C"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.33333333, 0.33333333, 0.33333333, 0.33333333, 0.33333333,\n",
              "        0.33333333],\n",
              "       [0.66666667, 0.66666667, 0.66666667, 0.66666667, 0.66666667,\n",
              "        0.66666667],\n",
              "       [1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "        1.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbXIXsDIUmtp"
      },
      "source": [
        "## Exercício 2.5\n",
        "\n",
        "Modificar o exercício anterior de forma que os valores de cada *linha* da matriz `A` sejam normalizados entre 0 e 1 independentemente dos valores das outras linhas.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-12-10T17:56:40.413601Z",
          "start_time": "2019-12-10T17:56:40.405056Z"
        },
        "id": "i-5Hv8-heDlW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0495ba46-ed21-4074-cb24-9c213649c6ec"
      },
      "source": [
        "# Escreva sua solução aqui.\n",
        "min_rows = A.min(axis=1, keepdims=True)\n",
        "max_rows = A.max(axis=1, keepdims=True)\n",
        "C = (A - min_rows)/(max_rows - min_rows)\n",
        "C"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0. , 0.2, 0.4, 0.6, 0.8, 1. ],\n",
              "       [0. , 0.2, 0.4, 0.6, 0.8, 1. ],\n",
              "       [0. , 0.2, 0.4, 0.6, 0.8, 1. ],\n",
              "       [0. , 0.2, 0.4, 0.6, 0.8, 1. ]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKnLAyL7zgpa"
      },
      "source": [
        "## Exercício 2.6\n",
        "\n",
        "A [função softmax](https://en.wikipedia.org/wiki/Softmax_function) é bastante usada em apredizado de máquina para converter uma lista de números para uma distribuição de probabilidade, isto é, os números ficarão normalizados entre zero e um e sua soma será igual à um.\n",
        "\n",
        "Implemente a função softmax com suporte para batches, ou seja, o softmax deve ser aplicado a cada linha da matriz. Deve-se usar apenas a biblioteca numpy. Se atente que a exponenciação gera estouro de representação quando os números da entrada são muito grandes. Tente corrigir isto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lA5W9vxNEmOj"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def softmax(A):\n",
        "    '''\n",
        "    Aplica a função de softmax à matriz `A`.\n",
        "\n",
        "    Entrada:\n",
        "      `A` é uma matriz M x N, onde M é o número de exemplos a serem processados\n",
        "      independentemente e N é o tamanho de cada exemplo.\n",
        "    \n",
        "    Saída:\n",
        "      Uma matriz M x N, onde a soma de cada linha é igual a um.\n",
        "    '''\n",
        "    # Escreva sua solução aqui.\n",
        "    x = np.exp(A - A.max(1, keepdims=True))\n",
        "    rows_sum = x.sum(axis=1, keepdims=True)\n",
        "    return x / rows_sum # only difference"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpxlbh4ND54q"
      },
      "source": [
        "Mostre que sua implementação está correta usando uma matriz pequena como entrada:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6EZ5ZD7HFao",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77f7c426-d666-4500-f819-79a332ce5b63"
      },
      "source": [
        "A = np.array([[0.5, -1, 1000],\n",
        "              [-2,   0, 0.5]])\n",
        "softmax(A)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 1.        ],\n",
              "       [0.04861082, 0.35918811, 0.59220107]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9j2uXmKH8HF4"
      },
      "source": [
        "O código a seguir verifica se sua implementação do softmax está correta. \n",
        "- A soma de cada linha de A deve ser 1;\n",
        "- Os valores devem estar entre 0 e 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-sN4STk7qyN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5067d172-f7f0-42a1-a785-2ae7f1c98b8e"
      },
      "source": [
        "np.allclose(softmax(A).sum(axis=1), 1) and softmax(A).min() >= 0 and softmax(A).max() <= 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5_ZRWRfCZtI"
      },
      "source": [
        "Mostre que sua implementação é eficiente usando uma matriz grande como entrada:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhUeyrGaJ3J2"
      },
      "source": [
        "A = np.random.uniform(low=-10, high=10, size=(128, 100_000))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaa-C8XkKJin",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1584e5f8-fd10-49b0-9478-7f1209ad2ccc"
      },
      "source": [
        "%%timeit\n",
        "softmax(A)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 272 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XE6LaWi81zZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c59dca8-8d64-4c60-fcce-ec78c95cbada"
      },
      "source": [
        "SM = softmax(A)\n",
        "np.allclose(SM.sum(axis=1), 1) and SM.min() >= 0 and SM.max() <= 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Flr1lI5o-HpG"
      },
      "source": [
        "## Exercício 2.7\n",
        "\n",
        "A codificação one-hot é usada para codificar entradas categóricas. É uma codificação onde apenas um bit é 1 e os demais são zero, conforme a tabela a seguir.\n",
        "\n",
        "| Decimal | Binary | One-hot\n",
        "| ------- | ------ | -------\n",
        "| 0 | 000    | 1 0 0 0 0 0 0 0\n",
        "| 1 | 001    | 0 1 0 0 0 0 0 0\n",
        "| 2 | 010    | 0 0 1 0 0 0 0 0\n",
        "| 3 | 011    | 0 0 0 1 0 0 0 0\n",
        "| 4 | 100    | 0 0 0 0 1 0 0 0\n",
        "| 5 | 101    | 0 0 0 0 0 1 0 0\n",
        "| 6 | 110    | 0 0 0 0 0 0 1 0\n",
        "| 7 | 111    | 0 0 0 0 0 0 0 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CqXP_5ABbfo"
      },
      "source": [
        "Implemente a função one_hot(y, n_classes) que codifique o vetor de inteiros y que possuem valores entre 0 e n_classes-1.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "la-02w7qCH7L"
      },
      "source": [
        "def one_hot(y, n_classes):\n",
        "  # Escreva seu código aqui.\n",
        "  eye = np.eye(n_classes)\n",
        "  return eye[y] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zf5zyZO5Aiz_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "196e07fc-c167-4bf2-a672-87e35596e3d7"
      },
      "source": [
        "N_CLASSES = 9\n",
        "N_SAMPLES = 10\n",
        "y = (np.random.rand((N_SAMPLES)) * N_CLASSES).astype(np.int)\n",
        "print(y)\n",
        "print(one_hot(y, N_CLASSES))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8 7 1 2 2 7 0 4 7 2]\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nwuKnQUCzve"
      },
      "source": [
        "Mostre que sua implementação é eficiente usando uma matriz grande como entrada:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwuFy5rWC2tA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03bf28b0-a13f-4407-d8bb-7444bbcec232"
      },
      "source": [
        "N_SAMPLES = 100_000\n",
        "N_CLASSES = 1_000\n",
        "y = (np.random.rand((N_SAMPLES)) * N_CLASSES).astype(np.int)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7azMtF7wDJ2_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ebe0dfa-2b79-40b4-d0d2-760c07a37e72"
      },
      "source": [
        "%%timeit\n",
        "one_hot(y, N_CLASSES)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 143 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqMroZay2ubi"
      },
      "source": [
        "## Exercício 2.8\n",
        "\n",
        "Implemente uma classe que normalize um array de pontos flutuantes `array_a` para a mesma média e desvio padrão de um outro array `array_b`, conforme exemplo abaixo:\n",
        "```\n",
        "array_a = np.array([-1, 1.5, 0])\n",
        "array_b = np.array([1.4, 0.8, 0.3, 2.5])\n",
        "normalize = Normalizer(array_b)\n",
        "normalized_array = normalize(array_a)\n",
        "print(normalized_array)  # Deve imprimir [0.3187798  2.31425165 1.11696854]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaedJ5Cf5Oy2"
      },
      "source": [
        "# Escreva seu código aqui.\n",
        "# Escreva seu código aqui.\n",
        "class Normalizer:\n",
        "  \n",
        "  def __init__(self, lst: list):\n",
        "    self.new_mean, self.new_std = np.mean(lst), np.std(lst)\n",
        "\n",
        "  def __call__(self, lst: list):\n",
        "    mean, std = np.mean(lst), np.std(lst)\n",
        "    new_array = (lst - mean)/std\n",
        "    return (new_array*self.new_std)+self.new_mean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlkNNU6h5RbR"
      },
      "source": [
        "Mostre que seu código está correto com o exemplo abaixo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gad6zsbh5a0D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c0a13a8-216a-4dd1-d600-37add0b83db2"
      },
      "source": [
        "array_a = [-1, 1.5, 0]\n",
        "array_b = [1.4, 0.8, 0.3, 2.5]\n",
        "normalize = Normalizer(array_b)\n",
        "normalized_array = normalize(array_a)\n",
        "print(normalized_array)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.3187798  2.31425165 1.11696854]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrGVQFUYI_LP"
      },
      "source": [
        "# Parte 3:\n",
        "\n",
        "##Exercícios Pytorch: Grafo Computacional e Gradientes\n",
        "\n",
        "Nesta parte pode-se usar quaisquer bibliotecas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIlQdKAuCZtR"
      },
      "source": [
        "Um dos principais fundamentos para que o PyTorch seja adequado para deep learning é a sua habilidade de calcular o gradiente automaticamente a partir da expressões definidas. Essa facilidade é implementada através do cálculo automático do gradiente e construção dinâmica do grafo computacional."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF_-dJ2nCZtT"
      },
      "source": [
        "## Grafo computacional\n",
        "\n",
        "Seja um exemplo simples de uma função de perda J dada pela Soma dos Erros ao Quadrado (SEQ - Sum of Squared Errors): \n",
        "$$ J = \\sum_i (x_i w - y_i)^2 $$\n",
        "que pode ser reescrita como:\n",
        "$$ \\hat{y_i} = x_i w $$\n",
        "$$ e_i = \\hat{y_i} - y_i $$\n",
        "$$ e2_i = e_i^2 $$\n",
        "$$ J = \\sum_i e2_i $$\n",
        "\n",
        "As redes neurais são treinadas através da minimização de uma função de perda usando o método do gradiente descendente. Para ajustar o parâmetro $w$ precisamos calcular o gradiente $  \\frac{ \\partial J}{\\partial w} $. Usando a\n",
        "regra da cadeia podemos escrever:\n",
        "$$ \\frac{ \\partial J}{\\partial w} = \\frac{ \\partial J}{\\partial e2_i} \\frac{ \\partial e2_i}{\\partial e_i} \\frac{ \\partial e_i}{\\partial \\hat{y_i} } \\frac{ \\partial \\hat{y_i}}{\\partial w}$$ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jboejVQMCZtU"
      },
      "source": [
        "```\n",
        "    y_pred = x * w\n",
        "    e = y_pred - y\n",
        "    e2 = e**2\n",
        "    J = e2.sum()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7JmU6qhc2Y2"
      },
      "source": [
        "As quatro expressões acima, para o cálculo do J podem ser representadas pelo grafo computacional visualizado a seguir: os círculos são as variáveis (tensores), os quadrados são as operações, os números em preto são os cálculos durante a execução das quatro expressões para calcular o J (forward, predict). O cálculo do gradiente, mostrado em vermelho, é calculado pela regra da cadeia, de trás para frente (backward)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeeEBKl4CZtV"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/robertoalotufo/files/master/figures/GrafoComputacional.png\" width=\"600pt\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yZun7wrCZtX"
      },
      "source": [
        "Para entender melhor o funcionamento do grafo computacional com os tensores, recomenda-se leitura em:\n",
        "\n",
        "https://pytorch.org/docs/stable/notes/autograd.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-12-11T00:23:00.431853Z",
          "start_time": "2019-12-11T00:23:00.414813Z"
        },
        "id": "HlT2d-4fCZtZ"
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-12-11T00:23:00.863228Z",
          "start_time": "2019-12-11T00:23:00.844457Z"
        },
        "id": "xX0QwUduCZtf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ae4187ff-5765-42a7-90a9-6bf8c4975b7c"
      },
      "source": [
        "torch.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.10.0+cu111'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsqzALS4CZtl"
      },
      "source": [
        "**Tensor com atributo .requires_grad=True**\n",
        "\n",
        "Quando um tensor possui o atributo `requires_grad` como verdadeiro, qualquer expressão que utilizar esse tensor irá construir um grafo computacional para permitir posteriormente, após calcular a função a ser derivada, poder usar a regra da cadeia e calcular o gradiente da função em termos dos tensores que possuem o atributo `requires_grad`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-29T03:07:22.117010Z",
          "start_time": "2019-09-29T03:07:22.041861Z"
        },
        "id": "foaAb94aCZtm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5983c09-cf17-4dbe-d2f1-1a8dd528358c"
      },
      "source": [
        "y = torch.arange(0, 8, 2).float()\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 2., 4., 6.])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-29T03:07:28.610934Z",
          "start_time": "2019-09-29T03:07:28.598223Z"
        },
        "id": "no6SdSyICZtr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e270313e-1a75-41c6-ca32-40e89d17f6f6"
      },
      "source": [
        "x = torch.arange(0, 4).float()\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 1., 2., 3.])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-29T03:07:31.523762Z",
          "start_time": "2019-09-29T03:07:31.497683Z"
        },
        "id": "eL_i1mwGCZtw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa0211fc-b9fd-4c50-aa3f-d79071f288a9"
      },
      "source": [
        "w = torch.ones(1, requires_grad=True)\n",
        "w"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjEl-0l7CZt0"
      },
      "source": [
        "## Cálculo automático do gradiente da função perda J"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pUh-SCnCZt1"
      },
      "source": [
        "Seja a expressão: $$ J = \\sum_i ((x_i  w) - y_i)^2 $$\n",
        "\n",
        "Queremos calcular a derivada de $J$ em relação a $w$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMwwVtJ1CZt2"
      },
      "source": [
        "## Forward pass\n",
        "\n",
        "Durante a execução da expressão, o grafo computacional é criado. Compare os valores de cada parcela calculada com os valores em preto da figura ilustrativa do grafo computacional."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-29T03:07:36.290122Z",
          "start_time": "2019-09-29T03:07:36.273229Z"
        },
        "id": "zp2aK4YhCZt3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5899a7e0-6bee-450c-a6e0-f90d20d56dd8"
      },
      "source": [
        "# predict (forward)\n",
        "y_pred = x * w; print('y_pred =', y_pred)\n",
        "\n",
        "# cálculo da perda J: loss\n",
        "e = y_pred - y; print('e =',e)\n",
        "e2 = e.pow(2) ; print('e2 =', e2)\n",
        "J = e2.sum()  ; print('J =', J)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_pred = tensor([0., 1., 2., 3.], grad_fn=<MulBackward0>)\n",
            "e = tensor([ 0., -1., -2., -3.], grad_fn=<SubBackward0>)\n",
            "e2 = tensor([0., 1., 4., 9.], grad_fn=<PowBackward0>)\n",
            "J = tensor(14., grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC96wB7PCZt8"
      },
      "source": [
        "## Backward pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2017-10-04T15:55:45.308858",
          "start_time": "2017-10-04T15:55:45.304654"
        },
        "id": "kKbf4D0CCZt-"
      },
      "source": [
        "O `backward()` varre o grafo computacional a partir da variável a ele associada (raiz) e calcula o gradiente para todos os tensores que possuem o atributo `requires_grad` como verdadeiro.\n",
        "Observe que os tensores que tiverem o atributo `requires_grad` serão sempre folhas no grafo computacional.\n",
        "O `backward()` destroi o grafo após sua execução. Esse comportamento é padrão no PyTorch. \n",
        "\n",
        "A título ilustrativo, se quisermos depurar os gradientes dos nós que não são folhas no grafo computacional, precisamos primeiro invocar `retain_grad()` em cada um desses nós, como a seguir. Entretanto nos exemplos reais não há necessidade de verificar o gradiente desses nós."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-CjLPu6clVo"
      },
      "source": [
        "e2.retain_grad()\n",
        "e.retain_grad()\n",
        "y_pred.retain_grad()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtsZS2Bicof-"
      },
      "source": [
        "E agora calculamos os gradientes com o `backward()`.\n",
        "\n",
        "w.grad é o gradiente de J em relação a w."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-09-29T03:07:40.267334Z",
          "start_time": "2019-09-29T03:07:40.247422Z"
        },
        "id": "Z1lnkb0GCZt_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed89b9c7-751e-4fc8-ec11-63d94d19f77c"
      },
      "source": [
        "if w.grad: w.grad.zero_()\n",
        "J.backward()\n",
        "print(w.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-28.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1xYDPR_uOcZ"
      },
      "source": [
        "Mostramos agora os gradientes que estão grafados em vermelho no grafo computacional:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Enuk2tf0sDyO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1aa0c7a1-5e24-46b4-dc62-2764029a1dcd"
      },
      "source": [
        "print(e2.grad)\n",
        "print(e.grad)\n",
        "print(y_pred.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1.])\n",
            "tensor([ 0., -2., -4., -6.])\n",
            "tensor([ 0., -2., -4., -6.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsOThnt8fDJV"
      },
      "source": [
        "##Exercício 3.1\n",
        "Calcule o mesmo gradiente ilustrado no exemplo anterior usando a regra das diferenças finitas, de acordo com a equação a seguir, utilizando um valor de $\\Delta w$ bem pequeno.\n",
        "\n",
        "$$ \\frac{\\partial J}{\\partial w} = \\frac{J(w + \\Delta w) - J(w - \\Delta w)}{2 \\Delta w} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "62nZAfUoCZu5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5191e919-0272-45fe-e46d-8adbb10058c5"
      },
      "source": [
        "def J_func(w, x, y):\n",
        "    # programe a função J_func, para facilitar\n",
        "    return ((x*w-y)**2).sum()\n",
        "\n",
        "# Calcule o gradiente usando a regra diferenças finitas\n",
        "# Confira com o valor já calculado anteriormente\n",
        "x = torch.arange(0, 4).float()\n",
        "y = torch.arange(0, 8, 2).float()\n",
        "w = torch.ones(1)\n",
        "dw = 1e-4\n",
        "grad = (J_func(w+dw, x, y) - J_func(w-dw, x, y))/(2*dw)\n",
        "print('grad=', grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grad= tensor(-27.9999)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_Sx1QXZxJ3u"
      },
      "source": [
        "##Exercício 3.2\n",
        "\n",
        "Minimizando $J$ pelo gradiente descendente\n",
        "\n",
        "$$ w_{k+1} = w_k - \\lambda \\frac {\\partial J}{\\partial w} $$\n",
        "\n",
        "Supondo que valor inicial ($k=0$) $w_0 = 1$, use learning rate $\\lambda = 0.01$ para calcular o valor do novo $w_{20}$, ou seja, fazendo 20 atualizações de gradientes. Deve-se usar a função `J_func` criada no exercício anterior.\n",
        "\n",
        "Confira se o valor do primeiro gradiente está de acordo com os valores já calculado acima"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNszCOED1Wtu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ed2de5f3-9b50-4669-8e17-534546079a4e"
      },
      "source": [
        "learning_rate = 0.01\n",
        "iteracoes = 20\n",
        "\n",
        "x = torch.arange(0, 4).float()\n",
        "y = torch.arange(0, 8, 2).float()\n",
        "w = torch.ones(1)\n",
        "\n",
        "Js = []\n",
        "grads = []\n",
        "for i in range(iteracoes):\n",
        "    print('i =', i)\n",
        "    J = J_func(w, x, y)\n",
        "    Js.append(J)\n",
        "    print('J=', J)\n",
        "    grad = (J_func(w+dw, x, y) - J_func(w-dw, x, y))/(2*dw)\n",
        "    grads.append(grad)\n",
        "    print('grad =',grad)\n",
        "    w = w - learning_rate*grad\n",
        "    print('w =', w)\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(16,5))\n",
        "plt.scatter(np.arange(len(Js)),Js, color=\"black\")\n",
        "plt.plot(Js, lw=2, color=\"red\")\n",
        "plt.legend()\n",
        "plt.title('Custo vs iteração usando diferenças finitas', fontsize=20)\n",
        "plt.xlabel('Iteração', fontsize=16)\n",
        "plt.ylabel('Custo (J)', fontsize=16)\n",
        "plt.show()\n",
        "# Plote o gráfico da loss J pela iteração i"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No handles with labels found to put in legend.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i = 0\n",
            "J= tensor(14.)\n",
            "grad = tensor(-27.9999)\n",
            "w = tensor([1.2800])\n",
            "i = 1\n",
            "J= tensor(7.2576)\n",
            "grad = tensor(-20.1607)\n",
            "w = tensor([1.4816])\n",
            "i = 2\n",
            "J= tensor(3.7623)\n",
            "grad = tensor(-14.5137)\n",
            "w = tensor([1.6267])\n",
            "i = 3\n",
            "J= tensor(1.9505)\n",
            "grad = tensor(-10.4505)\n",
            "w = tensor([1.7312])\n",
            "i = 4\n",
            "J= tensor(1.0112)\n",
            "grad = tensor(-7.5281)\n",
            "w = tensor([1.8065])\n",
            "i = 5\n",
            "J= tensor(0.5240)\n",
            "grad = tensor(-5.4196)\n",
            "w = tensor([1.8607])\n",
            "i = 6\n",
            "J= tensor(0.2716)\n",
            "grad = tensor(-3.9014)\n",
            "w = tensor([1.8997])\n",
            "i = 7\n",
            "J= tensor(0.1407)\n",
            "grad = tensor(-2.8086)\n",
            "w = tensor([1.9278])\n",
            "i = 8\n",
            "J= tensor(0.0729)\n",
            "grad = tensor(-2.0218)\n",
            "w = tensor([1.9480])\n",
            "i = 9\n",
            "J= tensor(0.0378)\n",
            "grad = tensor(-1.4555)\n",
            "w = tensor([1.9626])\n",
            "i = 10\n",
            "J= tensor(0.0196)\n",
            "grad = tensor(-1.0472)\n",
            "w = tensor([1.9731])\n",
            "i = 11\n",
            "J= tensor(0.0102)\n",
            "grad = tensor(-0.7540)\n",
            "w = tensor([1.9806])\n",
            "i = 12\n",
            "J= tensor(0.0053)\n",
            "grad = tensor(-0.5432)\n",
            "w = tensor([1.9860])\n",
            "i = 13\n",
            "J= tensor(0.0027)\n",
            "grad = tensor(-0.3910)\n",
            "w = tensor([1.9900])\n",
            "i = 14\n",
            "J= tensor(0.0014)\n",
            "grad = tensor(-0.2814)\n",
            "w = tensor([1.9928])\n",
            "i = 15\n",
            "J= tensor(0.0007)\n",
            "grad = tensor(-0.2027)\n",
            "w = tensor([1.9948])\n",
            "i = 16\n",
            "J= tensor(0.0004)\n",
            "grad = tensor(-0.1458)\n",
            "w = tensor([1.9962])\n",
            "i = 17\n",
            "J= tensor(0.0002)\n",
            "grad = tensor(-0.1051)\n",
            "w = tensor([1.9973])\n",
            "i = 18\n",
            "J= tensor(0.0001)\n",
            "grad = tensor(-0.0756)\n",
            "w = tensor([1.9981])\n",
            "i = 19\n",
            "J= tensor(5.2911e-05)\n",
            "grad = tensor(-0.0544)\n",
            "w = tensor([1.9986])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBXxBmWGK3IU"
      },
      "source": [
        "##Exercício 3.3\n",
        "\n",
        "Repita o exercício 2 mas usando agora o calculando o gradiente usando o método backward() do pytorch. Confira se o primeiro valor do gradiente está de acordo com os valores anteriores. Execute essa próxima célula duas vezes. Os valores devem ser iguais.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMP4d5vtHtqy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fdd82b66-cdb7-43be-8190-38aaba5ed4e8"
      },
      "source": [
        "learning_rate = 0.01\n",
        "iteracoes = 20\n",
        "\n",
        "x = torch.arange(0, 4).float()\n",
        "y = torch.arange(0, 8, 2).float()\n",
        "w = torch.ones(1, requires_grad=True)\n",
        "\n",
        "Js_autograd = []\n",
        "grads_autograd = []\n",
        "for i in range(iteracoes):\n",
        "    print('i =', i)\n",
        "    J = J_func(w, x, y)\n",
        "    Js_autograd.append(J.item())\n",
        "    print('J=', J)\n",
        "    if w.grad: w.grad.zero_()\n",
        "    J.backward()\n",
        "    grad = w.grad\n",
        "    grads_autograd.append(grad.item())\n",
        "    print('grad =',grad)\n",
        "    w = w - learning_rate*grad\n",
        "    w.retain_grad()\n",
        "    print('w =', w)\n",
        "\n",
        "plt.figure(figsize=(16,5))\n",
        "plt.scatter(np.arange(len(Js)),Js, color=\"black\")\n",
        "plt.plot(Js_autograd, lw=2, color=\"red\")\n",
        "plt.legend()\n",
        "plt.title('Custo vs iteração usando autograd', fontsize=20)\n",
        "plt.xlabel('Iteração', fontsize=16)\n",
        "plt.ylabel('Custo (J)', fontsize=16)\n",
        "plt.show()\n",
        "# Plote aqui a loss pela iteração"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No handles with labels found to put in legend.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i = 0\n",
            "J= tensor(14., grad_fn=<SumBackward0>)\n",
            "grad = tensor([-28.])\n",
            "w = tensor([1.2800], grad_fn=<SubBackward0>)\n",
            "i = 1\n",
            "J= tensor(7.2576, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-20.1600])\n",
            "w = tensor([1.4816], grad_fn=<SubBackward0>)\n",
            "i = 2\n",
            "J= tensor(3.7623, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-14.5152])\n",
            "w = tensor([1.6268], grad_fn=<SubBackward0>)\n",
            "i = 3\n",
            "J= tensor(1.9504, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-10.4509])\n",
            "w = tensor([1.7313], grad_fn=<SubBackward0>)\n",
            "i = 4\n",
            "J= tensor(1.0111, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-7.5247])\n",
            "w = tensor([1.8065], grad_fn=<SubBackward0>)\n",
            "i = 5\n",
            "J= tensor(0.5241, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-5.4178])\n",
            "w = tensor([1.8607], grad_fn=<SubBackward0>)\n",
            "i = 6\n",
            "J= tensor(0.2717, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-3.9008])\n",
            "w = tensor([1.8997], grad_fn=<SubBackward0>)\n",
            "i = 7\n",
            "J= tensor(0.1409, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-2.8086])\n",
            "w = tensor([1.9278], grad_fn=<SubBackward0>)\n",
            "i = 8\n",
            "J= tensor(0.0730, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-2.0222])\n",
            "w = tensor([1.9480], grad_fn=<SubBackward0>)\n",
            "i = 9\n",
            "J= tensor(0.0379, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-1.4560])\n",
            "w = tensor([1.9626], grad_fn=<SubBackward0>)\n",
            "i = 10\n",
            "J= tensor(0.0196, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-1.0483])\n",
            "w = tensor([1.9730], grad_fn=<SubBackward0>)\n",
            "i = 11\n",
            "J= tensor(0.0102, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.7548])\n",
            "w = tensor([1.9806], grad_fn=<SubBackward0>)\n",
            "i = 12\n",
            "J= tensor(0.0053, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.5434])\n",
            "w = tensor([1.9860], grad_fn=<SubBackward0>)\n",
            "i = 13\n",
            "J= tensor(0.0027, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.3913])\n",
            "w = tensor([1.9899], grad_fn=<SubBackward0>)\n",
            "i = 14\n",
            "J= tensor(0.0014, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.2817])\n",
            "w = tensor([1.9928], grad_fn=<SubBackward0>)\n",
            "i = 15\n",
            "J= tensor(0.0007, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.2028])\n",
            "w = tensor([1.9948], grad_fn=<SubBackward0>)\n",
            "i = 16\n",
            "J= tensor(0.0004, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.1460])\n",
            "w = tensor([1.9962], grad_fn=<SubBackward0>)\n",
            "i = 17\n",
            "J= tensor(0.0002, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.1052])\n",
            "w = tensor([1.9973], grad_fn=<SubBackward0>)\n",
            "i = 18\n",
            "J= tensor(0.0001, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.0757])\n",
            "w = tensor([1.9981], grad_fn=<SubBackward0>)\n",
            "i = 19\n",
            "J= tensor(5.3059e-05, grad_fn=<SumBackward0>)\n",
            "grad = tensor([-0.0545])\n",
            "w = tensor([1.9986], grad_fn=<SubBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x360 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7EAAAFXCAYAAAB0ocnvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeZgcVb3/8fc3GyEhJBAjS0IyIIsgCoThAspVRJFNBREuYEA2jQLidlVAEBFvuFxcEa5IBERICCC44RUF9QcoIDJh3xFJMGELECCSBUjO749TEzqTnknPZGaqe+b9ep56uru6uuozVZU8/e1z6lSklJAkSZIkqREMKDuAJEmSJEm1soiVJEmSJDUMi1hJkiRJUsOwiJUkSZIkNQyLWEmSJElSw7CIlSRJkiQ1DItYSVKPiohZETGr7Bw9LSLGRsTtEfGviLgyIraIiP+JiDvKztbI+sv509dExA0R4X0cJfUIi1hJ/VZEvDUizomI+yLipYh4NSKejIj/i4ijI2KNXsySIuKG3tpe2SLiiOJvPqLsLN3oGGAj4AJge+Ah4MvAeWWGUvki4uLifG8qO4sk9QWDyg4gSWWIiFOBr5N/zLsV+CnwL2A9YFdyIXIM0FxSxL7kfWUH6CU/Bi5KKf0jIr4AbA4sSCk9WXIuSZL6FItYSf1ORHwV+AbwT+DAlNJtVZb5IPCfvZ2tL0opPVZ2ht6QUppd8TwBD5cYR5KkPsvuxJL6laI732nAa8De1QpYgJTSb4A9Kz63a9Ed8LR21rvSdXsRMSQiPhsRd0TE/IhYWCz3q4h4f7HMERXXjb2n2Eaqtq2I+I+IuKno+rwoIu6NiJNq7fYcET8q1rtvO+/vWLx/VcW89SLi2xHxcES8EhEvFs8vjohNatzuCvum6Db9k+LlT9r8zU0Vyw2KiGMj4q8R8XKx/+6MiM9ExIA222gqPn9xRGweEVdExLMRsSwidi2W2T4izo6IuyPihYhYHBGPRsR3ImKdDvIfFBF/rPjMrIiYERHNFcusHRFfiog/RcScomv6vIi4JiLe1cG63xcRvyvWvSQiHomIMyNiZC37tljHacXfvmuV95bvlzbzazquxTn8mYj4bUTMLjK+EBF/iIi92skzq5iGR8S3IuKJ4nN/j4gTIiKqfCaK7dxf7OO5EXFuR/shItaIiBOLfwcLi3PkzxHxH7Xuu2I9nTovOru/I//7Prx4+XjFuT6rzWc3i4hLir+99dKGSyJis3ZybxARPynO80URcVdEHB7t/F8VxTWqxTE9tTjeS1qzRsTIiPhylXP41xGxcwf77+CImFlkeDYiLo2IDdtbXpK6gy2xkvqbI4HBwOUppfs6WjCltGQ1t3UxcAhwH3AJsAjYENiFXCD/AbiL3Cr8dWB28ZlWN7Q+iYgzgJOA54DLyF2f9wLOAPaIiA+klF5dRZ6fAp8CPg78qsr7rV+0Ly62OQy4GXgLcD1wDRDABGBf4CrgH6vYZjUXAy8W6/gVeR+0erHY9uBie3uQWzQvAxYD7wXOAXYEDquy7rcAtwGPANOBNYGXi/c+CXwEuJG87weQr139IrBXROyYUlrQuqKi2PoJeb88B/wcmAeMK3I8DLQUi28O/Hex7v8D5gPjgQ8X6/5wSum3lUEj4lPk62VfAX4GPEvuyn4C8KGIeFdK6cX2d2PXdPK4rgucDdxSLDsP2AD4EPDbiPhkSumCKpsZDPyefL5fC7wO7AecCQwln/OVvg98FngKmEr+kWlf8nEeAqxwbkfEkGL97yFfe/y/wDDgAOCKiNg2pfTVGndJp86LLvgG+W/fhrwvW4/p8mMbETsU2x4B/Bp4AHgrcCiwb0S8P6V0e8XybyZfBjEBuIl8fNYHfghct4o8VwM7kI/LL8nnHcCWwJRifdXO4Q+llH5XuaLI3ea/W/wtlxSPexR5XlrlnpGkrkopOTk5OfWbCfgjkIBPdPJzuxafO62d92cBsypejwSWkYucgVWWH93mdQJuaGfdOxfvPwGsXzF/ELkAScBXa/w7HgaWAOu2mb8G8ALwDDComPehYt3fq7KeIcCIGre5wr4p5h1RrPuIdj5zWvH+OZX7DxgIXFi8t2/F/KZiXgLOaGedE9o5FkcXnzuhzfzJxfy/ASPbvDcQ2KDi9drAm6qsexzwJPBQlSxLyAX2W9u898Niu1Nr3L+t+2rXKu+17peLK+bVfFyL82JcleVGkn+ceQFYs8rxTsBvK98D3kwucl4EBlfMf2ex/N8rz0tysXtr8V7b8+ekim0MarON1u2/s8b919nzolP7u5h/cTG/qcpnAniweH9Sm/cOKuY/BAyomN/6b+B/2iy/TXFerfR/FflHsQTc0865OnIV5/CDVf7WV4tzoKli/gByoZwoetY7OTk5dfdkd2JJ/c0GxeOcHt5OIn85XUIuZld8M6XnO7Guo4rH/0opPV2xjtfJ1+0uAz5R47p+Si5UDmkz/0PAOsD0Yr2VFrVdSUrp1bR6rVPtitxV+HjgaeALKaWlFdtdSv6bEzCpysefYeVWvtbPzq5cV4WLyMXkHm3mH188fiqltEKrUkppaUrpqYrXL6eUnquyzTnkls0tImJ8xVuHko/DuSmlh9p87GRgAXBY9OwI2as8rimlJcXf0Ha5l8j7bR1yq141n00pLar4zLPklveRwBYVyx1ZPE5JKb1QsfxicrFazVHkc+CLledrsY1vFi9r+jfRhfOiu72T3Op6a0ppeptsVwB/Ie+vXWB5K/Qh5JbO/2qz/N3kFtGOfK2dc/WlVZzDb21zDk8it7ifk1KaVbH8MvKo3Cv9vydJ3cXuxJLUA1JKL0fENeTi8K6IuBr4M3BbSmlhJ1c3sXj8U5XtPBIRc4CNI2Jk22KrikvIX/IPJ3fBbLVCV+LCjcBc4MSImEhu9boZuKudL/3dZXNyN9ZHgVOqXEIJuQDbssr8u1M73cCLLsqfAg4GtiIXU5U/5o6tWHY4sDXwTErpzlpCR7729XPklvM3k4vUSmPJrenQ8TGdHxF3Au8mFzd317L9TujUcY2It5GLkneTfwQa2maRsW0/A7yUUvp7lfn/LB4rrzVt3Rc3Vln+L8AKmSJiBLApMLfKDwDwxj7drsp7K+nMedFD2j0XKubvQv57biIXtGsCLe38kPQXOi7g/9beG108h1c6bimP0P1Pciu3JHU7i1hJ/c1T5OKnp7+YQu4KeALwMd5oHVwceeCkL6WUnqlxPa2D2zzVzvtPka9dG8UqrkNLKc2JiD8Cu0fElimlB4vr6/YkFzH3VCz7ckTsVGT/MG+0SD0XET8ktwy/VuPf0Bmji8fNyNcKt2etKvOerjKv1RXkax//QW4RfJrcUg7weXLX2Vajise5qwoLEBEfIbdWLSZfO/oY+VrXZeSu6O9ps/5ajmlljm7TmeNaLPcn8veFP5Kv13yZ/HdtS75utVprcXvX8ra2mg6smNe6L1b695BSej0i2rYOdve+68x50RM6+/e0u79WMb9V1X8jq3EOt7e9p7GIldRDLGIl9Td/AXYj37v0wk58rrVrXHv/b46izRf3oivlacBpEbERuSXrCHJX0ibg32vcdmthuj75i2VbG7RZblV+CuxObn09kdwtcFAxfwVFV8Kji0GOtiLvu+OAU8mtVV+rcZud0fp3/CKltH8nP5uqzYw8kvBHyIPn7FXZBbXovvyVNh9pPZa1/tjxTfL1gc0ppQfbbPt8cgFQqfKY3l9lfZ05ph2dm1ULuU4c11PIrX7vTSndULmOiDiJXMSurta/cT3aDBQWEYOAN7Fi9//KfVdNzfuuC+cFdGF/r0Jn/57WgcrWa2f59uYDy2//VE1Xz+H1qH4Ot/f3SNJq85pYSf3NT8gjn340IrbqaME21yPOLx43qrLcprzRKlFVSumfxfVue5AHsNklIkZXLLKMFVunKrV2Z921nW2PAx5PtY9k+3PyF+FDiy/qh5NbyC7rIH9KKd2fUjqHXABDHnG1q1q7iFb7mx8iF5E7FV09u8OmxeOvq1zz+2/kQm25lNIr5IGL1ouIWrqlbgo8UOXL/wCKaxnb6OiYjiK3ci4mD/izKu2em0BzlXnL1XBcNwVeaFvAFtoWNV11Rwfr24U250jRhfYxYGw7t595b5v1dqRT50WhK/u7o/O93XOh0PbveYjcnf4dRdfqtqqdb7Xo7Dnc7nGLfJumavtHkrqFRaykfqUYgOQ08rVe/xcV9/qsFBF7km9B0eohcuG3b9H9tnW5NYEfVPn8mIh4e5VVDyd3g32dFW8b8jztf+m7qHg8JSLGVGxjIPBt8v/lNbcqFy3EV5JbGb9AHtH0t8WgOJV/w9siolqrTuu8zl7bW6l1YKvxbd8oiolzyC1QPyj28QqKe2R2+CNEG7OKx13brOfNrHhtcKXW43p+tLlfaUQMiIgNKmbNAjarvD9m0cp5Grmls61p5B9Tji9+iKj0TfJox9Pau763jdZrHI8sWi5bt78RuWV1BZ08rrOAdSPiHW3WcTTdN+DRxcXjyRGxbsU2hpJvW1TNReSB075V/Dto/cybeKMV+aJqH2xjVvG4a+XMVZwXndrfhXbPd/L1yA+Tf9g6oE2OA8g9Nh4h9yIh5VtpXUH+4eyUNstvQ76FVlfMonPn8HTeOIebKj4zAPgWfseU1IPsTiyp30kpnVF8+fw6cHtE3EK+Fc6/yF/k302+HrOl4jOvRcTZ5C/Id0bEL8j/h+5Ovv3Ek202M7ZY7l7yLS3+SS5MPkjuZveDNoOy/BE4uBgM6g7yl8ObUko3pZRuiYizyF0b7yuuqX2FfJ/Yrclfbr/Vyd3wU/LgL/9d8bqt3clFwq3kL9HPklt99yW3HHd2m5VuJRdLny9apFuv0zunGJzqm+Ti+tPke6b+iXx96pvJx+Zd5FF8H6hxe7eTi4X9i+P9F/Kx3otcQLQ9fgAXkAuIw4BHI+JX5PukbkjufnsR+Qs+wPeAH5GP+dXk4/cu8pf/1gG+lkspzYqIz5MLpTsi4spi3e8hD6rzEPl66lVKKd0WETeRz9u/FftqvWKbv2flH0c6c1y/Ty5W/1JkfInc2rgL+frJFYqurkgp3RwR55BHg249v1vvEzuf6teKfpt87PYF7o6I35LvE3sg+Rw5K6X0lxo23+nzogv7G/K/7y8DPy7OjwXAiymlc1NKKSIOJ1+HekVxnj1EHsBpv2LZjxej/rY6kXwOfiUidiTfl3UD4D/IA3XtR+dHB+7KOXwi8J3iM1eQz489yN2q7wFW+PFDkrpNZ+7H4+Tk5NSXJvIAT+eQu42+TG4ZfYrcAns0sEab5YP85fGxYtkngLPIX55nseJ9YkeRW2Vai68lxbpvIN8eI9qs+83k7rzPkLseVrvP48HkL9kLyF1N7ycXckO7+Pc/WmzneWBIO/vnu+Rifl7xN8wiFy813YOzWM8K+6Zi/p7kYvZfvHGP16Y2+/swcgHwQrHP5xb74KvARhXLNlHl/pxttrcu+R6ss4r99xhwRrXj1+Zzk8gjsL7GG/frnQ5MbLPcEcBd5B8YngN+Abydju8r+gHgOnKxtoTc1fwsYFQnj+Uo4MfkgnQJ+ZyeXG2/dPa4kn94+Wtx3r1Y5G29vnule/2uYl9W3RfFsf4Mufv0EnLx+L/k1sb2zp+hxXlwH7l77YLi3Dikk/uu0+dFZ/Z3xWe+WPH3Vbv37RbApeT/J14rHqcBW7STeyz5x6d5xd9/F/nSgAOK9X++zfI3sIr7ttK1c/gQ8g9vi4ss08g/9Kxye05OTk5dnSKl9q7vlyRJlSLiRnLX6/8pO4tUTURMIRf3e6aUfl92HknqCV6vIElS7X5Ovo+mVKrKa1cr5r0d+Cy550K1++5KUp/gNbGSJHWgGDjoEmA2+d6/3TVisrQ6WiLi7+SuzK+QrxXfh9xA8amU0uIyw0lST7KIlSSpY4l8y5sDyNdAfr7cOBIA55MHcDoEGEG+Xvn3wLdT9VsiSVKf4TWxkiRJkqSG4TWxkiRJkqSG0bDdid/0pjelpqamsmNIkiRJknrAzJkzn0spjWk7v2GL2KamJlpaWsqOIUmSJEnqARExu9p8uxNLkiRJkhqGRawkSZIkqWFYxEqSJEmSGkbDXhMrSZIkSWoMr732GnPmzGHx4sUrvTd06FDGjRvH4MGDa1qXRawkSZIkqUfNmTOHESNG0NTUREQsn59S4vnnn2fOnDlsvPHGNa3L7sSSJEmSpB61ePFiRo8evUIBCxARjB49umoLbXssYiVJkiRJPa5tAbuq+e3p1SI2Ii6KiGcj4r4q7/1nRKSIeFNvZuoJ06dPp6mpiQEDBtDU1MT06dPLjiRJkiRJfUJvt8ReDOzZdmZEbAR8AHiil/N0u+nTpzN58mRmz55NSonZs2czefJkC1lJkiRJ6ga9WsSmlG4CXqjy1veArwCpN/P0hJNPPpldFi7k1+SqHGDhwoWcfPLJZcaSJEmSpFKlVL3ca29+e0q/JjYi9gXmppTurmHZyRHREhEt8+bN64V0nffEE0/QDHwIOLzNfEmSJEnqj4YOHcrzzz+/UsHaOjrx0KFDa15XqbfYiYhhwFd5o9GyQymlqcBUgObm5rpstR0/fjyXzZ7NFGA/YC3gX8V8SZIkSeqPxo0bx5w5c6jWGNl6n9halX2f2LcAGwN3FyNSjQPuiIh/Syk9XWqyLpoyZQqTJ0/mzwsX8u/kQvbnw4YxZcqUsqNJkiRJUikGDx5c831gV6XUIjaldC/w5tbXETELaE4pPVdaqNU0adIkAK797Gf59xde4JNDh7Ln1KnL50uSJEmSuq63b7EzA7gV2CIi5kTE0b25/d4yadIkznj0URg8mHe/+iqTdtut7EiSJEmS1Cf09ujEh6SUNkgpDU4pjUspXdjm/aZGboVdwbrrwj77wLJlcPnlZaeRJEmSpD6h9NGJ+7RDD82P06aVm0OSJEmS+giL2J60zz4wciTccQc88EDZaSRJkiSp4VnE9qShQ+HAA/Pz6dPLzSJJkiRJfYBFbE9rHZV4+vR8fawkSZIkqcssYnvau98N48bB7Nlwyy1lp5EkSZKkhmYR29MGDHijNdYBniRJkiRptVjE9obWUYqvvBKWLCk3iyRJkiQ1MIvY3rD11rDNNjB/Plx7bdlpJEmSJKlhWcT2Fu8ZK0mSJEmrzSK2txxyCETANdfAiy+WnUaSJEmSGpJFbG8ZOxZ22w1efRWuuqrsNJIkSZLUkCxie5NdiiVJkiRptVjE9qb994ehQ+HGG+GJJ8pOI0mSJEkNxyK2N629Nnz4w/n5jBnlZpEkSZKkBmQR29tauxRfeimkVG4WSZIkSWowFrG9bY89YPRouP9+uOeestNIkiRJUkOxiO1tQ4bAQQfl5w7wJEmSJEmdYhFbhtYuxZddBkuXlptFkiRJkhqIRWwZdtoJNtkEnnwSbrih7DSSJEmS1DAsYssQ4T1jJUmSJKkLLGLLMmlSfrz6ali4sNwskiRJktQgLGLLsvnm8G//BgsWwDXXlJ1GkiRJkhqCRWyZWltj7VIsSZIkSTWxiC3TQQfBwIHwu9/Bc8+VnUaSJEmS6p5FbJnWWw8+8AF4/XW48sqy00iSJElS3bOILZujFEuSJElSzXq1iI2IiyLi2Yi4r2LetyLioYi4JyJ+ERGjejNT6fbdF4YPh1tvhcceKzuNJEmSJNW13m6JvRjYs82864GtU0rvAB4BTurlTOUaPhz23z8/nz693CySJEmSVOd6tYhNKd0EvNBm3nUppdeLl38FxvVmprpQ2aU4pXKzSJIkSVIdq7drYo8Cri07RK/bbTdYf3149FG4/fay00iSJElS3aqbIjYiTgZeB9rtUxsRkyOiJSJa5s2b13vhetqgQXDIIfm5AzxJkiRJUrvqooiNiCOADwKTUmq/P21KaWpKqTml1DxmzJhey9crJk3Kj5dfDq+9Vm4WSZIkSapTpRexEbEn8BXgwymlhWXnKc3EifDWt8K8efCHP5SdRpIkSZLqUm/fYmcGcCuwRUTMiYijgXOBEcD1EXFXRPyoNzPVjQjvGStJkiRJqxAd9N6ta83NzamlpaXsGN3r8cdhk01gzTXhmWdgxIiyE0mSJElSKSJiZkqpue380rsTq8LGG8Muu8CiRfDLX5adRpIkSZLqjkVsvbFLsSRJkiS1yyK23hx4IAwenAd3euqpstNIkiRJUl2xiK03664L++wDy5bl2+1IkiRJkpaziK1HdimWJEmSpKosYuvRPvvAyJFwxx3w4INlp5EkSZKkumERW4+GDoUDDsjPp08vN4skSZIk1RGL2HrV2qV4+vR8fawkSZIkySK2br373TBuHMyaBbfcUnYaSZIkSaoLFrH1asAAmDQpP3eAJ0mSJEkCLGLrW2uX4iuvhCVLys0iSZIkSXXAIraebb01bLMNzJ8P115bdhpJkiRJKp1FbL3znrGSJEmStJxFbL075BCIgGuugRdfLDuNJEmSJJXKIrbejR0Lu+0Gr74KV11VdhpJkiRJKpVFbCNoHaV4+vRyc0iSJElSySxiG8H++8PQoXDDDfDEE2WnkSRJkqTSWMQ2gpEj4cMfzs9nzCg3iyRJkiSVyCK2UbSOUnzppZBSuVkkSZIkqSQWsY1ijz1g9Gi4/364556y00iSJElSKSxiG8WQIXDQQfm594yVJEmS1E9ZxDaS1i7Fl10GS5eWm0WSJEmSSmAR20h22gk22QSefDKPVCxJkiRJ/YxFbCOJeKM11i7FkiRJkvohi9hGM2lSfrz6ali0qNwskiRJktTLLGIbzeabww47wIIFcM01ZaeRJEmSpF7Vq0VsRFwUEc9GxH0V89aNiOsj4tHicZ3ezNSQ7FIsSZIkqZ/q7ZbYi4E928w7EfhjSmkz4I/Fa3XkoINg4EC49lp47rmy00iSJElSr+nVIjaldBPwQpvZ+wI/LZ7/FNivNzM1pPXWgw98AF5/Ha68suw0kiRJktRr6uGa2PVSSk8Vz58G1iszTMOwS7EkSZKkfqgeitjlUkoJSO29HxGTI6IlIlrmzZvXi8nq0L77wvDhcOut8NhjZaeRJEmSpF5RD0XsMxGxAUDx+Gx7C6aUpqaUmlNKzWPGjOm1gHVp+HDYf//8fPr0crNIkiRJUi+phyL218DhxfPDgV+VmKWxVHYpTu02YEuSJElSn9Hbt9iZAdwKbBERcyLiaOBMYPeIeBR4f/FatdhtN1h/fXj0UWhpKTuNJEmSJPW43h6d+JCU0gYppcEppXEppQtTSs+nlN6XUtospfT+lFLb0YvVnkGD4OCD83MHeJIkSZLUD9RDd2KtjtYuxTNmwGuvlZtFkiRJknqYRWyjmzgR3vpWmDcP/vCHstNIkiRJUo+yiG10Ed4zVpIkSVK/YRHbF3zsY/nxF7+ABQvKzSJJkiRJPcgiti/YeGPYZRdYtAh++cuy00iSJElSj7GI7SvsUixJkiSpH7CI7SsOPBAGD86DOz39dNlpJEmSJKlHWMT2FeuuC/vsA8uWweWXl51GkiRJknqERWxfYpdiSZIkSX2cRWxfss8+MHIkzJwJDz5YdhpJkiRJ6nYWsX3J0KFwwAH5+fTp5WaRJEmSpB5gEdvXtHYpnj49Xx8rSZIkSX2IRWxf8+53w7hxMGsW3HJL2WkkSZIkqVtZxPY1AwbApEn5uQM8SZIkSepjLGL7otYuxVdeCUuWlJtFkiRJkrqRRWxftPXWsM02MH8+XHtt2WkkSZIkqdsMqnXBiGgCdgI2BNYEngMeBv6aUlrcE+G0Gg49FO6+O3cp3m+/stNIkiRJUreIlFL7b0aMAj5RTJsBUWWxV4FfAz9MKd3QAxmram5uTi0tLb21ucYzdy5stBEMGQJPPw2jRpWdSJIkSZJqFhEzU0rNbee32504Ir4E/AP4IvB74D+ATYGRwBBgfWBn4ARgFPCHiPhDRGzR/fHVaWPHwnvfm6+JvfrqstNIkiRJUrfo6JrYjwFHAeNSSp9LKV2dUvpHSmlBSun1lNKzKaXbUkpnp5Q+AIwH7gE+3BvBVYPWAZ4cpViSJElSH9Fhd+J6ZnfiGrz0Eqy/PixeDLNnw/jxZSeSJEmSpJp0ujux+oCRI+HDRcP4jBnlZpEkSZKkbtDRNbEDapyqDfaketHapfjSS6FBW90lSZIkqVVHLbGvA6/VML0eEa9GxCMR8V8RUfNte9QL9tgDRo+G+++He+4pO40kSZIkrZaOCs7TgVqb7tYENge+BAwETlrNXOouQ4bAQQfBD3+YB3jaZpuyE0mSJElSl3XrwE4R8QXg+JTSJt220nY4sFMn3HorvPOdsOGG8MQTMHBg2YkkSZIkqUO9NbDTTdTeeruCiPhCRNwfEfdFxIyIGNrN2fqvnXaCTTaBJ5+EG28sO40kSZIkdVlHAzt9sQuFZAI+09kQETEW+CzQnFLamtwl+eDOrkftiPCesZIkSZL6hI5aYg8DHo+IMyOi3QspI2KdiDgsIq4D/gKM6GKWQcCaxcBQw4Anu7geVTNpUn686ipYtKjcLJIkSZLURR0VsROBE4C9gDsj4sWI+HNE/Lzo7vu7iHgEeA44H5gLbJVSurKzIVJKc4FvA08ATwEvpZSu6+x61IHNN4cddoAFC+Caa8pOI0mSJEld0m4Rm7JLUkrbADsD3wMWAJsA25FbXP8MHAVsmFI6MqU0qyshImIdYF9gY2BDYHhEHFpluckR0RIRLfPmzevKpvo3uxRLkiRJanDdOjpxl0NEHAjsmVI6unj9cWCnlNKx7X3G0Ym74JlnYOzYfI3sU0/Bm95UdiJJkiRJqqq3RifuqieAnSJiWEQE8D7gwZIz9T3rrQcf+AC8/jpc2ele35IkSZJUurooYlNKtwFXAXcA95JzTS01VF9ll2JJkiRJDawuuhN3hd2Ju+iVV3KL7CuvwN//Dm95S9mJJEmSJGkl9d6dWL1l+HDYf//8/LLLys0iSZIkSZ1kEdsfVXYpbtCWeEmSJEn9k0Vsf7TbbrlL8SOPgF2yJUmSJDWQmovYYuTgz0TEzyLij8XjsRGxZk8GVA8YNAgOOSQ/d4AnSZIkSQ2kpiI2ItYnjxz8A6AZGFY8ngvcEd7tB4cAACAASURBVBHr9VhC9YzWLsUzZsBrr5WbRZIkSZJqVGtL7FnAOsC/p5Q2TintnFLaGNgFGAX8T08FVA+ZOJGXNtwQ5s1j7yFDaGpqYvr06WWnkiRJkqQO1VrE7gWclFK6uXJmSukW4BRgn+4Opp41/bLL+N68eQBMAmbPns3kyZMtZCVJkiTVtVqL2LWAJ9t5b07xvhrIySefzE+LbsQfIR/AhQsXcvLJJ5eaS5IkSZI6UmsR+zBwWDvvHQo81D1x1FueeOIJZgE3ki9w/q+K+ZIkSZJUrwbVuNy3gUuKAZwuA54C1gcOBt5P+wWu6tT48eOZPXs2XwT+CnwOuAb4+/jx5QaTJEmSpA7U1BKbUpoGfBrYGrgA+D/gQuAdwKdTSpf1WEL1iClTpjBs2DDuAL5RzLs4gm999atlxpIkSZKkDtV8n9iU0lRgQ+BtwL8Xj2NTSj/uoWzqQZMmTWLq1KlMmDCB/wHuGDKEcSlx4I03lh1NkiRJktpV631iT42IDVNKy1JKD6aUbi4el0XEBhFxak8HVfebNGkSs2bN4rWUmHjffTBsGFx2GVx5ZdnRJEmSJKmqWltivw6Ma+e9DYv31cg22wy+8538/NOfhifbG4xakiRJkspTaxEbHby3DrCkG7KobJ/6FOy1F8yfD0cdBSmVnUiSJEmSVtDu6MQRsSuwW8WsT0XEB9sstiawD3B/90dTr4uACy+ErbeG3/8ezjsPjj227FSSJEmStFxHt9h5D3BK8TwBR1ZZ5lXgAeCz3ZxLZdlgAzj/fDjwQPjSl+D974fNNy87lSRJkiQBHXQnTil9I6U0IKU0gNydeKfW1xXT0JTSxJTSrb0XWT3ugAPg0ENh0SI47DB4/fWyE0mSJEkSUPt9YgeklP7W02FUR845B8aNg7/9Dc44o+w0kiRJkgTUfoudd1ZeDxsRoyNiRkTcGxHfjoiBPRdRpRg1Ci6+OD8//XRoaSk1jiRJkiRB7aMT/w+wfcXrbwF7A48AxwBf7eZcqgfvex98/vOwdGnuVrxoUdmJJEmSJPVztRaxbwVaACJiMHAA8IWU0keBk4GP9Uw8le6MM2DLLeGhh+DEE8tOI0mSJKmfq7WIXQt4uXj+b8Bw4DfF6zuA8d2cS/VizTVh2jQYNAh+8AO4/vqyE0mSJEnqx2otYucC2xTP9wLuSyk9W7xeB1jY3cFURyZOhK9/PT8/8kiYP7/cPJIkSZL6rVqL2BnAGRFxFfBFYFrFexOBR7s7mOrMiSfCTjvB3Lnwmc+UnUaSJElSP1VrEXsaeXCnNYAzge9WvLcN8LPujaW6M2gQXHopDBsGl10GV1xRdiJJkiRJ/VCklMrO0CXNzc2pxdu+9L4f/QiOOQbWWQfuvRfGji07kSRJkqQ+KCJmppSa286vtSW2x0XEqIi4KiIeiogHI2LnsjOpik99CvbaK18Xe/TR0KA/gkiSJElqTINqWSgiHgc6rFZSSpusZpazgd+llA6IiCHAsNVcn3pCBFx4IWy9Nfz+93DeeXDssWWnkiRJktRP1NoSe2OV6T5g7WIdN6xOiIgYCbwbuBAgpfRqSunF1VmnetAGG8D55+fnX/oSPPxwuXkkSZIk9Rs1tcSmlI6oNj8iRgG/A/6wmjk2BuYBP4mIbYCZwOdSSq+s5nrVUw44AA49NN9D9uMfh5tvzoM/SZIkSVIPWq1rYovW0m8Bp65mjkHkW/Wcl1LaDngFOLHtQhExOSJaIqJl3rx5q7lJrbZzzoGNNoK//Q3OOKPsNJIkSZL6ge4Y2GkxMG411zEHmJNSuq14fRW5qF1BSmlqSqk5pdQ8ZsyY1dykVtuoUXDxxfn56afD7beXGkeSJElS39flIjYiBkXEtuR7yN6/OiFSSk8D/4yILYpZ7wMeWJ11qpfstht8/vOwdCkcdhgsXFh2IkmSJEl9WE1FbEQsi4illROwhHzt6qbAF7ohy/HA9Ii4B9gWsH9qozjjDNhyyzzA04kr9QKXJEmSpG5T60g8p7PyLXYWA7OBa1NKL61ukJTSXcBKN7JVA1hzzTzA04475utkP/Qh2H33slNJkiRJ6oNqHZ34tB7OoUY3cSKcdhqccgoceSTcey+ss07ZqSRJkiT1Me12J46IARHxoYjYuoNl3h4RH+qZaGo4J5wAO+0Ec+fCcceVnUaSJElSH9TRNbGHAjPIt7tpzwJgRkQc0q2p1JgGDYJLL4Vhw2DGDLjiirITSZIkSepjVlXE/iSl9Hh7C6SUZgEXAod3cy41qk03he9+Nz8/5pjcKitJkiRJ3aSjInYicF0N6/gDDsikSpMnw957w/z5cNRRkNqOCSZJkiRJXdNRETsCmF/DOuYXy0pZBFxwAYweDdddBz/8YdmJJEmSJPURHRWxzwETaljH+GJZ6Q0bbADnn5+ff/nL+R6ykiRJkrSaOipi/0Jt17oeUSwrreijH4XDDoNFi/Lja6+VnUiSJElSg+uoiP0+8L6I+F5EDGn7ZkQMjojvA7sB3+upgGpw55wDG20Et98OZ5xRdhpJkiRJDS5SB4PuRMTnge8Az5MHeZpdvDUB2B0YDfxnSunsHs65kubm5tTS0tLbm1VX/OlP8L73wcCBcOutsMMOZSeSJEmSVOciYmZKaaVBhDtqiSWl9H3gvcDtwEeAk4rpI0AL8N4yClg1mN12gy98AZYuzd2KFy4sO5EkSZKkBtVhEQuQUroppbQPeQTi9Ytp7ZTSPimlP/d0QPURZ5wBW22VB3g68cSy00iSJElqUKssYlullJallJ4tpqU9GUp90NChMG0aDBqUr5O9/vqyE0mSJElqQDUXsdJq2247OO20/PzII2F+LbchliRJkqQ3WMSqd51wAuy8M8ydC8cdV3YaSZIkSQ3GIla9a9AguOQSGD4cZsyAyy8vO5EkSZKkBmIRq9636abwne/k58cck1tlJUmSJKkGFrEqx+TJsPfe8OKLcNRR0MH9iiVJkiSplUWsyhEBF1wAo0fDddfBD39YdiJJkiRJDcAiVuXZYAM4//z8/MtfzveQlSRJkqQOWMSqXB/9KBx2GCxalB9fe63sRJIkSZLqmEWsynfOOTB+PNx+O5xxRtlpJEmSJNUxi1iVb+RIuPji/Pyb38zFrCRJkiRVYRGr+vDe98IXvgBLl8Khh8LChWUnkiRJklSHLGJVP844A7baCh55BE44oew0kiRJkuqQRazqx9ChMG0aDB4M554L119fdiJJkiRJdaauitiIGBgRd0bEb8rOopJstx2cdlp+fsQR8MILZaaRJEmSVGfqqogFPgc8WHYIlewrX4Gdd4Ynn4Tjjis7jSRJkqQ6UjdFbESMA/YBLig7i0o2aBBccgkMHw6XX54nSZIkSaKOiljg+8BXgGVlB1Ed2HRT+O538/NjjoG5c8vNI0mSJKku1EURGxEfBJ5NKc1cxXKTI6IlIlrmzZvXS+lUmk9+EvbZB158EY48Epb5+4YkSZLU39VFEQu8C/hwRMwCLgd2i4hpbRdKKU1NKTWnlJrHjBnT2xnV2yLgggtg9Gi4/npOfdObGDBgAE1NTUyfPr3sdJIkSZJKUBdFbErppJTSuJRSE3Aw8KeU0qElx1I9WH99bjo0nwonzp/PZikxe/ZsJk+ebCErSZIk9UN1UcRKHfn4L3/JT4FhwFXABGDhwoWcfPLJ5QaTJEmS1OvqrohNKd2QUvpg2TlUP5544gk+CzwKvB24E9i3mC9JkiSpf6m7IlZqa/z48bwM7Aj8ClgH+CVwwVprwauvlppNkiRJUu+yiFXdmzJlCsOGDWM+sB/wBeA14KgFC2CXXeDxx8sNKEmSJKnXWMSq7k2aNImpU6cyYcIEIoJfTJjAH087DSZMgNtvh+22g1/8ouyYkiRJknpBpJTKztAlzc3NqaWlpewYKtP8+fn+sb/6VX792c/CWWfBGmuUm0uSJEnSaouImSml5rbzbYlV41pnndwC+/3vw+DB8IMfwLveBf/4R9nJJEmSJPUQi1g1tgj43Ofg5puhqQlmzszdi6++uuxkkiRJknqARaz6hh12gDvvhI98BF5+GQ44AI4/HpYsKTuZJEmSpG5kEau+Y9So3AJ79tm5e/G55+buxY89VnYySZIkSd3EIlZ9S0Qe4Onmm2HjjXP34okT4aqryk4mSZIkqRtYxKpv2mEHuOMO2H//3L34wAPhM5+BxYvLTiZJkiRpNVjEqu8aNSq3wJ5zTu5e/L//C+98J/z972UnkyRJktRFFrHq2yJyC+wtt+TuxXfembsXX3ll2ckkSZIkdYFFrPqH5ubcvfijH4UFC+Cgg+DYY+1eLEmSJDUYi1j1H6NGwc9+lkctHjIEzjsPdt4ZHn207GSSJEmSamQRq/4lAo47Lncv3mQTuOsu2H57uOKKspNJkiRJqoFFrPqn7bfP3YsPPDB3Lz74YDjmGLsXS5IkSXXOIlb918iRuQX2f/83dy/+0Y9gp53gkUfKTiZJkiSpHRax6t8i8gBPt94Kb3kL3H13bqWdMaPsZJIkSZKqsIiVIN9254474D/+A/71L/jYx+BTn4JFi8pOJkmSJKmCRazUau214fLL86jFa6wBU6fm7sUPP1x2MkmSJEkFi1ipUgR8+tO5e/Gmm8I99+R7zF52WdnJJEmSJGERK1W33XYwcyYcdFDuXjxpEkyebPdiSZIkqWQWsVJ71l47D/D0ox/l7sU//jHsuCM89FDZySRJkqR+yyJW6khEHuDpr3+FzTaDe+/N3YunTy87mSRJktQvWcRKtdh229y9+JBD4JVX4NBD4ROfgIULy04mSZIk9SsWsVKtRozILbBTp+buxRdeaPdiSZIkqZfVRREbERtFxP+LiAci4v6I+FzZmaSqIuCTn4TbboPNN4f77svdi6dNKzuZJEmS1C/URRELvA78Z0ppK2An4LiI2KrkTFL7ttkGWlrgYx/L3YsPO8zuxZIkSVIvqIsiNqX0VErpjuL5AuBBYGy5qaRVGDEit8D++McwdOjy7sXXnHUWTU1NDBgwgKamJqY7CJQkSZLUbeqiiK0UEU3AdsBt5SaRahCRW2Bvuw222ALuu4/dTjiBd8+eTUqJ2bNnM3nyZAtZSZIkqZvUVREbEWsBVwOfTym9XOX9yRHREhEt8+bN6/2AUnve8Q5oaeHnw4czHLgE+CNwMLB04UJOPvnkcvNJkiRJfUTdFLERMZhcwE5PKf282jIppakppeaUUvOYMWN6N6C0KmutxQGvvMJRwCvAbsAM4EngP2fPhrvvLjWeJEmS1BfURREbEQFcCDyYUvpu2Xmkrho/YQI/IV/QfSwwE1gXOB7yvWabm+FHP4KXXioxpSRJktS46qKIBd4FHAbsFhF3FdPeZYeSOmvKlCkMGzaMl4DzgGbgnUOH8vDuu8OoUTBzJhxzDGywAXz843DTTZBSyaklSZKkxlEXRWxK6S8ppUgpvSOltG0x/bbsXFJnTZo0ialTpzJhwgQiggkTJnDcBRewxXXXwZNP5tGM3/teWLQILr0U3vOePCDUmWfCU0+VHV+SJEmqe5EatBWoubk5tbS0lB1D6prHHoOLLoKLL87FLcDAgbDPPnD00bD33jBoUKkRJUmSpDJFxMyUUnPb+XXREiv1O295C0yZArNnw29+A/vtl2/X8+tfw777wvjxcNJJ8OijZSeVJEmS6opFrFSmQYNy6+svfgFz5sBZZ8Hmm+euxWeemZ/vumvuerxwYdlpJUmSpNJZxEr1Yr314Mtfhocegj//GQ4/HIYNgxtvzINAbbghHHtsHhyqQS8DkCRJklaXRaxUbyJgl13y9bJPPQXnnw877JBvy3Peefk2PRMnwrnnwvz5ZaeVJEmSepVFrFTP1l4bJk+Gv/0N7rkHPvc5WHdduOsuOP74fKueSZPgT3+CZcvKTitJkiT1OItYqVG8/e3w/e/D3Llw+eWw++6wZAlcdhm8732w2WZ5sKi5c8tOKkmSJPUYi1ip0QwdCgcdBNddB48/DqeeCuPGwT/+Aaeckkc2bh0s6rXXyk4rSZIkdSuLWKmRNTXBN74Bs2bBtdfCAQfk+83+9rew//65uG0dLEqSJEnqAyxipb5g4EDYc0/42c9yd+LvfAe22gqefRa+/W3Ycss8WNRPfgKvvFJ2WkmSJKnLLGKlvmbMGPjiF+G+++DWW+Hoo2H4cLj5ZjjqqDwY1OTJ/O7002maMIEBAwbQ1NTE9OnTy04uSZIkrVKkBr3fZHNzc2ppaSk7htQYFiyAK6+ECy/MhW3hXuAnwE3AY2uuybk//jGTJk0qK6UkSZK0XETMTCk1rzTfIlbqZx54gB/vtBP7LVjAmIrZrwIPDxnC2484ArbfPt+PduutYciQkoJKkiSpP7OIlbTcgAEDGJQSHwI+AmwPbEGV6wuGDIF3vCMXtK2F7dveBoMH93ZkSZIk9TPtFbGDyggjqVzjx49n9uzZ/Bz4eTFvBLDXeutxxVe+AjNnQksLPPJIfqz8wWiNNWCbbd4oarffPg8iZWErSZKkXmARK/VDU6ZMYfLkySxcuHD5vKXDhvHh73wHKq+JfekluPPON4ralhb4+9/hb3/LU6uhQ3NhW9liu+WWMMj/YiRJktS97E4s9VPTp0/n5JNP5oknnmD8+PFMmTKltkGdXnwR7rgjF7atxe1jj6283Jprwrbbrthiu+WW+XZAkiRJ0ip4TayknjN//huFbWuL7eOPr7zcsGG5sK1ssd1iCwtbSZIkrcQiVlLveuGFN1prW4vbWbNWXm74cNhuuxUL2803hwFvDDPV5VZjSZIkNSyLWEnle/75Nwra1scnnlh5ubXWgokTYfvtuXnJEo676CLuWbyY1v+thg0bxtSpUy1kJUmS+jCLWEn1ad68FVtrZ86Ef/5zpcVeBu4D5hbTolGjOOncc2HsWNhww/w4fHgvh5ckSVJPsYiV1DiefXZ5UfvLU0+lGRhXy+dGjlyxqK32fL31HDVZkiSpAVjESmpITU1NzJ49m/WAzYENgbHAliNG8Im99oInn4S5c/PjkiWrXuGAAbD++h0XumPH5oI4omf/OEmSJLWrvSLW5ghJda31nrbPLFzIM8W8YcOGMfW881a8p21KeTCpuXPfKGpbn1e+fvbZ/PzJJ3P35fYMG7bqVt0NN4QhQ1b4mINQSZIk9SyLWEl1rbUAXGVhGAGjR+fpHe9of4WvvgpPP1292K18/sor8OijeerImDHLi9tHFy1i1p//zO6vv87zwMuzZ3P+0Uez9pNP8qFJk2DttfN1u7bwSpIkdZndiSWprZTg5ZfbL3Bbnz/9NCxd2rl1R8CIEbmgrTa19161+YMHr9afaauxJEmqZ3YnlqRaReRrYkeOhC23bH+5pUtz9+SiuD1uv/3YgHzN7jrA2sU0Athi/fVzYbxwYX58+eXVzzl0aOcL32K65oYbOPXUU3l+8WIGALNnz2by5MkAdVfIWmxLkqRKddMSGxF7AmcDA4ELUkpndrS8LbGS6k3rIFRtTZgwgVmzZuUXr78OCxbkIrb1sdrU3nuV8zvbCtyBpcAS4LUBAxg5ZgyssUYuktdYY+Wpp+evsQYMHAjkAnby5MksXLhwedZ6vk9wIxXcjZK1UXKCWXtKo2RtlJxg1p7QKDmhsbLW9ejEETEQeATYHZgD3A4cklJ6oL3PWMRKqje9WnClBIsWdb7wLaZHZs5c3ko8lPzrYV0ZNAjWWIP5ixaxaNkylpCL7NeLaeCQIbx9223zcgMH5sfWqaPXXX2vhmX/cMMNfOt73+OVJUtYCiwDhqyxBl895RT22mefPDJ2Z6aIzi9f4/XWjfLjQKPkBLP2lEbJ2ig5waw9oVFyQmNlhfovYncGTksp7VG8PgkgpfTf7X3GIlZSPWqUXzfbthoPBNYANh03jrtvuy3frqjttHhx98yv5TPqmmqFb5V5z7/4Iq8vW8YyIFVMAwYOZMMNN3yjIK51at12N09/ve02Fi1ZskJGgDWGDuXfd9llxW2v6rEzy3bh8Zrf/IZXFi5cnrH1cfiwYey7334rH6dqzzvz3mqsZ8YVV/Cvf/1rhZwAa621Fh875JD219lWR+9303uXXHIJC6pkHTFiBId//OMd56tle9302Z9cfDELFixY/ro169ojRnDkkUd2fftdyLIqF110ES+3k/Xoo4/ulm10lwsvvHCFrK3qLWvbnJX79BOf+EQ5odpxwQUXrJD1LOAZ2vQaqyP1XsQeAOyZUvpE8fowYMeU0mfaLDcZmAwwfvz47at125MkrVpd/xKbErz2GixZwnZbbcWzc+YwFBhCLrYHARutvz7X/PKXuXt267R0afXnq3rd1ffavP7j9dczCBgMDACieBwAbL/ttrBsWdemlGpfTpKkTngb8AAQESxbtqzsOCvpEwM7pZSmAlMht8SWHEeSGlbNty4qQ0S+/+6QIXzpzDOrFttf/va3YccdSwy5sqM7uib6zjt7PkBK7Re8beZP3HZb5s6Zw0Bysd06bTR2LLfcfPMb66p1qtx+N06HHHwwzzzzzPJ8FI/rvfnNTLv00je2u6rHWpZZzcfjjz+e5557bnnGVmNGj+bss89e8ThVe96Z91ZzPSeeeCLPv/ACbdv1Rq+7Lv/93/9d/XNtdfR+N773tVNP5YUqWdddZx1OP/30jjOuanvd+NnTTjuNF+bPB1Y8/uuusw5f//rXu56hC1lW5fTTT28369e+9rVu2053+OY3v7k8a6V6y1qZs3KfrrPOOnztlFPKCdWOb/7XfzG/Yp8+UzyOHz++nEBdlVIqfQJ2Bn5f8fok4KSOPrP99tsnSVLfN23atDRhwoQUEWnChAlp2rRpZUeqatq0aWnYsGGVPV/TsGHD6jJvo2RtlJwpmbWnNErWRsmZkll7QqPkTKmxsqaUEtCSqtWP1Wb29kRuEf4HsDG5x9jdwNs6+oxFrCSp3jRKwZ1S42RtlJwpmbWnNErWRsmZkll7QqPkTKmxsrZXxNbFNbEAEbE38H3yJU8XpZSmdLS8AztJkiRJUt9V99fEppR+C/y27BySJEmSpPo1oOwAkiRJkiTVyiJWkiRJktQwLGIlSZIkSQ3DIlaSJEmS1DAsYiVJkiRJDcMiVpIkSZLUMCxiJUmSJEkNI1JKZWfokoiYB8wuO8cqvAl4ruwQWiWPU+PwWDUOj1Xj8Fg1Do9VY/A4NQ6PVf2bkFIa03ZmwxaxjSAiWlJKzWXnUMc8To3DY9U4PFaNw2PVODxWjcHj1Dg8Vo3L7sSSJEmSpIZhEStJkiRJahgWsT1ratkBVBOPU+PwWDUOj1Xj8Fg1Do9VY/A4NQ6PVYPymlhJkiRJUsOwJVaSJEmS1DAsYldTROwZEQ9HxN8j4sQq768REVcU798WEU29n1IRsVFE/L+IeCAi7o+Iz1VZZteIeCki7iqmU8vIKoiIWRFxb3EcWqq8HxHxg+Lf1T0RMbGMnP1dRGxR8e/lroh4OSI+32YZ/12VJCIuiohnI+K+innrRsT1EfFo8bhOO589vFjm0Yg4vPdS9z/tHKdvRcRDxf9vv4iIUe18tsP/K9W92jlWp0XE3Ir/4/Zu57Mdfl9U92rnWF1RcZxmRcRd7XzWf1cNwO7EqyEiBgKPALsDc4DbgUNSSg9ULHMs8I6U0qcj4mDgIymlg0oJ3I9FxAbABimlOyJiBDAT2K/NsdoV+FJK6YMlxVQhImYBzSmlqvduK74kHA/sDewInJ1S2rH3Eqqt4v/DucCOKaXZFfN3xX9XpYiIdwP/Ai5JKW1dzDsLeCGldGbxRXqd9P/bu/cYOas6jOPfx7YCUsAWEspNvBFNGi0CVhssEMFyEWhBg6sIVAWFiJH4h1wUIUWjGC4RQjDhYhGhXAUKQqEUAREhYA2IILGaGtu0pVCgFCpQ+vjHexbG6czust2dC/t8ks3MvOfMmTP75rzz/t5zee2T6943HngU2AMw1fFyd9vPt/QLjBBN9tM04B7b6ySdDVC/n0q+xfRxrIyh1WRfnQmssX1OH+/r93wxhlajfVWXfi7wou1ZDdIWk3bV8dITu3EmA4ts/8v2a8A1wPS6PNOBK8rzG4B9JamFdQzA9jLbC8vzl4CngB3aW6vYCNOpfphs+yHgveVCRbTPvsA/awPYaC/b9wOr6jbX/iZdAcxo8Nb9gfm2V5XAdT5wwLBVdIRrtJ9s32V7XXn5ELBjyysWG2jSpgZiIOeLMYT62lflPPwIYE5LKxVDKkHsxtkB+E/N6yVsGBi9maf8IL0IbN2S2kVDZUj3J4CHGyRPkfSYpDskTWxpxaKWgbsk/VnSNxukD6TtRWv10PyEIO2qc2xre1l5vhzYtkGetK/O8nXgjiZp/R0rozVOLEO/L28yRD9tqrNMBVbY/keT9LSrLpAgNkYUSWOBG4GTbK+uS14I7Gx7EnAhcHOr6xdv+ozt3YADgW+XYUHRoSS9GzgUuL5BctpVh3I1nyhzijqYpB8A64CrmmTJsbL9LgY+BOwKLAPObW91YgC+TN+9sGlXXSBB7MZZCuxU83rHsq1hHkmjga2A51pSu/g/ksZQBbBX2f5tfbrt1bbXlOe3A2MkbdPiagZge2l5fAa4iWooVq2BtL1onQOBhbZX1CekXXWcFb1D78vjMw3ypH11AEkzgYOBI91kAZMBHCtjmNleYfsN2+uBS2i8D9KmOkQ5Fz8cuLZZnrSr7pAgduM8Auwi6QOlJ6IHmFuXZy7Qu7LjF6kWasiV7xYr8x8uA56yfV6TPBN65ytLmkzVPnLBocUkbV4W30LS5sA04Im6bHOBo1X5NNXiDMuIdml6VTvtquPU/iYdA9zSIM+dwDRJ48rQyGllW7SIpAOA7wOH2n6lSZ6BHCtjmNWtx3AYjffBQM4XozX2A/5ue0mjxLSr7jG63RXoZmXVwBOpftxHAZfb/pukWcCjtudSBU5XE8DLkAAABYBJREFUSlpENcG8p301HtH2BI4C/lqzpPppwPsAbP+S6iLDCZLWAWuBnlxwaIttgZtK3DMauNr2PEnHw5v76naqlYkXAa8AX2tTXUe88iP/OeBbNdtq91XaVZtImgPsA2wjaQlwBvAz4DpJ3wD+TbW4CZL2AI63faztVZLOojrxBphlezCL2cQANNlPpwKbAPPLsfChcpeD7YFLbR9Ek2NlG77CiNFkX+0jaVeqofmLKcfC2n3V7HyxDV9hxGi0r2xfRoP1G9KuulNusRMRERERERFdI8OJIyIiIiIiomskiI2IiIiIiIiukSA2IiIiIiIiukaC2IiIiIiIiOgaCWIjIiIiIiKiaySIjYiIGCBJMyVZ0ofL65MkHd7uevVH0kRJSyU9Lml3SVdLOqb/d0ZERHSeBLERERGDdxLQ8UEscCQwD/g1cCswsTxGRER0ndHtrkBERES8RdImtl8dyjJtn1bz8pyhLDsiIqLV0hMbERExCJIWAzsDR5YhxpY0uyZ9kqS5kp6XtFbSHyVNrStjtqQlkqZIelDSWuDnJa1H0j2SVkpaI+kvjYYASxot6WRJT0r6b8k/T9JHS/qmks6X9EQpZ7mkW3vT68qaLOnuku9lSQskTR7Sf1xERMRGShAbERExOIcBy4E7gSnl7ywASbsBDwLjgeOALwDPAXdL2r2unK2Aa4A5wIHA1WX7B4EbqIYCz6Aa/nuppOPr3n8N8BPg9pLvOOBJYLuSvgmwBfBj4PPACcCmwJ8kTegtRNLHgfuAccBM4GhgS+A+SZPe5v8mIiJi2Mh2u+sQERHRFSTNBH4F7GJ7UemNfcD2V+vyLQC2BybZfq1sGwU8ATxte0bZNhs4Bphh+5Y+PvddVBeeLwYm255Utn8WWAB81/YFA/wOo6gC2xXAj2yfX7bfAOwHvN/2C2XblsBi4F7b3TD3NyIiRoD0xEZERAwhSZsBewPXA+vLcN/RgIC7gb3q3vI6cFuDcnaRNEfS0pLndeBY4CM12aYBBi7pp05HSHpY0gvAOuBlYGxdWXsBt/UGsAC2VwNzy/eJiIjoCAliIyIihtZ4YBRwOm8Fn71/JwLjSs9qr5W236gtQNJYYD4wCTgFmAp8Ericqhe119bAKttrm1VG0iHAtcBTwFeAT5WyVlINK66t97IGRSynGmIcERHREbI6cURExNB6AVgPXER1S5sN2F5f+7JBlilUi0ZNtf1A78bSo1vrWWC8pM36CGR7gEW2Z9aUM4YqaK21CpjAhiYAzzcpOyIiouUSxEZERAzeq8BmtRtsvyzpD1S9qAvrAtaBek95fL13g6RxwPS6fHdR9dQeC1zYR1nr6rYdRdVbXOs+4CBJW9h+qXzmFsAhwL1vs/4RERHDJkFsRETE4D0JTJV0MNWw22dtLwa+B9wP3CnpMqphutsAuwGjbJ/ST7kPAquBiySdAWwO/JCq53Wr3ky2fy/pRuA8STsB9wBjqOa3/s72vcA8YIak86nm3u4BfIeqx7jWWcDBwAJJZ1P1EJ9MFQTPepv/l4iIiGGTObERERGDdyrwNHAd8AhwJoDthVTzTp8DLqDqMf0F8DGq4LZPtldS3cJnFNVtdn4KXAr8pkH2nvK5M4A7gJuBibw1v/USqlvwfInqNj0HUfWuvlj3mY8D+1AFz1cAVwJrgL1tP9ZfnSMiIlolt9iJiIh4h5C0N3C67f3aXZeIiIjhkuHEERERXa7MXd0T2A7YV9I421mMKSIi3pESxEZERHS/scBsqvmy17HhfNeIiIh3jAwnjoiIiIiIiK6RhZ0iIiIiIiKiaySIjYiIiIiIiK6RIDYiIiIiIiK6RoLYiIiIiIiI6BoJYiMiIiIiIqJrJIiNiIiIiIiIrvE/k9HQ+OI7bxUAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Confirmando se os valores são iguais\n",
        "np.asarray(grads_autograd)  - np.asarray(grads)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yO8y_MCZF11U",
        "outputId": "d04e3737-d511-418a-e447-37357fd8942a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.22070312e-04,  6.73294067e-04, -1.46675110e-03, -4.60624695e-04,\n",
              "        3.38983536e-03,  1.78623199e-03,  6.29186630e-04, -2.14576721e-06,\n",
              "       -4.20808792e-04, -5.12957573e-04, -1.06787682e-03, -7.47621059e-04,\n",
              "       -2.42173672e-04, -2.37673521e-04, -3.63409519e-04, -1.52483582e-04,\n",
              "       -2.12103128e-04, -9.19327140e-05, -1.17644668e-04, -8.09133053e-05])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como as diferenças dos gradientes usando diferenças finitas ou autograd são aproximadamente zero, logo ambos métodos funcionam."
      ],
      "metadata": {
        "id": "-1-DEMiXF5v7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GulfYtzBMx2e"
      },
      "source": [
        "##Exercício 3.4\n",
        "\n",
        "Quais são as restrições na escolha dos valores de $\\Delta w$ no cálculo do gradiente por diferenças finitas?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXQGEyvtiTAR"
      },
      "source": [
        "Resposta: Teoricamente, $\\Delta w$ tem que ser diferente de zero. Além disso, um valor muito grande para $\\Delta w$ torna a estimativa do cálculo imprecisa e um valor muito pequeno tende para uma estimativa igual a zero."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsrSF8GEiXk4"
      },
      "source": [
        "##Exercício 3.5\n",
        "\n",
        "Até agora trabalhamos com $w$ contendo apenas um parâmetro. Suponha agora que $w$ seja uma matriz com $N$ parâmetros e que o custo para executar $(x_i w - y_i)^2$ seja $O(N)$.\n",
        "> a) Qual é o custo computacional para fazer uma única atualização (um passo de gradiente) dos parâmetros de $w$ usando o método das diferencas finitas?\n",
        ">\n",
        "> b) Qual é o custo computacional para fazer uma única atualização (um passo de gradiente) dos parâmetros de $w$ usando o método do backpropagation?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4Pna3bcicHj"
      },
      "source": [
        "Resposta (justifique):\n",
        "\n",
        "a) Nesse caso seria $O(N^2)$, pois precisamos calcular $N$ parâmetros $N$ vezes.\n",
        "\n",
        "b) Nesse caso seria $O(N)$ porque enquanto fazemos o foward salvamos os gradientes parciais, logo conseguimos calcular o gradiente final percorrendo a rede de trás para frente (*backpropagation*) multiplicando os gradientes parciais (regra da cadeia). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35I5w8EZdjIo"
      },
      "source": [
        "##Exercício 3.6\n",
        "\n",
        "Qual o custo (entropia cruzada) esperado para um exemplo (uma amostra) no começo do treinamento de um classificador inicializado aleatoriamente?\n",
        "\n",
        "A equação da entropia cruzada é:\n",
        "$$L = - \\sum_{j=0}^{K-1} y_j \\log p_j, $$\n",
        "Onde:\n",
        "\n",
        "- K é o número de classes;\n",
        "\n",
        "- $y_j=1$ se $j$ é a classe do exemplo (ground-truth), 0 caso contrário. Ou seja, $y$ é um vetor one-hot;\n",
        "\n",
        "- $p_j$ é a probabilidade predita pelo modelo para a classe $j$.\n",
        "\n",
        "A resposta tem que ser em função de uma ou mais das seguintes variáveis:\n",
        "\n",
        "- K = número de classes\n",
        "\n",
        "- B = batch size\n",
        "\n",
        "- D = dimensão de qualquer vetor do modelo\n",
        "\n",
        "- LR = learning rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swTOphiVs6eN"
      },
      "source": [
        "Resposta:\n",
        "\n",
        "\n",
        "No caso, como o classificador foi inicializado aleatoriamente, vamos supor que o *output* do classificador tem distribuição de probabilidade uniforme ao longo das classes, isso é, $p_j = \\frac{1}{K}$. Logo temos:\n",
        "\n",
        "$$L = - \\sum_{j=0}^{K-1} y_j \\log p_j = - \\sum_{j=0}^{K-1} y_j \\log \\frac{1}{K}$$\n",
        "\n",
        "No caso, como $y_j$ é um vetor *one-hot* temos que somente para uma classe existe valor tal que $y_j=1$. Logo temos:\n",
        "\n",
        "$$L = - \\sum_{j=0}^{K-1} y_j \\log \\frac{1}{K} = - \\log \\frac{1}{K} = -(\\log 1 - \\log K) = \\log K$$\n",
        "\n",
        "Assim sendo, o custo esperado para um exemplo no começo do treinamento é:\n",
        "\n",
        "$$\\log K$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UNdHqgSB6S9"
      },
      "source": [
        "Fim do notebook."
      ]
    }
  ]
}